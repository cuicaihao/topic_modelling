{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Word2Vec Model\n",
    "==============\n",
    "\n",
    "Introduces Gensim's Word2Vec model and demonstrates its use on the Lee Corpus.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you missed the buzz, word2vec is a widely featured as a member of the\n",
    "“new wave” of machine learning algorithms based on neural networks, commonly\n",
    "referred to as \"deep learning\" (though word2vec itself is rather shallow).\n",
    "Using large amounts of unannotated plain text, word2vec learns relationships\n",
    "between words automatically. The output are vectors, one vector per word,\n",
    "with remarkable linear relationships that allow us to do things like:\n",
    "\n",
    "* vec(\"king\") - vec(\"man\") + vec(\"woman\") =~ vec(\"queen\")\n",
    "* vec(\"Montreal Canadiens\") – vec(\"Montreal\") + vec(\"Toronto\") =~ vec(\"Toronto Maple Leafs\").\n",
    "\n",
    "Word2vec is very useful in `automatic text tagging\n",
    "<https://github.com/RaRe-Technologies/movie-plots-by-genre>`_\\ , recommender\n",
    "systems and machine translation.\n",
    "\n",
    "This tutorial:\n",
    "\n",
    "#. Introduces ``Word2Vec`` as an improvement over traditional bag-of-words\n",
    "#. Shows off a demo of ``Word2Vec`` using a pre-trained model\n",
    "#. Demonstrates training a new model from your own data\n",
    "#. Demonstrates loading and saving models\n",
    "#. Introduces several training parameters and demonstrates their effect\n",
    "#. Discusses memory requirements\n",
    "#. Visualizes Word2Vec embeddings by applying dimensionality reduction\n",
    "\n",
    "Review: Bag-of-words\n",
    "--------------------\n",
    "\n",
    ".. Note:: Feel free to skip these review sections if you're already familiar with the models.\n",
    "\n",
    "You may be familiar with the `bag-of-words model\n",
    "<https://en.wikipedia.org/wiki/Bag-of-words_model>`_ from the\n",
    "`core_concepts_vector` section.\n",
    "This model transforms each document to a fixed-length vector of integers.\n",
    "For example, given the sentences:\n",
    "\n",
    "- ``John likes to watch movies. Mary likes movies too.``\n",
    "- ``John also likes to watch football games. Mary hates football.``\n",
    "\n",
    "The model outputs the vectors:\n",
    "\n",
    "- ``[1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0]``\n",
    "- ``[1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1]``\n",
    "\n",
    "Each vector has 10 elements, where each element counts the number of times a\n",
    "particular word occurred in the document.\n",
    "The order of elements is arbitrary.\n",
    "In the example above, the order of the elements corresponds to the words:\n",
    "``[\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"Mary\", \"too\", \"also\", \"football\", \"games\", \"hates\"]``.\n",
    "\n",
    "Bag-of-words models are surprisingly effective, but have several weaknesses.\n",
    "\n",
    "First, they lose all information about word order: \"John likes Mary\" and\n",
    "\"Mary likes John\" correspond to identical vectors. There is a solution: bag\n",
    "of `n-grams <https://en.wikipedia.org/wiki/N-gram>`__\n",
    "models consider word phrases of length n to represent documents as\n",
    "fixed-length vectors to capture local word order but suffer from data\n",
    "sparsity and high dimensionality.\n",
    "\n",
    "Second, the model does not attempt to learn the meaning of the underlying\n",
    "words, and as a consequence, the distance between vectors doesn't always\n",
    "reflect the difference in meaning.  The ``Word2Vec`` model addresses this\n",
    "second problem.\n",
    "\n",
    "Introducing: the ``Word2Vec`` Model\n",
    "-----------------------------------\n",
    "\n",
    "``Word2Vec`` is a more recent model that embeds words in a lower-dimensional\n",
    "vector space using a shallow neural network. The result is a set of\n",
    "word-vectors where vectors close together in vector space have similar\n",
    "meanings based on context, and word-vectors distant to each other have\n",
    "differing meanings. For example, ``strong`` and ``powerful`` would be close\n",
    "together and ``strong`` and ``Paris`` would be relatively far.\n",
    "\n",
    "The are two versions of this model and :py:class:`~gensim.models.word2vec.Word2Vec`\n",
    "class implements them both:\n",
    "\n",
    "1. Skip-grams (SG)\n",
    "2. Continuous-bag-of-words (CBOW)\n",
    "\n",
    ".. Important::\n",
    "  Don't let the implementation details below scare you.\n",
    "  They're advanced material: if it's too much, then move on to the next section.\n",
    "\n",
    "The `Word2Vec Skip-gram <http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model>`__\n",
    "model, for example, takes in pairs (word1, word2) generated by moving a\n",
    "window across text data, and trains a 1-hidden-layer neural network based on\n",
    "the synthetic task of given an input word, giving us a predicted probability\n",
    "distribution of nearby words to the input. A virtual `one-hot\n",
    "<https://en.wikipedia.org/wiki/One-hot>`__ encoding of words\n",
    "goes through a 'projection layer' to the hidden layer; these projection\n",
    "weights are later interpreted as the word embeddings. So if the hidden layer\n",
    "has 300 neurons, this network will give us 300-dimensional word embeddings.\n",
    "\n",
    "Continuous-bag-of-words Word2vec is very similar to the skip-gram model. It\n",
    "is also a 1-hidden-layer neural network. The synthetic training task now uses\n",
    "the average of multiple input context words, rather than a single word as in\n",
    "skip-gram, to predict the center word. Again, the projection weights that\n",
    "turn one-hot words into averageable vectors, of the same width as the hidden\n",
    "layer, are interpreted as the word embeddings.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec Demo\n",
    "-------------\n",
    "\n",
    "To see what ``Word2Vec`` can do, let's download a pre-trained model and play\n",
    "around with it. We will fetch the Word2Vec model trained on part of the\n",
    "Google News dataset, covering approximately 3 million words and phrases. Such\n",
    "a model can take hours to train, but since it's already available,\n",
    "downloading and loading it with Gensim takes minutes.\n",
    "\n",
    ".. Important::\n",
    "  The model is approximately 2GB, so you'll need a decent network connection\n",
    "  to proceed.  Otherwise, skip ahead to the \"Training Your Own Model\" section\n",
    "  below.\n",
    "\n",
    "You may also check out an `online word2vec demo\n",
    "<http://radimrehurek.com/2014/02/word2vec-tutorial/#app>`_ where you can try\n",
    "this vector algebra for yourself. That demo runs ``word2vec`` on the\n",
    "**entire** Google News dataset, of **about 100 billion words**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:21:35,672 : INFO : loading projection weights from /Users/caihaocui/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2020-04-17 14:23:38,474 : INFO : loaded (3000000, 300) matrix from /Users/caihaocui/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/word2vec-google-news-300.joblib.z']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Compressed joblib pickles\n",
    "# joblib.dump(wv, '../models/word2vec-google-news-300.joblib.z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common operation is to retrieve the vocabulary of a model.  That is trivial:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n",
      "in\n",
      "for\n",
      "that\n",
      "is\n",
      "on\n",
      "##\n",
      "The\n",
      "with\n",
      "said\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily obtain vectors for terms the model is familiar with:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_king = wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
       "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
       "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
       "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
       "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
       "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
       "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
       "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
       "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
       "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
       "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
       "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
       "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
       "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
       "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
       "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
       "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
       "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
       "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
       "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
       "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
       "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
       "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
       "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
       "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
       "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
       "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
       "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
       "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
       "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
       "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
       "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
       "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
       "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
       "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
       "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
       "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
       "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
       "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
       "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
       "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
       "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
       "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
       "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
       "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
       "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
       "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
       "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
       "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
       "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
       "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
       "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
       "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
       "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
       "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
       "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
       "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
       "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
       "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
       "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
       "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
       "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
       "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
       "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
       "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
       "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
       "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
       "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
       "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
       "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
       "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
       "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
       "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
       "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
       "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_king"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the model is unable to infer vectors for unfamiliar words.\n",
    "This is one limitation of Word2Vec: if this limitation matters to you, check\n",
    "out the FastText model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'cameroon' does not appear in this model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vec_cameroon = wv['cameroon']\n",
    "except KeyError:\n",
    "    print(\"The word 'cameroon' does not appear in this model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, ``Word2Vec`` supports several word similarity tasks out of the\n",
    "box.  You can see how the similarity intuitively decreases as the words get\n",
    "less and less similar.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the 5 most similar words to \"car\" or \"minivan\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:17:08,984 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SUV', 0.853219211101532), ('vehicle', 0.8175784349441528), ('pickup_truck', 0.7763689160346985), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.756571888923645)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=['car', 'minivan'], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the below does not belong in the sequence?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caihaocui/anaconda3/envs/NLP/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Your Own Model\n",
    "-----------------------\n",
    "\n",
    "To start, you'll need some data for training the model.  For the following\n",
    "examples, we'll use the `Lee Corpus\n",
    "<https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/test_data/lee_background.cor>`_\n",
    "(which you already have if you've installed gensim).\n",
    "\n",
    "This corpus is small enough to fit entirely in memory, but we'll implement a\n",
    "memory-friendly iterator that reads it line-by-line to demonstrate how you\n",
    "would handle a larger corpus.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to do any custom preprocessing, e.g. decode a non-standard\n",
    "encoding, lowercase, remove numbers, extract named entities... All of this can\n",
    "be done inside the ``MyCorpus`` iterator and ``word2vec`` doesn’t need to\n",
    "know. All that is required is that the input yields one sentence (list of\n",
    "utf8 words) after another.\n",
    "\n",
    "Let's go ahead and train a model on our corpus.  Don't worry about the\n",
    "training parameters much for now, we'll revisit them later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:37:21,372 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:37:21,378 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:37:21,451 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2020-04-17 14:37:21,453 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:37:21,459 : INFO : effective_min_count=5 retains 1750 unique words (25% of original 6981, drops 5231)\n",
      "2020-04-17 14:37:21,460 : INFO : effective_min_count=5 leaves 49335 word corpus (84% of original 58152, drops 8817)\n",
      "2020-04-17 14:37:21,468 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2020-04-17 14:37:21,469 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-04-17 14:37:21,470 : INFO : downsampling leaves estimated 35935 word corpus (72.8% of prior 49335)\n",
      "2020-04-17 14:37:21,475 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2020-04-17 14:37:21,476 : INFO : resetting layer weights\n",
      "2020-04-17 14:37:21,756 : INFO : training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:37:21,855 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:37:21,857 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:37:21,858 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:37:21,859 : INFO : EPOCH - 1 : training on 58152 raw words (35993 effective words) took 0.1s, 386703 effective words/s\n",
      "2020-04-17 14:37:21,937 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:37:21,939 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:37:21,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:37:21,943 : INFO : EPOCH - 2 : training on 58152 raw words (35986 effective words) took 0.1s, 433499 effective words/s\n",
      "2020-04-17 14:37:22,021 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:37:22,027 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:37:22,029 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:37:22,030 : INFO : EPOCH - 3 : training on 58152 raw words (35905 effective words) took 0.1s, 422712 effective words/s\n",
      "2020-04-17 14:37:22,108 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:37:22,111 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:37:22,113 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:37:22,114 : INFO : EPOCH - 4 : training on 58152 raw words (35933 effective words) took 0.1s, 435700 effective words/s\n",
      "2020-04-17 14:37:22,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:37:22,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:37:22,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:37:22,199 : INFO : EPOCH - 5 : training on 58152 raw words (35859 effective words) took 0.1s, 428643 effective words/s\n",
      "2020-04-17 14:37:22,199 : INFO : training on a 290760 raw words (179676 effective words) took 0.4s, 405909 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our model, we can use it in the same way as in the demo above.\n",
    "\n",
    "The main part of the model is ``model.wv``\\ , where \"wv\" stands for \"word vectors\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_king = model.wv['king']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the vocabulary works the same way:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hundreds\n",
      "of\n",
      "people\n",
      "have\n",
      "been\n",
      "forced\n",
      "to\n",
      "their\n",
      "homes\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(model.wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing and loading models\n",
    "--------------------------\n",
    "\n",
    "You'll notice that training non-trivial models can take time.  Once you've\n",
    "trained your model and it works as expected, you can save it to disk.  That\n",
    "way, you don't have to spend time training it all over again later.\n",
    "\n",
    "You can store/load models using the standard gensim methods:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:37:50,323 : INFO : saving Word2Vec object under /var/folders/nb/1jpl223s247d7gwj8hb54b0w0000gn/T/gensim-model-2mfz9t3x, separately None\n",
      "2020-04-17 14:37:50,324 : INFO : not storing attribute vectors_norm\n",
      "2020-04-17 14:37:50,325 : INFO : not storing attribute cum_table\n",
      "2020-04-17 14:37:50,351 : INFO : saved /var/folders/nb/1jpl223s247d7gwj8hb54b0w0000gn/T/gensim-model-2mfz9t3x\n",
      "2020-04-17 14:37:50,351 : INFO : loading Word2Vec object from /var/folders/nb/1jpl223s247d7gwj8hb54b0w0000gn/T/gensim-model-2mfz9t3x\n",
      "2020-04-17 14:37:50,369 : INFO : loading wv recursively from /var/folders/nb/1jpl223s247d7gwj8hb54b0w0000gn/T/gensim-model-2mfz9t3x.wv.* with mmap=None\n",
      "2020-04-17 14:37:50,370 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-04-17 14:37:50,371 : INFO : loading vocabulary recursively from /var/folders/nb/1jpl223s247d7gwj8hb54b0w0000gn/T/gensim-model-2mfz9t3x.vocabulary.* with mmap=None\n",
      "2020-04-17 14:37:50,372 : INFO : loading trainables recursively from /var/folders/nb/1jpl223s247d7gwj8hb54b0w0000gn/T/gensim-model-2mfz9t3x.trainables.* with mmap=None\n",
      "2020-04-17 14:37:50,373 : INFO : setting ignored attribute cum_table to None\n",
      "2020-04-17 14:37:50,374 : INFO : loaded /var/folders/nb/1jpl223s247d7gwj8hb54b0w0000gn/T/gensim-model-2mfz9t3x\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    model.save(temporary_filepath)\n",
    "    #\n",
    "    # The model is now safely stored in the filepath.\n",
    "    # You can copy it to other machines, share it with others, etc.\n",
    "    #\n",
    "    # To load a saved model:\n",
    "    #\n",
    "    new_model = gensim.models.Word2Vec.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which uses pickle internally, optionally ``mmap``\\ ‘ing the model’s internal\n",
    "large NumPy matrices into virtual memory directly from disk files, for\n",
    "inter-process memory sharing.\n",
    "\n",
    "In addition, you can load models created by the original C tool, both using\n",
    "its text and binary formats::\n",
    "\n",
    "  model = gensim.models.KeyedVectors.load_word2vec_format('/tmp/vectors.txt', binary=False)\n",
    "  # using gzipped/bz2 input works too, no need to unzip\n",
    "  model = gensim.models.KeyedVectors.load_word2vec_format('/tmp/vectors.bin.gz', binary=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, '../models/gensim-model-Lee Corpus.z')\n",
    "new_model = joblib.load('../models/gensim-model-Lee Corpus.z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hundreds\n",
      "of\n",
      "people\n",
      "have\n",
      "been\n",
      "forced\n",
      "to\n",
      "their\n",
      "homes\n",
      "in\n",
      "[-0.01732911 -0.02997664 -0.03767837 -0.0766324   0.01324796 -0.01675296\n",
      "  0.05482481 -0.03078569 -0.04718136  0.00045335  0.01799739  0.03271269\n",
      " -0.00772294  0.05855966 -0.01453003  0.03809257  0.03609253 -0.00192986\n",
      "  0.00481473 -0.01255722  0.01087584 -0.02284502  0.00936334 -0.00693843\n",
      " -0.02568576  0.08502577 -0.0183079  -0.05152747 -0.00454475 -0.01175759\n",
      " -0.01653733 -0.02631769 -0.01993887 -0.01263655  0.02192106  0.0039287\n",
      "  0.03444264  0.01505884 -0.01548206 -0.02628593 -0.00882326 -0.04035963\n",
      "  0.00923365  0.05125612 -0.03212337  0.0096742  -0.02519332 -0.0061903\n",
      "  0.02187816  0.02910632  0.02966235 -0.00727127  0.03666604  0.02229308\n",
      " -0.04737489 -0.01757282  0.04990115 -0.05369172 -0.03785142  0.01172126\n",
      "  0.01106479 -0.00365501 -0.03034444 -0.02472414  0.00095579 -0.0501749\n",
      " -0.04425829  0.01184128 -0.03996208  0.0517815   0.0351619   0.058522\n",
      " -0.02869451  0.02419358  0.00569182  0.03154719  0.02417227 -0.01564167\n",
      "  0.00308904  0.02253046  0.04017276  0.04392068 -0.01288971  0.04880586\n",
      "  0.01556747 -0.00413938 -0.03320894 -0.04060649  0.02800165  0.02438884\n",
      " -0.04964662 -0.0113043  -0.0443565  -0.02708641 -0.01003764  0.01430745\n",
      "  0.0232032  -0.02947849  0.0215957  -0.00329722]\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(new_model.wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)\n",
    "    \n",
    "print(model.wv['king'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Parameters\n",
    "-------------------\n",
    "\n",
    "``Word2Vec`` accepts several parameters that affect both training speed and quality.\n",
    "\n",
    "min_count\n",
    "---------\n",
    "\n",
    "``min_count`` is for pruning the internal dictionary. Words that appear only\n",
    "once or twice in a billion-word corpus are probably uninteresting typos and\n",
    "garbage. In addition, there’s not enough data to make any meaningful training\n",
    "on those words, so it’s best to ignore them:\n",
    "\n",
    "default value of min_count=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:43:38,738 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:43:38,741 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:43:38,811 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2020-04-17 14:43:38,812 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:43:38,815 : INFO : effective_min_count=10 retains 889 unique words (12% of original 6981, drops 6092)\n",
      "2020-04-17 14:43:38,816 : INFO : effective_min_count=10 leaves 43776 word corpus (75% of original 58152, drops 14376)\n",
      "2020-04-17 14:43:38,818 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2020-04-17 14:43:38,819 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2020-04-17 14:43:38,819 : INFO : downsampling leaves estimated 29691 word corpus (67.8% of prior 43776)\n",
      "2020-04-17 14:43:38,821 : INFO : estimated required memory for 889 words and 100 dimensions: 1155700 bytes\n",
      "2020-04-17 14:43:38,821 : INFO : resetting layer weights\n",
      "2020-04-17 14:43:38,966 : INFO : training model with 3 workers on 889 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:43:39,044 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:43:39,045 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:43:39,049 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:43:39,050 : INFO : EPOCH - 1 : training on 58152 raw words (29735 effective words) took 0.1s, 363746 effective words/s\n",
      "2020-04-17 14:43:39,122 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:43:39,127 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:43:39,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:43:39,129 : INFO : EPOCH - 2 : training on 58152 raw words (29761 effective words) took 0.1s, 381711 effective words/s\n",
      "2020-04-17 14:43:39,207 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:43:39,208 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:43:39,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:43:39,210 : INFO : EPOCH - 3 : training on 58152 raw words (29671 effective words) took 0.1s, 371650 effective words/s\n",
      "2020-04-17 14:43:39,287 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:43:39,287 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:43:39,291 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:43:39,291 : INFO : EPOCH - 4 : training on 58152 raw words (29718 effective words) took 0.1s, 370645 effective words/s\n",
      "2020-04-17 14:43:39,367 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:43:39,369 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:43:39,370 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:43:39,371 : INFO : EPOCH - 5 : training on 58152 raw words (29702 effective words) took 0.1s, 380831 effective words/s\n",
      "2020-04-17 14:43:39,371 : INFO : training on a 290760 raw words (148587 effective words) took 0.4s, 367558 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences, min_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size\n",
    "----\n",
    "\n",
    "``size`` is the number of dimensions (N) of the N-dimensional space that\n",
    "gensim Word2Vec maps the words onto.\n",
    "\n",
    "Bigger size values require more training data, but can lead to better (more\n",
    "accurate) models. Reasonable values are in the tens to hundreds.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:44:02,868 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:44:02,869 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:44:02,940 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2020-04-17 14:44:02,941 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:44:02,945 : INFO : effective_min_count=5 retains 1750 unique words (25% of original 6981, drops 5231)\n",
      "2020-04-17 14:44:02,946 : INFO : effective_min_count=5 leaves 49335 word corpus (84% of original 58152, drops 8817)\n",
      "2020-04-17 14:44:02,950 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2020-04-17 14:44:02,950 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-04-17 14:44:02,951 : INFO : downsampling leaves estimated 35935 word corpus (72.8% of prior 49335)\n",
      "2020-04-17 14:44:02,953 : INFO : estimated required memory for 1750 words and 200 dimensions: 3675000 bytes\n",
      "2020-04-17 14:44:02,954 : INFO : resetting layer weights\n",
      "2020-04-17 14:44:03,232 : INFO : training model with 3 workers on 1750 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:44:03,314 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:44:03,318 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:44:03,319 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:44:03,320 : INFO : EPOCH - 1 : training on 58152 raw words (35865 effective words) took 0.1s, 416711 effective words/s\n",
      "2020-04-17 14:44:03,400 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:44:03,403 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:44:03,407 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:44:03,407 : INFO : EPOCH - 2 : training on 58152 raw words (35988 effective words) took 0.1s, 416600 effective words/s\n",
      "2020-04-17 14:44:03,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:44:03,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:44:03,494 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:44:03,494 : INFO : EPOCH - 3 : training on 58152 raw words (35891 effective words) took 0.1s, 419158 effective words/s\n",
      "2020-04-17 14:44:03,575 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:44:03,576 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:44:03,581 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:44:03,581 : INFO : EPOCH - 4 : training on 58152 raw words (35871 effective words) took 0.1s, 418835 effective words/s\n",
      "2020-04-17 14:44:03,664 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:44:03,667 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:44:03,673 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:44:03,673 : INFO : EPOCH - 5 : training on 58152 raw words (35921 effective words) took 0.1s, 395171 effective words/s\n",
      "2020-04-17 14:44:03,674 : INFO : training on a 290760 raw words (179536 effective words) took 0.4s, 407069 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# default value of size=100\n",
    "model = gensim.models.Word2Vec(sentences, size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "workers\n",
    "-------\n",
    "\n",
    "``workers`` , the last of the major parameters (full list `here\n",
    "<http://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec>`_)\n",
    "is for training parallelization, to speed up training:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:52:34,974 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:52:34,977 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:52:35,051 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2020-04-17 14:52:35,052 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:52:35,057 : INFO : effective_min_count=5 retains 1750 unique words (25% of original 6981, drops 5231)\n",
      "2020-04-17 14:52:35,058 : INFO : effective_min_count=5 leaves 49335 word corpus (84% of original 58152, drops 8817)\n",
      "2020-04-17 14:52:35,062 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2020-04-17 14:52:35,063 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2020-04-17 14:52:35,063 : INFO : downsampling leaves estimated 35935 word corpus (72.8% of prior 49335)\n",
      "2020-04-17 14:52:35,067 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2020-04-17 14:52:35,067 : INFO : resetting layer weights\n",
      "2020-04-17 14:52:35,339 : INFO : training model with 4 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:52:35,420 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-17 14:52:35,426 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:52:35,431 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:52:35,431 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:52:35,432 : INFO : EPOCH - 1 : training on 58152 raw words (35896 effective words) took 0.1s, 398056 effective words/s\n",
      "2020-04-17 14:52:35,517 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-17 14:52:35,518 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:52:35,518 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:52:35,523 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:52:35,523 : INFO : EPOCH - 2 : training on 58152 raw words (35995 effective words) took 0.1s, 400234 effective words/s\n",
      "2020-04-17 14:52:35,600 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-17 14:52:35,604 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:52:35,605 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:52:35,607 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:52:35,608 : INFO : EPOCH - 3 : training on 58152 raw words (35858 effective words) took 0.1s, 432429 effective words/s\n",
      "2020-04-17 14:52:35,686 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-17 14:52:35,687 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:52:35,689 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:52:35,692 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:52:35,692 : INFO : EPOCH - 4 : training on 58152 raw words (35936 effective words) took 0.1s, 441779 effective words/s\n",
      "2020-04-17 14:52:35,771 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-17 14:52:35,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:52:35,776 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:52:35,777 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:52:35,777 : INFO : EPOCH - 5 : training on 58152 raw words (35883 effective words) took 0.1s, 430013 effective words/s\n",
      "2020-04-17 14:52:35,778 : INFO : training on a 290760 raw words (179568 effective words) took 0.4s, 409925 effective words/s\n",
      "2020-04-17 14:52:35,778 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "# default value of workers=3 (tutorial says 1...)\n",
    "model = gensim.models.Word2Vec(sentences, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``workers`` parameter only has an effect if you have `Cython\n",
    "<http://cython.org/>`_ installed. Without Cython, you’ll only be able to use\n",
    "one core because of the `GIL\n",
    "<https://wiki.python.org/moin/GlobalInterpreterLock>`_ (and ``word2vec``\n",
    "training will be `miserably slow\n",
    "<http://rare-technologies.com/word2vec-in-python-part-two-optimizing/>`_\\ ).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory\n",
    "------\n",
    "\n",
    "At its core, ``word2vec`` model parameters are stored as matrices (NumPy\n",
    "arrays). Each array is **#vocabulary** (controlled by min_count parameter)\n",
    "times **#size** (size parameter) of floats (single precision aka 4 bytes).\n",
    "\n",
    "Three such matrices are held in RAM (work is underway to reduce that number\n",
    "to two, or even one). So if your input contains 100,000 unique words, and you\n",
    "asked for layer ``size=200``\\ , the model will require approx.\n",
    "``100,000*200*4*3 bytes = ~229MB``.\n",
    "\n",
    "There’s a little extra memory needed for storing the vocabulary tree (100,000 words would take a few megabytes), but unless your words are extremely loooong strings, memory footprint will be dominated by the three matrices above.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating\n",
    "----------\n",
    "\n",
    "``Word2Vec`` training is an unsupervised task, there’s no good way to\n",
    "objectively evaluate the result. Evaluation depends on your end application.\n",
    "\n",
    "Google has released their testing set of about 20,000 syntactic and semantic\n",
    "test examples, following the “A is to B as C is to D” task. It is provided in\n",
    "the 'datasets' folder.\n",
    "\n",
    "For example a syntactic analogy of comparative type is bad:worse;good:?.\n",
    "There are total of 9 types of syntactic comparisons in the dataset like\n",
    "plural nouns and nouns of opposite meaning.\n",
    "\n",
    "The semantic questions contain five types of semantic analogies, such as\n",
    "capital cities (Paris:France;Tokyo:?) or family members\n",
    "(brother:sister;dad:?).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim supports the same evaluation set, in exactly the same format:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caihaocui/anaconda3/envs/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `accuracy` (Method will be removed in 4.0.0, use self.wv.evaluate_word_analogies() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2020-04-17 14:52:40,715 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-04-17 14:52:40,719 : INFO : capital-common-countries: 0.0% (0/6)\n",
      "2020-04-17 14:52:40,730 : INFO : capital-world: 0.0% (0/2)\n",
      "2020-04-17 14:52:40,741 : INFO : family: 16.7% (1/6)\n",
      "2020-04-17 14:52:40,752 : INFO : gram3-comparative: 0.0% (0/20)\n",
      "2020-04-17 14:52:40,759 : INFO : gram4-superlative: 0.0% (0/12)\n",
      "2020-04-17 14:52:40,768 : INFO : gram5-present-participle: 0.0% (0/20)\n",
      "2020-04-17 14:52:40,779 : INFO : gram6-nationality-adjective: 0.0% (0/30)\n",
      "2020-04-17 14:52:40,787 : INFO : gram7-past-tense: 0.0% (0/20)\n",
      "2020-04-17 14:52:40,797 : INFO : gram8-plural: 0.0% (0/30)\n",
      "2020-04-17 14:52:40,799 : INFO : total: 0.7% (1/146)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'section': 'capital-common-countries',\n",
       "  'correct': [],\n",
       "  'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "   ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n",
       "   ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "   ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n",
       "   ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n",
       "   ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN')]},\n",
       " {'section': 'capital-world',\n",
       "  'correct': [],\n",
       "  'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "   ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE')]},\n",
       " {'section': 'currency', 'correct': [], 'incorrect': []},\n",
       " {'section': 'city-in-state', 'correct': [], 'incorrect': []},\n",
       " {'section': 'family',\n",
       "  'correct': [('HIS', 'HER', 'HE', 'SHE')],\n",
       "  'incorrect': [('HE', 'SHE', 'HIS', 'HER'),\n",
       "   ('HE', 'SHE', 'MAN', 'WOMAN'),\n",
       "   ('HIS', 'HER', 'MAN', 'WOMAN'),\n",
       "   ('MAN', 'WOMAN', 'HE', 'SHE'),\n",
       "   ('MAN', 'WOMAN', 'HIS', 'HER')]},\n",
       " {'section': 'gram1-adjective-to-adverb', 'correct': [], 'incorrect': []},\n",
       " {'section': 'gram2-opposite', 'correct': [], 'incorrect': []},\n",
       " {'section': 'gram3-comparative',\n",
       "  'correct': [],\n",
       "  'incorrect': [('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
       "   ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
       "   ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
       "   ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n",
       "   ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
       "   ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
       "   ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n",
       "   ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
       "   ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
       "   ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n",
       "   ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
       "   ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
       "   ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n",
       "   ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
       "   ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
       "   ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
       "   ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n",
       "   ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n",
       "   ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n",
       "   ('SMALL', 'SMALLER', 'LOW', 'LOWER')]},\n",
       " {'section': 'gram4-superlative',\n",
       "  'correct': [],\n",
       "  'incorrect': [('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
       "   ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
       "   ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
       "   ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
       "   ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
       "   ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
       "   ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
       "   ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
       "   ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
       "   ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
       "   ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
       "   ('LARGE', 'LARGEST', 'GREAT', 'GREATEST')]},\n",
       " {'section': 'gram5-present-participle',\n",
       "  'correct': [],\n",
       "  'incorrect': [('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
       "   ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
       "   ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
       "   ('GO', 'GOING', 'SAY', 'SAYING'),\n",
       "   ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
       "   ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
       "   ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
       "   ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
       "   ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
       "   ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
       "   ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
       "   ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
       "   ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
       "   ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
       "   ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
       "   ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
       "   ('SAY', 'SAYING', 'GO', 'GOING'),\n",
       "   ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
       "   ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
       "   ('SAY', 'SAYING', 'RUN', 'RUNNING')]},\n",
       " {'section': 'gram6-nationality-adjective',\n",
       "  'correct': [],\n",
       "  'incorrect': [('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
       "   ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
       "   ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
       "   ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n",
       "   ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
       "   ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
       "   ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
       "   ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n",
       "   ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
       "   ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "   ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
       "   ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n",
       "   ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
       "   ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "   ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
       "   ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n",
       "   ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
       "   ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "   ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
       "   ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
       "   ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n",
       "   ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "   ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n",
       "   ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n",
       "   ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n",
       "   ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "   ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
       "   ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
       "   ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
       "   ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE')]},\n",
       " {'section': 'gram7-past-tense',\n",
       "  'correct': [],\n",
       "  'incorrect': [('GOING', 'WENT', 'PAYING', 'PAID'),\n",
       "   ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
       "   ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
       "   ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
       "   ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
       "   ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
       "   ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
       "   ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
       "   ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
       "   ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
       "   ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
       "   ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
       "   ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
       "   ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
       "   ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
       "   ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
       "   ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
       "   ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
       "   ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
       "   ('TAKING', 'TOOK', 'SAYING', 'SAID')]},\n",
       " {'section': 'gram8-plural',\n",
       "  'correct': [],\n",
       "  'incorrect': [('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
       "   ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
       "   ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
       "   ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n",
       "   ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n",
       "   ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
       "   ('CAR', 'CARS', 'MAN', 'MEN'),\n",
       "   ('CAR', 'CARS', 'ROAD', 'ROADS'),\n",
       "   ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n",
       "   ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
       "   ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
       "   ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n",
       "   ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n",
       "   ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
       "   ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
       "   ('MAN', 'MEN', 'ROAD', 'ROADS'),\n",
       "   ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n",
       "   ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
       "   ('MAN', 'MEN', 'CAR', 'CARS'),\n",
       "   ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n",
       "   ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n",
       "   ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n",
       "   ('ROAD', 'ROADS', 'CAR', 'CARS'),\n",
       "   ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n",
       "   ('ROAD', 'ROADS', 'MAN', 'MEN'),\n",
       "   ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n",
       "   ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n",
       "   ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n",
       "   ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n",
       "   ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]},\n",
       " {'section': 'gram9-plural-verbs', 'correct': [], 'incorrect': []},\n",
       " {'section': 'total',\n",
       "  'correct': [('HIS', 'HER', 'HE', 'SHE')],\n",
       "  'incorrect': [('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "   ('CANBERRA', 'AUSTRALIA', 'PARIS', 'FRANCE'),\n",
       "   ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "   ('KABUL', 'AFGHANISTAN', 'CANBERRA', 'AUSTRALIA'),\n",
       "   ('PARIS', 'FRANCE', 'CANBERRA', 'AUSTRALIA'),\n",
       "   ('PARIS', 'FRANCE', 'KABUL', 'AFGHANISTAN'),\n",
       "   ('CANBERRA', 'AUSTRALIA', 'KABUL', 'AFGHANISTAN'),\n",
       "   ('KABUL', 'AFGHANISTAN', 'PARIS', 'FRANCE'),\n",
       "   ('HE', 'SHE', 'HIS', 'HER'),\n",
       "   ('HE', 'SHE', 'MAN', 'WOMAN'),\n",
       "   ('HIS', 'HER', 'MAN', 'WOMAN'),\n",
       "   ('MAN', 'WOMAN', 'HE', 'SHE'),\n",
       "   ('MAN', 'WOMAN', 'HIS', 'HER'),\n",
       "   ('GOOD', 'BETTER', 'GREAT', 'GREATER'),\n",
       "   ('GOOD', 'BETTER', 'LONG', 'LONGER'),\n",
       "   ('GOOD', 'BETTER', 'LOW', 'LOWER'),\n",
       "   ('GOOD', 'BETTER', 'SMALL', 'SMALLER'),\n",
       "   ('GREAT', 'GREATER', 'LONG', 'LONGER'),\n",
       "   ('GREAT', 'GREATER', 'LOW', 'LOWER'),\n",
       "   ('GREAT', 'GREATER', 'SMALL', 'SMALLER'),\n",
       "   ('GREAT', 'GREATER', 'GOOD', 'BETTER'),\n",
       "   ('LONG', 'LONGER', 'LOW', 'LOWER'),\n",
       "   ('LONG', 'LONGER', 'SMALL', 'SMALLER'),\n",
       "   ('LONG', 'LONGER', 'GOOD', 'BETTER'),\n",
       "   ('LONG', 'LONGER', 'GREAT', 'GREATER'),\n",
       "   ('LOW', 'LOWER', 'SMALL', 'SMALLER'),\n",
       "   ('LOW', 'LOWER', 'GOOD', 'BETTER'),\n",
       "   ('LOW', 'LOWER', 'GREAT', 'GREATER'),\n",
       "   ('LOW', 'LOWER', 'LONG', 'LONGER'),\n",
       "   ('SMALL', 'SMALLER', 'GOOD', 'BETTER'),\n",
       "   ('SMALL', 'SMALLER', 'GREAT', 'GREATER'),\n",
       "   ('SMALL', 'SMALLER', 'LONG', 'LONGER'),\n",
       "   ('SMALL', 'SMALLER', 'LOW', 'LOWER'),\n",
       "   ('BIG', 'BIGGEST', 'GOOD', 'BEST'),\n",
       "   ('BIG', 'BIGGEST', 'GREAT', 'GREATEST'),\n",
       "   ('BIG', 'BIGGEST', 'LARGE', 'LARGEST'),\n",
       "   ('GOOD', 'BEST', 'GREAT', 'GREATEST'),\n",
       "   ('GOOD', 'BEST', 'LARGE', 'LARGEST'),\n",
       "   ('GOOD', 'BEST', 'BIG', 'BIGGEST'),\n",
       "   ('GREAT', 'GREATEST', 'LARGE', 'LARGEST'),\n",
       "   ('GREAT', 'GREATEST', 'BIG', 'BIGGEST'),\n",
       "   ('GREAT', 'GREATEST', 'GOOD', 'BEST'),\n",
       "   ('LARGE', 'LARGEST', 'BIG', 'BIGGEST'),\n",
       "   ('LARGE', 'LARGEST', 'GOOD', 'BEST'),\n",
       "   ('LARGE', 'LARGEST', 'GREAT', 'GREATEST'),\n",
       "   ('GO', 'GOING', 'LOOK', 'LOOKING'),\n",
       "   ('GO', 'GOING', 'PLAY', 'PLAYING'),\n",
       "   ('GO', 'GOING', 'RUN', 'RUNNING'),\n",
       "   ('GO', 'GOING', 'SAY', 'SAYING'),\n",
       "   ('LOOK', 'LOOKING', 'PLAY', 'PLAYING'),\n",
       "   ('LOOK', 'LOOKING', 'RUN', 'RUNNING'),\n",
       "   ('LOOK', 'LOOKING', 'SAY', 'SAYING'),\n",
       "   ('LOOK', 'LOOKING', 'GO', 'GOING'),\n",
       "   ('PLAY', 'PLAYING', 'RUN', 'RUNNING'),\n",
       "   ('PLAY', 'PLAYING', 'SAY', 'SAYING'),\n",
       "   ('PLAY', 'PLAYING', 'GO', 'GOING'),\n",
       "   ('PLAY', 'PLAYING', 'LOOK', 'LOOKING'),\n",
       "   ('RUN', 'RUNNING', 'SAY', 'SAYING'),\n",
       "   ('RUN', 'RUNNING', 'GO', 'GOING'),\n",
       "   ('RUN', 'RUNNING', 'LOOK', 'LOOKING'),\n",
       "   ('RUN', 'RUNNING', 'PLAY', 'PLAYING'),\n",
       "   ('SAY', 'SAYING', 'GO', 'GOING'),\n",
       "   ('SAY', 'SAYING', 'LOOK', 'LOOKING'),\n",
       "   ('SAY', 'SAYING', 'PLAY', 'PLAYING'),\n",
       "   ('SAY', 'SAYING', 'RUN', 'RUNNING'),\n",
       "   ('AUSTRALIA', 'AUSTRALIAN', 'FRANCE', 'FRENCH'),\n",
       "   ('AUSTRALIA', 'AUSTRALIAN', 'INDIA', 'INDIAN'),\n",
       "   ('AUSTRALIA', 'AUSTRALIAN', 'ISRAEL', 'ISRAELI'),\n",
       "   ('AUSTRALIA', 'AUSTRALIAN', 'JAPAN', 'JAPANESE'),\n",
       "   ('AUSTRALIA', 'AUSTRALIAN', 'SWITZERLAND', 'SWISS'),\n",
       "   ('FRANCE', 'FRENCH', 'INDIA', 'INDIAN'),\n",
       "   ('FRANCE', 'FRENCH', 'ISRAEL', 'ISRAELI'),\n",
       "   ('FRANCE', 'FRENCH', 'JAPAN', 'JAPANESE'),\n",
       "   ('FRANCE', 'FRENCH', 'SWITZERLAND', 'SWISS'),\n",
       "   ('FRANCE', 'FRENCH', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "   ('INDIA', 'INDIAN', 'ISRAEL', 'ISRAELI'),\n",
       "   ('INDIA', 'INDIAN', 'JAPAN', 'JAPANESE'),\n",
       "   ('INDIA', 'INDIAN', 'SWITZERLAND', 'SWISS'),\n",
       "   ('INDIA', 'INDIAN', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "   ('INDIA', 'INDIAN', 'FRANCE', 'FRENCH'),\n",
       "   ('ISRAEL', 'ISRAELI', 'JAPAN', 'JAPANESE'),\n",
       "   ('ISRAEL', 'ISRAELI', 'SWITZERLAND', 'SWISS'),\n",
       "   ('ISRAEL', 'ISRAELI', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "   ('ISRAEL', 'ISRAELI', 'FRANCE', 'FRENCH'),\n",
       "   ('ISRAEL', 'ISRAELI', 'INDIA', 'INDIAN'),\n",
       "   ('JAPAN', 'JAPANESE', 'SWITZERLAND', 'SWISS'),\n",
       "   ('JAPAN', 'JAPANESE', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "   ('JAPAN', 'JAPANESE', 'FRANCE', 'FRENCH'),\n",
       "   ('JAPAN', 'JAPANESE', 'INDIA', 'INDIAN'),\n",
       "   ('JAPAN', 'JAPANESE', 'ISRAEL', 'ISRAELI'),\n",
       "   ('SWITZERLAND', 'SWISS', 'AUSTRALIA', 'AUSTRALIAN'),\n",
       "   ('SWITZERLAND', 'SWISS', 'FRANCE', 'FRENCH'),\n",
       "   ('SWITZERLAND', 'SWISS', 'INDIA', 'INDIAN'),\n",
       "   ('SWITZERLAND', 'SWISS', 'ISRAEL', 'ISRAELI'),\n",
       "   ('SWITZERLAND', 'SWISS', 'JAPAN', 'JAPANESE'),\n",
       "   ('GOING', 'WENT', 'PAYING', 'PAID'),\n",
       "   ('GOING', 'WENT', 'PLAYING', 'PLAYED'),\n",
       "   ('GOING', 'WENT', 'SAYING', 'SAID'),\n",
       "   ('GOING', 'WENT', 'TAKING', 'TOOK'),\n",
       "   ('PAYING', 'PAID', 'PLAYING', 'PLAYED'),\n",
       "   ('PAYING', 'PAID', 'SAYING', 'SAID'),\n",
       "   ('PAYING', 'PAID', 'TAKING', 'TOOK'),\n",
       "   ('PAYING', 'PAID', 'GOING', 'WENT'),\n",
       "   ('PLAYING', 'PLAYED', 'SAYING', 'SAID'),\n",
       "   ('PLAYING', 'PLAYED', 'TAKING', 'TOOK'),\n",
       "   ('PLAYING', 'PLAYED', 'GOING', 'WENT'),\n",
       "   ('PLAYING', 'PLAYED', 'PAYING', 'PAID'),\n",
       "   ('SAYING', 'SAID', 'TAKING', 'TOOK'),\n",
       "   ('SAYING', 'SAID', 'GOING', 'WENT'),\n",
       "   ('SAYING', 'SAID', 'PAYING', 'PAID'),\n",
       "   ('SAYING', 'SAID', 'PLAYING', 'PLAYED'),\n",
       "   ('TAKING', 'TOOK', 'GOING', 'WENT'),\n",
       "   ('TAKING', 'TOOK', 'PAYING', 'PAID'),\n",
       "   ('TAKING', 'TOOK', 'PLAYING', 'PLAYED'),\n",
       "   ('TAKING', 'TOOK', 'SAYING', 'SAID'),\n",
       "   ('BUILDING', 'BUILDINGS', 'CAR', 'CARS'),\n",
       "   ('BUILDING', 'BUILDINGS', 'CHILD', 'CHILDREN'),\n",
       "   ('BUILDING', 'BUILDINGS', 'MAN', 'MEN'),\n",
       "   ('BUILDING', 'BUILDINGS', 'ROAD', 'ROADS'),\n",
       "   ('BUILDING', 'BUILDINGS', 'WOMAN', 'WOMEN'),\n",
       "   ('CAR', 'CARS', 'CHILD', 'CHILDREN'),\n",
       "   ('CAR', 'CARS', 'MAN', 'MEN'),\n",
       "   ('CAR', 'CARS', 'ROAD', 'ROADS'),\n",
       "   ('CAR', 'CARS', 'WOMAN', 'WOMEN'),\n",
       "   ('CAR', 'CARS', 'BUILDING', 'BUILDINGS'),\n",
       "   ('CHILD', 'CHILDREN', 'MAN', 'MEN'),\n",
       "   ('CHILD', 'CHILDREN', 'ROAD', 'ROADS'),\n",
       "   ('CHILD', 'CHILDREN', 'WOMAN', 'WOMEN'),\n",
       "   ('CHILD', 'CHILDREN', 'BUILDING', 'BUILDINGS'),\n",
       "   ('CHILD', 'CHILDREN', 'CAR', 'CARS'),\n",
       "   ('MAN', 'MEN', 'ROAD', 'ROADS'),\n",
       "   ('MAN', 'MEN', 'WOMAN', 'WOMEN'),\n",
       "   ('MAN', 'MEN', 'BUILDING', 'BUILDINGS'),\n",
       "   ('MAN', 'MEN', 'CAR', 'CARS'),\n",
       "   ('MAN', 'MEN', 'CHILD', 'CHILDREN'),\n",
       "   ('ROAD', 'ROADS', 'WOMAN', 'WOMEN'),\n",
       "   ('ROAD', 'ROADS', 'BUILDING', 'BUILDINGS'),\n",
       "   ('ROAD', 'ROADS', 'CAR', 'CARS'),\n",
       "   ('ROAD', 'ROADS', 'CHILD', 'CHILDREN'),\n",
       "   ('ROAD', 'ROADS', 'MAN', 'MEN'),\n",
       "   ('WOMAN', 'WOMEN', 'BUILDING', 'BUILDINGS'),\n",
       "   ('WOMAN', 'WOMEN', 'CAR', 'CARS'),\n",
       "   ('WOMAN', 'WOMEN', 'CHILD', 'CHILDREN'),\n",
       "   ('WOMAN', 'WOMEN', 'MAN', 'MEN'),\n",
       "   ('WOMAN', 'WOMEN', 'ROAD', 'ROADS')]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy('../data/raw/questions-words.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ``accuracy`` takes an `optional parameter\n",
    "<http://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec.accuracy>`_\n",
    "``restrict_vocab`` which limits which test examples are to be considered.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the December 2016 release of Gensim we added a better way to evaluate semantic similarity.\n",
    "\n",
    "By default it uses an academic dataset WS-353 but one can create a dataset\n",
    "specific to your business based on it. It contains word pairs together with\n",
    "human-assigned similarity judgments. It measures the relatedness or\n",
    "co-occurrence of two words. For example, 'coast' and 'shore' are very similar\n",
    "as they appear in the same context. At the same time 'clothes' and 'closet'\n",
    "are less similar because they are related but not interchangeable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caihaocui/anaconda3/envs/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `evaluate_word_pairs` (Method will be removed in 4.0.0, use self.wv.evaluate_word_pairs() instead).\n",
      "  \n",
      "2020-04-17 14:52:47,014 : INFO : Pearson correlation coefficient against ../data/raw/wordsim353.tsv: 0.1420\n",
      "2020-04-17 14:52:47,015 : INFO : Spearman rank-order correlation coefficient against ../data/raw/wordsim353.tsv: 0.1612\n",
      "2020-04-17 14:52:47,015 : INFO : Pairs with unknown words ratio: 83.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.14199559050123303, 0.2791410602553877),\n",
       " SpearmanrResult(correlation=0.16115048036198817, pvalue=0.2186723333380953),\n",
       " 83.0028328611898)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate_word_pairs(datapath('../data/raw/wordsim353.tsv'))\n",
    "model.evaluate_word_pairs('../data/raw/wordsim353.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. Important::\n",
    "  Good performance on Google's or WS-353 test set doesn’t mean word2vec will\n",
    "  work well in your application, or vice versa. It’s always best to evaluate\n",
    "  directly on your intended task. For an example of how to use word2vec in a\n",
    "  classifier pipeline, see this `tutorial\n",
    "  <https://github.com/RaRe-Technologies/movie-plots-by-genre>`_.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online training / Resuming training\n",
    "-----------------------------------\n",
    "\n",
    "Advanced users can load a model and continue training it with more sentences\n",
    "and `new vocabulary words <online_w2v_tutorial.ipynb>`_:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:55:04,133 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:55:04,133 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:55:04,133 : INFO : collected 13 word types from a corpus of 13 raw words and 1 sentences\n",
      "2020-04-17 14:55:04,134 : INFO : Updating model with new vocabulary\n",
      "2020-04-17 14:55:04,134 : INFO : New added 0 unique words (0% of original 13) and increased the count of 0 pre-existing words (0% of original 13)\n",
      "2020-04-17 14:55:04,135 : INFO : deleting the raw counts dictionary of 13 items\n",
      "2020-04-17 14:55:04,135 : INFO : sample=0.001 downsamples 0 most-common words\n",
      "2020-04-17 14:55:04,136 : INFO : downsampling leaves estimated 0 word corpus (0.0% of prior 0)\n",
      "2020-04-17 14:55:04,138 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes\n",
      "2020-04-17 14:55:04,138 : INFO : updating layer weights\n",
      "/Users/caihaocui/anaconda3/envs/NLP/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \n",
      "2020-04-17 14:55:04,139 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2020-04-17 14:55:04,140 : INFO : training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:55:04,141 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:55:04,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:55:04,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:55:04,142 : INFO : EPOCH - 1 : training on 13 raw words (4 effective words) took 0.0s, 3167 effective words/s\n",
      "2020-04-17 14:55:04,144 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:55:04,144 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:55:04,145 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:55:04,145 : INFO : EPOCH - 2 : training on 13 raw words (6 effective words) took 0.0s, 5086 effective words/s\n",
      "2020-04-17 14:55:04,146 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:55:04,147 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:55:04,147 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:55:04,147 : INFO : EPOCH - 3 : training on 13 raw words (5 effective words) took 0.0s, 4257 effective words/s\n",
      "2020-04-17 14:55:04,149 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:55:04,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:55:04,150 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:55:04,150 : INFO : EPOCH - 4 : training on 13 raw words (5 effective words) took 0.0s, 4033 effective words/s\n",
      "2020-04-17 14:55:04,152 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:55:04,152 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:55:04,152 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:55:04,153 : INFO : EPOCH - 5 : training on 13 raw words (6 effective words) took 0.0s, 4805 effective words/s\n",
      "2020-04-17 14:55:04,153 : INFO : training on a 65 raw words (26 effective words) took 0.0s, 1950 effective words/s\n",
      "2020-04-17 14:55:04,154 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "temporary_filepath = '../models/gensim-model-Lee Corpus.z'\n",
    "\n",
    "# model = gensim.models.Word2Vec.load(temporary_filepath)\n",
    "\n",
    "model = joblib.load(temporary_filepath)\n",
    "\n",
    "more_sentences = [\n",
    "    ['Advanced', 'users', 'can', 'load', 'a', 'model',\n",
    "     'and', 'continue', 'training', 'it', 'with', 'more', 'sentences']\n",
    "]\n",
    "\n",
    "model.build_vocab(more_sentences, update=True)\n",
    "\n",
    "model.train(more_sentences, total_examples=model.corpus_count, epochs=model.iter)\n",
    "\n",
    "# cleaning up temporary file\n",
    "import os\n",
    "os.remove(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to tweak the ``total_words`` parameter to ``train()``,\n",
    "depending on what learning rate decay you want to simulate.\n",
    "\n",
    "Note that it’s not possible to resume training with models generated by the C\n",
    "tool, ``KeyedVectors.load_word2vec_format()``. You can still use them for\n",
    "querying/similarity, but information vital for training (the vocab tree) is\n",
    "missing there.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loss Computation\n",
    "-------------------------\n",
    "\n",
    "The parameter ``compute_loss`` can be used to toggle computation of loss\n",
    "while training the Word2Vec model. The computed loss is stored in the model\n",
    "attribute ``running_training_loss`` and can be retrieved using the function\n",
    "``get_latest_training_loss`` as follows :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:55:31,578 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:55:31,581 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:55:31,652 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences\n",
      "2020-04-17 14:55:31,652 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:55:31,661 : INFO : effective_min_count=1 retains 6981 unique words (100% of original 6981, drops 0)\n",
      "2020-04-17 14:55:31,662 : INFO : effective_min_count=1 leaves 58152 word corpus (100% of original 58152, drops 0)\n",
      "2020-04-17 14:55:31,676 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2020-04-17 14:55:31,677 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2020-04-17 14:55:31,677 : INFO : downsampling leaves estimated 45723 word corpus (78.6% of prior 58152)\n",
      "2020-04-17 14:55:31,688 : INFO : estimated required memory for 6981 words and 100 dimensions: 9075300 bytes\n",
      "2020-04-17 14:55:31,689 : INFO : resetting layer weights\n",
      "2020-04-17 14:55:32,764 : INFO : training model with 3 workers on 6981 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:55:32,916 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:55:32,933 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:55:32,933 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:55:32,934 : INFO : EPOCH - 1 : training on 58152 raw words (45692 effective words) took 0.2s, 271115 effective words/s\n",
      "2020-04-17 14:55:33,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:55:33,084 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:55:33,090 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:55:33,091 : INFO : EPOCH - 2 : training on 58152 raw words (45642 effective words) took 0.2s, 293160 effective words/s\n",
      "2020-04-17 14:55:33,213 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:55:33,238 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:55:33,239 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:55:33,239 : INFO : EPOCH - 3 : training on 58152 raw words (45727 effective words) took 0.1s, 311514 effective words/s\n",
      "2020-04-17 14:55:33,364 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:55:33,385 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:55:33,388 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:55:33,388 : INFO : EPOCH - 4 : training on 58152 raw words (45648 effective words) took 0.1s, 309157 effective words/s\n",
      "2020-04-17 14:55:33,530 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:55:33,533 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:55:33,536 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:55:33,537 : INFO : EPOCH - 5 : training on 58152 raw words (45700 effective words) took 0.1s, 310434 effective words/s\n",
      "2020-04-17 14:55:33,537 : INFO : training on a 290760 raw words (228409 effective words) took 0.8s, 295643 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376148.875\n"
     ]
    }
   ],
   "source": [
    "# instantiating and training the Word2Vec model\n",
    "model_with_loss = gensim.models.Word2Vec(\n",
    "    sentences,\n",
    "    min_count=1,\n",
    "    compute_loss=True,\n",
    "    hs=0,\n",
    "    sg=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# getting the training loss value\n",
    "training_loss = model_with_loss.get_latest_training_loss()\n",
    "print(training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks\n",
    "----------\n",
    "\n",
    "Let's run some benchmarks to see effect of the training loss computation code\n",
    "on training time.\n",
    "\n",
    "We'll use the following data for the benchmarks:\n",
    "\n",
    "#. Lee Background corpus: included in gensim's test data\n",
    "#. Text8 corpus.  To demonstrate the effect of corpus size, we'll look at the\n",
    "   first 1MB, 10MB, 50MB of the corpus, as well as the entire thing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:56:24,037 : INFO : text8 downloaded\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import gensim.models.word2vec\n",
    "import gensim.downloader as api\n",
    "import smart_open\n",
    "\n",
    "\n",
    "def head(path, size):\n",
    "    with smart_open.open(path) as fin:\n",
    "        return io.StringIO(fin.read(size))\n",
    "\n",
    "\n",
    "def generate_input_data():\n",
    "    lee_path = datapath('lee_background.cor')\n",
    "    ls = gensim.models.word2vec.LineSentence(lee_path)\n",
    "    ls.name = '25kB'\n",
    "    yield ls\n",
    "\n",
    "    text8_path = api.load('text8').fn\n",
    "    labels = ('1MB', '10MB', '50MB', '100MB')\n",
    "    sizes = (1024 ** 2, 10 * 1024 ** 2, 50 * 1024 ** 2, 100 * 1024 ** 2)\n",
    "    for l, s in zip(labels, sizes):\n",
    "        ls = gensim.models.word2vec.LineSentence(head(text8_path, s))\n",
    "        ls.name = l\n",
    "        yield ls\n",
    "\n",
    "\n",
    "input_data = list(generate_input_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare the training time taken for different combinations of input\n",
    "data and model training parameters like ``hs`` and ``sg``.\n",
    "\n",
    "For each combination, we repeat the test several times to obtain the mean and\n",
    "standard deviation of the test duration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:43,589 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:43,591 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:43,607 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:43,608 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:43,614 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:43,614 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:43,619 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:43,619 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:43,620 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:43,623 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:43,623 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:43,910 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:43,945 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:43,946 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:43,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:43,951 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 834257 effective words/s\n",
      "2020-04-17 14:58:43,972 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:43,976 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:43,979 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:43,980 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 1180487 effective words/s\n",
      "2020-04-17 14:58:44,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,003 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,006 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,007 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 1263417 effective words/s\n",
      "2020-04-17 14:58:44,033 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,034 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,038 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,039 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 1133960 effective words/s\n",
      "2020-04-17 14:58:44,066 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,069 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,071 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,071 : INFO : EPOCH - 5 : training on 59890 raw words (32618 effective words) took 0.0s, 1062175 effective words/s\n",
      "2020-04-17 14:58:44,072 : INFO : training on a 299450 raw words (162903 effective words) took 0.2s, 1010275 effective words/s\n",
      "2020-04-17 14:58:44,074 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:44,077 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:44,094 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:44,095 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:44,100 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:44,100 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:44,105 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:44,106 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:44,107 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:44,115 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:44,115 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:44,407 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:44,430 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,434 : INFO : EPOCH - 1 : training on 59890 raw words (32549 effective words) took 0.0s, 1259176 effective words/s\n",
      "2020-04-17 14:58:44,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,461 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,465 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,466 : INFO : EPOCH - 2 : training on 59890 raw words (32604 effective words) took 0.0s, 1072612 effective words/s\n",
      "2020-04-17 14:58:44,489 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,491 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,493 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,494 : INFO : EPOCH - 3 : training on 59890 raw words (32676 effective words) took 0.0s, 1238508 effective words/s\n",
      "2020-04-17 14:58:44,516 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,520 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,522 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,522 : INFO : EPOCH - 4 : training on 59890 raw words (32605 effective words) took 0.0s, 1214043 effective words/s\n",
      "2020-04-17 14:58:44,543 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,545 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,548 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,548 : INFO : EPOCH - 5 : training on 59890 raw words (32405 effective words) took 0.0s, 1320839 effective words/s\n",
      "2020-04-17 14:58:44,549 : INFO : training on a 299450 raw words (162839 effective words) took 0.1s, 1149779 effective words/s\n",
      "2020-04-17 14:58:44,550 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:44,551 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:44,566 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:44,567 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:44,572 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:44,573 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:44,580 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:44,580 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:44,581 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:44,584 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:44,584 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:44,864 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:44,883 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,886 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,888 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1426152 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:44,909 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,912 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,914 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,915 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 1288032 effective words/s\n",
      "2020-04-17 14:58:44,934 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,936 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,939 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,939 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 1422867 effective words/s\n",
      "2020-04-17 14:58:44,963 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,964 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,969 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,969 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 1204881 effective words/s\n",
      "2020-04-17 14:58:44,990 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:44,992 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:44,995 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:44,996 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 1294220 effective words/s\n",
      "2020-04-17 14:58:44,996 : INFO : training on a 299450 raw words (162877 effective words) took 0.1s, 1236520 effective words/s\n",
      "2020-04-17 14:58:44,997 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:44,998 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:45,013 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:45,013 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:45,018 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:45,018 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:45,022 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:45,023 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:45,024 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:45,027 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:45,027 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #0: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 0.46947534879048664, 'train_time_std': 0.016242761213383295}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:45,304 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:45,323 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:45,327 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:45,328 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:45,329 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1388438 effective words/s\n",
      "2020-04-17 14:58:45,354 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:45,355 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:45,359 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:45,360 : INFO : EPOCH - 2 : training on 59890 raw words (32652 effective words) took 0.0s, 1109503 effective words/s\n",
      "2020-04-17 14:58:45,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:45,382 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:45,384 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:45,385 : INFO : EPOCH - 3 : training on 59890 raw words (32579 effective words) took 0.0s, 1380962 effective words/s\n",
      "2020-04-17 14:58:45,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:45,407 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:45,410 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:45,410 : INFO : EPOCH - 4 : training on 59890 raw words (32609 effective words) took 0.0s, 1377685 effective words/s\n",
      "2020-04-17 14:58:45,430 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:45,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:45,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:45,434 : INFO : EPOCH - 5 : training on 59890 raw words (32723 effective words) took 0.0s, 1448668 effective words/s\n",
      "2020-04-17 14:58:45,435 : INFO : training on a 299450 raw words (163106 effective words) took 0.1s, 1255469 effective words/s\n",
      "2020-04-17 14:58:45,436 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:45,436 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:45,451 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:45,451 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:45,456 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:45,457 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:45,461 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:45,462 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:45,462 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:45,465 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:45,465 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:45,744 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:45,762 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:45,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:45,767 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:45,767 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1485274 effective words/s\n",
      "2020-04-17 14:58:45,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:45,788 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:45,791 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:45,792 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 1396638 effective words/s\n",
      "2020-04-17 14:58:45,812 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:45,815 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:45,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:45,817 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 1379237 effective words/s\n",
      "2020-04-17 14:58:45,840 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:45,843 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:45,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:45,848 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 1132103 effective words/s\n",
      "2020-04-17 14:58:45,870 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:45,871 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:45,875 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:45,875 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 1232963 effective words/s\n",
      "2020-04-17 14:58:45,876 : INFO : training on a 299450 raw words (162877 effective words) took 0.1s, 1239798 effective words/s\n",
      "2020-04-17 14:58:45,877 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:45,878 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:45,893 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:45,894 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:45,899 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:45,900 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:45,904 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:45,905 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:45,905 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:45,910 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:45,912 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:46,193 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:46,213 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:46,215 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:46,217 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:46,218 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 1399589 effective words/s\n",
      "2020-04-17 14:58:46,241 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:46,242 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:46,245 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:46,246 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 1235704 effective words/s\n",
      "2020-04-17 14:58:46,265 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:46,268 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:46,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:46,270 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 1395588 effective words/s\n",
      "2020-04-17 14:58:46,291 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:46,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:46,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:46,296 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 1387148 effective words/s\n",
      "2020-04-17 14:58:46,318 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:46,319 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:46,321 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:46,322 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 1381096 effective words/s\n",
      "2020-04-17 14:58:46,322 : INFO : training on a 299450 raw words (162877 effective words) took 0.1s, 1265861 effective words/s\n",
      "2020-04-17 14:58:46,324 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:46,325 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:46,340 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:46,341 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:46,346 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:46,346 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:46,351 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:46,352 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:46,352 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:46,354 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:46,386 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:46,389 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:46,390 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #1: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 0.4421900113423665, 'train_time_std': 0.0035101271553160955}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:46,680 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:46,714 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:46,721 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:46,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:46,727 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 713141 effective words/s\n",
      "2020-04-17 14:58:46,761 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:46,764 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:46,768 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:46,769 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 803783 effective words/s\n",
      "2020-04-17 14:58:46,803 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:46,809 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:46,811 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:46,811 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 791212 effective words/s\n",
      "2020-04-17 14:58:46,846 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:46,847 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:46,851 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:46,852 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 833132 effective words/s\n",
      "2020-04-17 14:58:46,885 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:46,890 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:46,891 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:46,892 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 844985 effective words/s\n",
      "2020-04-17 14:58:46,892 : INFO : training on a 299450 raw words (162877 effective words) took 0.2s, 769082 effective words/s\n",
      "2020-04-17 14:58:46,893 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:46,894 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:46,909 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:46,909 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:46,914 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:46,915 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:46,919 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:46,919 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:46,920 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:46,921 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:46,952 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:46,955 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:46,956 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:47,239 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:47,275 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:47,275 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:47,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:47,279 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 829104 effective words/s\n",
      "2020-04-17 14:58:47,314 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:47,316 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:47,321 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:47,321 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 812165 effective words/s\n",
      "2020-04-17 14:58:47,355 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:47,358 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:47,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:47,363 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 813169 effective words/s\n",
      "2020-04-17 14:58:47,398 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:47,400 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:47,404 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:47,404 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 814771 effective words/s\n",
      "2020-04-17 14:58:47,440 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:47,446 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:47,448 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:47,449 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 776092 effective words/s\n",
      "2020-04-17 14:58:47,449 : INFO : training on a 299450 raw words (162877 effective words) took 0.2s, 777558 effective words/s\n",
      "2020-04-17 14:58:47,452 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:47,453 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:47,468 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:47,469 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:47,475 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:47,476 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:47,481 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:47,481 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:47,482 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:47,483 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:47,512 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:47,515 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:47,515 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:47,796 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:47,829 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:47,834 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:47,836 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:47,837 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 822979 effective words/s\n",
      "2020-04-17 14:58:47,876 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:47,877 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:47,882 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:47,883 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 740478 effective words/s\n",
      "2020-04-17 14:58:47,916 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:47,922 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:47,924 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:47,925 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 806545 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:47,959 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:47,961 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:47,966 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:47,966 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 809798 effective words/s\n",
      "2020-04-17 14:58:48,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:48,005 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:48,011 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:48,012 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 738930 effective words/s\n",
      "2020-04-17 14:58:48,012 : INFO : training on a 299450 raw words (162877 effective words) took 0.2s, 754712 effective words/s\n",
      "2020-04-17 14:58:48,014 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:48,015 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:48,030 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:48,030 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:48,035 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:48,036 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:48,041 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:48,042 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:48,043 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:48,044 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:48,072 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:48,076 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:48,076 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #2: {'train_data': '25kB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 0.563281774520874, 'train_time_std': 0.004205707141329885}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:48,356 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:48,390 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:48,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:48,397 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:48,398 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 800745 effective words/s\n",
      "2020-04-17 14:58:48,432 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:48,441 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:48,443 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:48,443 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 748253 effective words/s\n",
      "2020-04-17 14:58:48,476 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:48,482 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:48,484 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:48,485 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 807549 effective words/s\n",
      "2020-04-17 14:58:48,522 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:48,523 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:48,525 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:48,525 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 839818 effective words/s\n",
      "2020-04-17 14:58:48,558 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:48,560 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:48,563 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:48,564 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 875006 effective words/s\n",
      "2020-04-17 14:58:48,564 : INFO : training on a 299450 raw words (162877 effective words) took 0.2s, 783776 effective words/s\n",
      "2020-04-17 14:58:48,566 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:48,567 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:48,582 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:48,582 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:48,587 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:48,588 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:48,592 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:48,593 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:48,593 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:48,594 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:48,623 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:48,625 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:48,626 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:48,907 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:48,943 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:48,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:48,947 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:48,948 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 834162 effective words/s\n",
      "2020-04-17 14:58:48,981 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:48,985 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:48,988 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:48,989 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 815458 effective words/s\n",
      "2020-04-17 14:58:49,023 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:49,027 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:49,028 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:49,029 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 857019 effective words/s\n",
      "2020-04-17 14:58:49,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:49,065 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:49,069 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:49,069 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 838483 effective words/s\n",
      "2020-04-17 14:58:49,104 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:49,110 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:49,113 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:49,114 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 751185 effective words/s\n",
      "2020-04-17 14:58:49,114 : INFO : training on a 299450 raw words (162877 effective words) took 0.2s, 788505 effective words/s\n",
      "2020-04-17 14:58:49,116 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:49,117 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:49,131 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:49,132 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:49,136 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:49,137 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:49,141 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:49,142 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:49,143 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:49,144 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:49,173 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:49,176 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:49,177 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:49,455 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:49,490 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:49,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:49,499 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:49,499 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.0s, 757006 effective words/s\n",
      "2020-04-17 14:58:49,534 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:49,539 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:49,542 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:49,543 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.0s, 775968 effective words/s\n",
      "2020-04-17 14:58:49,575 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:49,579 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:49,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:49,582 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.0s, 860213 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:49,615 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:49,618 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:49,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:49,623 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.0s, 825782 effective words/s\n",
      "2020-04-17 14:58:49,656 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:49,658 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:49,662 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:49,663 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.0s, 845455 effective words/s\n",
      "2020-04-17 14:58:49,663 : INFO : training on a 299450 raw words (162877 effective words) took 0.2s, 783579 effective words/s\n",
      "2020-04-17 14:58:49,665 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:49,666 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:49,681 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:49,681 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:49,686 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:49,687 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:49,691 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:49,692 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:49,692 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:49,695 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:49,695 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #3: {'train_data': '25kB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 0.5502861340840658, 'train_time_std': 0.0011700468198865938}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:49,976 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:50,037 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:50,038 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:50,041 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:50,042 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 510268 effective words/s\n",
      "2020-04-17 14:58:50,102 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:50,103 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:50,106 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:50,106 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 512501 effective words/s\n",
      "2020-04-17 14:58:50,165 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:50,167 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:50,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:50,172 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 509151 effective words/s\n",
      "2020-04-17 14:58:50,231 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:50,234 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:50,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:50,237 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 515910 effective words/s\n",
      "2020-04-17 14:58:50,296 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:50,297 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:50,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:50,301 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 519943 effective words/s\n",
      "2020-04-17 14:58:50,301 : INFO : training on a 299450 raw words (162877 effective words) took 0.3s, 501515 effective words/s\n",
      "2020-04-17 14:58:50,303 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:50,304 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:50,318 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:50,319 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:50,324 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:50,325 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:50,329 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:50,330 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:50,330 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:50,333 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:50,333 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:50,615 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:50,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:50,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:50,679 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:50,680 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 509286 effective words/s\n",
      "2020-04-17 14:58:50,740 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:50,743 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:50,747 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:50,748 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 491180 effective words/s\n",
      "2020-04-17 14:58:50,807 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:50,809 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:50,813 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:50,814 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 510007 effective words/s\n",
      "2020-04-17 14:58:50,871 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:50,873 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:50,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:50,878 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 516471 effective words/s\n",
      "2020-04-17 14:58:50,936 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:50,938 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:50,942 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:50,943 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 512521 effective words/s\n",
      "2020-04-17 14:58:50,943 : INFO : training on a 299450 raw words (162877 effective words) took 0.3s, 496500 effective words/s\n",
      "2020-04-17 14:58:50,944 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:50,945 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:50,959 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:50,960 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:50,965 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:50,965 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:50,969 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:50,970 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:50,970 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:50,975 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:50,976 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:51,253 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:51,314 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:51,314 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:51,318 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:51,318 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 514881 effective words/s\n",
      "2020-04-17 14:58:51,378 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:51,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:51,383 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:51,384 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 505893 effective words/s\n",
      "2020-04-17 14:58:51,444 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:51,444 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:51,448 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:51,449 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 516628 effective words/s\n",
      "2020-04-17 14:58:51,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:51,513 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:51,518 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:51,518 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 479117 effective words/s\n",
      "2020-04-17 14:58:51,581 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:51,584 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:51,588 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:51,589 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 471630 effective words/s\n",
      "2020-04-17 14:58:51,589 : INFO : training on a 299450 raw words (162877 effective words) took 0.3s, 486049 effective words/s\n",
      "2020-04-17 14:58:51,591 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:51,592 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:51,607 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:51,608 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:51,613 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:51,613 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:51,618 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:51,619 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:51,619 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:51,622 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:51,623 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #4: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 0.6418556372324625, 'train_time_std': 0.0035530302350750237}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:51,906 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:51,967 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:51,971 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:51,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:51,975 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 489852 effective words/s\n",
      "2020-04-17 14:58:52,036 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:52,036 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:52,039 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:52,040 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 511585 effective words/s\n",
      "2020-04-17 14:58:52,098 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:52,100 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:52,104 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:52,105 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 511533 effective words/s\n",
      "2020-04-17 14:58:52,164 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:52,167 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:52,170 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:52,171 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 503600 effective words/s\n",
      "2020-04-17 14:58:52,231 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:52,233 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:52,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:52,237 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 506126 effective words/s\n",
      "2020-04-17 14:58:52,237 : INFO : training on a 299450 raw words (162877 effective words) took 0.3s, 492633 effective words/s\n",
      "2020-04-17 14:58:52,239 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:52,240 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:52,255 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:52,255 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:52,261 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:52,261 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:52,266 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:52,267 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:52,267 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:52,271 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:52,273 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:52,558 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:52,616 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:52,617 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:52,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:52,622 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 515792 effective words/s\n",
      "2020-04-17 14:58:52,681 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:52,683 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:52,686 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:52,687 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 515463 effective words/s\n",
      "2020-04-17 14:58:52,745 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:52,748 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:52,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:52,752 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 511580 effective words/s\n",
      "2020-04-17 14:58:52,842 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:52,904 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:52,906 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:52,906 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.2s, 213003 effective words/s\n",
      "2020-04-17 14:58:52,968 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:52,970 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:52,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:52,975 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 485164 effective words/s\n",
      "2020-04-17 14:58:52,975 : INFO : training on a 299450 raw words (162877 effective words) took 0.4s, 390570 effective words/s\n",
      "2020-04-17 14:58:52,976 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:52,977 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:52,992 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:52,993 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:52,998 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:52,998 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:53,003 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:53,004 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:53,005 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:53,010 : INFO : estimated required memory for 1762 words and 100 dimensions: 2290600 bytes\n",
      "2020-04-17 14:58:53,010 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:53,323 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:53,385 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:53,386 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:53,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:53,392 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 490276 effective words/s\n",
      "2020-04-17 14:58:53,460 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:53,461 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:53,464 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:53,464 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 465073 effective words/s\n",
      "2020-04-17 14:58:53,533 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:53,536 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:53,543 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:53,544 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 420670 effective words/s\n",
      "2020-04-17 14:58:53,612 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:53,615 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:53,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:53,626 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 403632 effective words/s\n",
      "2020-04-17 14:58:53,695 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:53,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:53,706 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:53,707 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 415942 effective words/s\n",
      "2020-04-17 14:58:53,708 : INFO : training on a 299450 raw words (162877 effective words) took 0.4s, 424655 effective words/s\n",
      "2020-04-17 14:58:53,710 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:53,711 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:53,732 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:53,732 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:53,738 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:53,740 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:53,746 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:53,747 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:53,747 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:53,749 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:53,783 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:53,786 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:53,786 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #5: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 0.7063467502593994, 'train_time_std': 0.04149649974900909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:54,205 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:54,385 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:54,399 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:54,400 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:54,400 : INFO : EPOCH - 1 : training on 59890 raw words (32528 effective words) took 0.2s, 169635 effective words/s\n",
      "2020-04-17 14:58:54,537 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:54,538 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:54,545 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:54,545 : INFO : EPOCH - 2 : training on 59890 raw words (32557 effective words) took 0.1s, 228937 effective words/s\n",
      "2020-04-17 14:58:54,677 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:54,679 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:54,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:54,687 : INFO : EPOCH - 3 : training on 59890 raw words (32654 effective words) took 0.1s, 232282 effective words/s\n",
      "2020-04-17 14:58:54,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:54,816 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:54,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:54,827 : INFO : EPOCH - 4 : training on 59890 raw words (32527 effective words) took 0.1s, 236376 effective words/s\n",
      "2020-04-17 14:58:54,951 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:54,953 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:54,959 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:54,960 : INFO : EPOCH - 5 : training on 59890 raw words (32640 effective words) took 0.1s, 248771 effective words/s\n",
      "2020-04-17 14:58:54,961 : INFO : training on a 299450 raw words (162906 effective words) took 0.8s, 216139 effective words/s\n",
      "2020-04-17 14:58:54,962 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:54,963 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:54,978 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:54,978 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:54,984 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:54,984 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:54,988 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:54,989 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:54,990 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:54,993 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:55,023 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:55,027 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:55,027 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:55,305 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:55,425 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:55,426 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:55,432 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:55,433 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 257684 effective words/s\n",
      "2020-04-17 14:58:55,555 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:55,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:55,561 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:55,562 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 254869 effective words/s\n",
      "2020-04-17 14:58:55,684 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:55,685 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:55,694 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:55,694 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 249094 effective words/s\n",
      "2020-04-17 14:58:55,817 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:55,819 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:55,825 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:55,826 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 250434 effective words/s\n",
      "2020-04-17 14:58:55,949 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:55,950 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:55,956 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:55,957 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 252484 effective words/s\n",
      "2020-04-17 14:58:55,957 : INFO : training on a 299450 raw words (162877 effective words) took 0.7s, 249749 effective words/s\n",
      "2020-04-17 14:58:55,961 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:55,962 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:55,979 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:55,979 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:55,984 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:55,985 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:55,989 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:55,990 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:55,990 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:55,992 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:56,023 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:56,026 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:56,027 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:56,310 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:56,433 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:56,435 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:56,440 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:56,441 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 256720 effective words/s\n",
      "2020-04-17 14:58:56,563 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:56,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:56,578 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:56,579 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 239005 effective words/s\n",
      "2020-04-17 14:58:56,698 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:56,699 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:56,709 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:56,709 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 252352 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:56,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:56,829 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:56,834 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:56,834 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 264006 effective words/s\n",
      "2020-04-17 14:58:56,956 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:56,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:56,963 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:56,963 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 255736 effective words/s\n",
      "2020-04-17 14:58:56,963 : INFO : training on a 299450 raw words (162877 effective words) took 0.7s, 249890 effective words/s\n",
      "2020-04-17 14:58:56,965 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:56,966 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:56,982 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:56,983 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:56,988 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:56,989 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:56,993 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:56,994 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:56,994 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:56,995 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:57,026 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:57,028 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:57,029 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #6: {'train_data': '25kB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 1.0849557717641194, 'train_time_std': 0.1178281414835077}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:57,308 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:57,426 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:57,427 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:57,430 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:57,430 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 269547 effective words/s\n",
      "2020-04-17 14:58:57,547 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:57,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:57,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:57,556 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 262740 effective words/s\n",
      "2020-04-17 14:58:57,672 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:57,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:57,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:57,680 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 264082 effective words/s\n",
      "2020-04-17 14:58:57,797 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:57,798 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:57,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:57,804 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 267479 effective words/s\n",
      "2020-04-17 14:58:57,924 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:57,926 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:57,932 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:57,932 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 256652 effective words/s\n",
      "2020-04-17 14:58:57,932 : INFO : training on a 299450 raw words (162877 effective words) took 0.6s, 261168 effective words/s\n",
      "2020-04-17 14:58:57,934 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:57,935 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:57,951 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:57,952 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:57,958 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:57,959 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:57,963 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:57,964 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:57,964 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:57,965 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:57,996 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:57,999 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:57,999 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:58,291 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:58,415 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:58,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:58,421 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:58,422 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 252859 effective words/s\n",
      "2020-04-17 14:58:58,545 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:58,547 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:58,552 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:58,553 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 250765 effective words/s\n",
      "2020-04-17 14:58:58,673 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:58,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:58,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:58,681 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 258233 effective words/s\n",
      "2020-04-17 14:58:58,800 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:58,801 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:58,814 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:58,814 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 247096 effective words/s\n",
      "2020-04-17 14:58:58,941 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:58,946 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:58,951 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:58,952 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 239581 effective words/s\n",
      "2020-04-17 14:58:58,953 : INFO : training on a 299450 raw words (162877 effective words) took 0.7s, 246584 effective words/s\n",
      "2020-04-17 14:58:58,957 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:58,959 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:58:58,977 : INFO : collected 10781 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2020-04-17 14:58:58,978 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:58:58,982 : INFO : effective_min_count=5 retains 1762 unique words (16% of original 10781, drops 9019)\n",
      "2020-04-17 14:58:58,983 : INFO : effective_min_count=5 leaves 46084 word corpus (76% of original 59890, drops 13806)\n",
      "2020-04-17 14:58:58,987 : INFO : deleting the raw counts dictionary of 10781 items\n",
      "2020-04-17 14:58:58,988 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-04-17 14:58:58,989 : INFO : downsampling leaves estimated 32610 word corpus (70.8% of prior 46084)\n",
      "2020-04-17 14:58:58,990 : INFO : constructing a huffman tree from 1762 words\n",
      "2020-04-17 14:58:59,023 : INFO : built huffman tree with maximum node depth 13\n",
      "2020-04-17 14:58:59,029 : INFO : estimated required memory for 1762 words and 100 dimensions: 3347800 bytes\n",
      "2020-04-17 14:58:59,030 : INFO : resetting layer weights\n",
      "2020-04-17 14:58:59,309 : INFO : training model with 3 workers on 1762 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:58:59,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:59,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:59,442 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:59,443 : INFO : EPOCH - 1 : training on 59890 raw words (32543 effective words) took 0.1s, 245872 effective words/s\n",
      "2020-04-17 14:58:59,562 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:59,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:59,572 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:59,572 : INFO : EPOCH - 2 : training on 59890 raw words (32552 effective words) took 0.1s, 254181 effective words/s\n",
      "2020-04-17 14:58:59,697 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:59,702 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:59,710 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:59,711 : INFO : EPOCH - 3 : training on 59890 raw words (32603 effective words) took 0.1s, 238432 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:58:59,830 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:59,830 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:59,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:59,838 : INFO : EPOCH - 4 : training on 59890 raw words (32587 effective words) took 0.1s, 259401 effective words/s\n",
      "2020-04-17 14:58:59,957 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:58:59,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:58:59,961 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:58:59,961 : INFO : EPOCH - 5 : training on 59890 raw words (32592 effective words) took 0.1s, 267096 effective words/s\n",
      "2020-04-17 14:58:59,962 : INFO : training on a 299450 raw words (162877 effective words) took 0.7s, 249801 effective words/s\n",
      "2020-04-17 14:58:59,964 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:58:59,990 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:00,025 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:00,026 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:00,035 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:00,035 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:00,047 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:00,048 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:00,049 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:00,056 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:00,057 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #7: {'train_data': '25kB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 0.9994269212086996, 'train_time_std': 0.022374977285268764}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:00,703 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:00,777 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:00,781 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:00,782 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:00,782 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.1s, 1621173 effective words/s\n",
      "2020-04-17 14:59:00,862 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:00,866 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:00,871 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:00,872 : INFO : EPOCH - 2 : training on 175599 raw words (110156 effective words) took 0.1s, 1426117 effective words/s\n",
      "2020-04-17 14:59:00,973 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:00,977 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:00,977 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:00,978 : INFO : EPOCH - 3 : training on 175599 raw words (110147 effective words) took 0.1s, 1331891 effective words/s\n",
      "2020-04-17 14:59:01,057 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:01,060 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:01,062 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:01,062 : INFO : EPOCH - 4 : training on 175599 raw words (110288 effective words) took 0.1s, 1557869 effective words/s\n",
      "2020-04-17 14:59:01,143 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:01,147 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:01,149 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:01,149 : INFO : EPOCH - 5 : training on 175599 raw words (110258 effective words) took 0.1s, 1477173 effective words/s\n",
      "2020-04-17 14:59:01,149 : INFO : training on a 877995 raw words (551133 effective words) took 0.4s, 1236443 effective words/s\n",
      "2020-04-17 14:59:01,151 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:01,162 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:01,194 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:01,194 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:01,204 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:01,205 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:01,217 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:01,218 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:01,219 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:01,226 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:01,227 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:01,882 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:01,958 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:01,961 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:01,963 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:01,964 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 1601924 effective words/s\n",
      "2020-04-17 14:59:02,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:02,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:02,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:02,045 : INFO : EPOCH - 2 : training on 175599 raw words (110214 effective words) took 0.1s, 1580743 effective words/s\n",
      "2020-04-17 14:59:02,122 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:02,125 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:02,127 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:02,128 : INFO : EPOCH - 3 : training on 175599 raw words (110156 effective words) took 0.1s, 1554242 effective words/s\n",
      "2020-04-17 14:59:02,203 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:02,206 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:02,207 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:02,208 : INFO : EPOCH - 4 : training on 175599 raw words (110155 effective words) took 0.1s, 1619683 effective words/s\n",
      "2020-04-17 14:59:02,282 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:02,286 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:02,287 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:02,287 : INFO : EPOCH - 5 : training on 175599 raw words (110257 effective words) took 0.1s, 1637419 effective words/s\n",
      "2020-04-17 14:59:02,288 : INFO : training on a 877995 raw words (551126 effective words) took 0.4s, 1360715 effective words/s\n",
      "2020-04-17 14:59:02,290 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:02,300 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:02,332 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:02,333 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:02,344 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:02,345 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:02,354 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:02,355 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:02,356 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:02,363 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:02,363 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:03,008 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:03,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:03,090 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:03,090 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:03,091 : INFO : EPOCH - 1 : training on 175599 raw words (110124 effective words) took 0.1s, 1582577 effective words/s\n",
      "2020-04-17 14:59:03,167 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:03,168 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:03,169 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:03,170 : INFO : EPOCH - 2 : training on 175599 raw words (110192 effective words) took 0.1s, 1622674 effective words/s\n",
      "2020-04-17 14:59:03,244 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:03,246 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:03,247 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:03,248 : INFO : EPOCH - 3 : training on 175599 raw words (110317 effective words) took 0.1s, 1684611 effective words/s\n",
      "2020-04-17 14:59:03,324 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:03,328 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:03,329 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:03,330 : INFO : EPOCH - 4 : training on 175599 raw words (110190 effective words) took 0.1s, 1566767 effective words/s\n",
      "2020-04-17 14:59:03,407 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:03,411 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:03,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:03,412 : INFO : EPOCH - 5 : training on 175599 raw words (110080 effective words) took 0.1s, 1576637 effective words/s\n",
      "2020-04-17 14:59:03,412 : INFO : training on a 877995 raw words (550903 effective words) took 0.4s, 1364860 effective words/s\n",
      "2020-04-17 14:59:03,414 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:03,426 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:03,457 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:03,458 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:03,467 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:03,468 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:03,476 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:03,478 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:03,479 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:03,485 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:03,486 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #8: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 1.1500287055969238, 'train_time_std': 0.027173434297282157}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:04,135 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:04,206 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:04,208 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:04,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:04,210 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.1s, 1753864 effective words/s\n",
      "2020-04-17 14:59:04,291 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:04,295 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:04,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:04,297 : INFO : EPOCH - 2 : training on 175599 raw words (110178 effective words) took 0.1s, 1462118 effective words/s\n",
      "2020-04-17 14:59:04,375 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:04,378 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:04,379 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:04,379 : INFO : EPOCH - 3 : training on 175599 raw words (110145 effective words) took 0.1s, 1666496 effective words/s\n",
      "2020-04-17 14:59:04,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:04,457 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:04,459 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:04,459 : INFO : EPOCH - 4 : training on 175599 raw words (110114 effective words) took 0.1s, 1653793 effective words/s\n",
      "2020-04-17 14:59:04,533 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:04,535 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:04,536 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:04,536 : INFO : EPOCH - 5 : training on 175599 raw words (110064 effective words) took 0.1s, 1671606 effective words/s\n",
      "2020-04-17 14:59:04,536 : INFO : training on a 877995 raw words (550495 effective words) took 0.4s, 1372729 effective words/s\n",
      "2020-04-17 14:59:04,538 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:04,548 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:04,577 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:04,578 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:04,587 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:04,588 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:04,596 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:04,598 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:04,598 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:04,605 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:04,605 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:05,245 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:05,320 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:05,324 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:05,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:05,325 : INFO : EPOCH - 1 : training on 175599 raw words (110202 effective words) took 0.1s, 1677158 effective words/s\n",
      "2020-04-17 14:59:05,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:05,403 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:05,403 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:05,404 : INFO : EPOCH - 2 : training on 175599 raw words (110115 effective words) took 0.1s, 1661608 effective words/s\n",
      "2020-04-17 14:59:05,479 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:05,481 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:05,481 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:05,482 : INFO : EPOCH - 3 : training on 175599 raw words (110270 effective words) took 0.1s, 1688208 effective words/s\n",
      "2020-04-17 14:59:05,551 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:05,554 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:05,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:05,556 : INFO : EPOCH - 4 : training on 175599 raw words (110118 effective words) took 0.1s, 1768524 effective words/s\n",
      "2020-04-17 14:59:05,624 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:05,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:05,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:05,628 : INFO : EPOCH - 5 : training on 175599 raw words (110199 effective words) took 0.1s, 1823228 effective words/s\n",
      "2020-04-17 14:59:05,629 : INFO : training on a 877995 raw words (550904 effective words) took 0.4s, 1439178 effective words/s\n",
      "2020-04-17 14:59:05,630 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:05,641 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:05,669 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:05,669 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:05,679 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:05,679 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:05,688 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:05,692 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:05,693 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:05,699 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:05,700 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:06,345 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:06,422 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:06,426 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:06,426 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:06,427 : INFO : EPOCH - 1 : training on 175599 raw words (110086 effective words) took 0.1s, 1616114 effective words/s\n",
      "2020-04-17 14:59:06,503 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:06,507 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:06,508 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:06,508 : INFO : EPOCH - 2 : training on 175599 raw words (110309 effective words) took 0.1s, 1572219 effective words/s\n",
      "2020-04-17 14:59:06,578 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:06,580 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:06,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:06,582 : INFO : EPOCH - 3 : training on 175599 raw words (110307 effective words) took 0.1s, 1801890 effective words/s\n",
      "2020-04-17 14:59:06,651 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:06,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:06,656 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:06,656 : INFO : EPOCH - 4 : training on 175599 raw words (110428 effective words) took 0.1s, 1765462 effective words/s\n",
      "2020-04-17 14:59:06,726 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:06,728 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:06,729 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:06,730 : INFO : EPOCH - 5 : training on 175599 raw words (110382 effective words) took 0.1s, 1794707 effective words/s\n",
      "2020-04-17 14:59:06,730 : INFO : training on a 877995 raw words (551512 effective words) took 0.4s, 1433128 effective words/s\n",
      "2020-04-17 14:59:06,732 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:06,742 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:06,770 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:06,771 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:06,780 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:06,781 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:06,790 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:06,791 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:06,792 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:06,795 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:06,867 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:06,872 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:06,873 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #9: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 1.1058674653371174, 'train_time_std': 0.013163796722582029}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:07,520 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:07,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:07,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:07,660 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:07,661 : INFO : EPOCH - 1 : training on 175599 raw words (110202 effective words) took 0.1s, 857523 effective words/s\n",
      "2020-04-17 14:59:07,784 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:07,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:07,796 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:07,797 : INFO : EPOCH - 2 : training on 175599 raw words (110115 effective words) took 0.1s, 891692 effective words/s\n",
      "2020-04-17 14:59:07,926 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:07,928 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:07,933 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:07,933 : INFO : EPOCH - 3 : training on 175599 raw words (110227 effective words) took 0.1s, 885726 effective words/s\n",
      "2020-04-17 14:59:08,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:08,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:08,069 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:08,070 : INFO : EPOCH - 4 : training on 175599 raw words (110332 effective words) took 0.1s, 891022 effective words/s\n",
      "2020-04-17 14:59:08,194 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:08,199 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:08,203 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:08,204 : INFO : EPOCH - 5 : training on 175599 raw words (110211 effective words) took 0.1s, 903188 effective words/s\n",
      "2020-04-17 14:59:08,204 : INFO : training on a 877995 raw words (551087 effective words) took 0.7s, 805990 effective words/s\n",
      "2020-04-17 14:59:08,206 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:08,216 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:08,245 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:08,246 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:08,255 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:08,256 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:08,265 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:08,266 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:08,266 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:08,271 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:08,344 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:08,348 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:08,349 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:09,002 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:09,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:09,132 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:09,136 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:09,136 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 901159 effective words/s\n",
      "2020-04-17 14:59:09,263 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:09,269 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:09,273 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:09,274 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.1s, 873321 effective words/s\n",
      "2020-04-17 14:59:09,400 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:09,409 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:09,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:09,414 : INFO : EPOCH - 3 : training on 175599 raw words (110352 effective words) took 0.1s, 860910 effective words/s\n",
      "2020-04-17 14:59:09,537 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:09,541 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:09,545 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:09,546 : INFO : EPOCH - 4 : training on 175599 raw words (110129 effective words) took 0.1s, 929394 effective words/s\n",
      "2020-04-17 14:59:09,668 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:09,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:09,675 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:09,676 : INFO : EPOCH - 5 : training on 175599 raw words (110271 effective words) took 0.1s, 934623 effective words/s\n",
      "2020-04-17 14:59:09,676 : INFO : training on a 877995 raw words (551163 effective words) took 0.7s, 818827 effective words/s\n",
      "2020-04-17 14:59:09,679 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:09,690 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:09,720 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:09,720 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:09,730 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:09,730 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:09,740 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:09,741 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:09,742 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:09,745 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:09,819 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:09,827 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:09,828 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:10,484 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:10,625 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:10,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:10,637 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:10,638 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 754293 effective words/s\n",
      "2020-04-17 14:59:10,765 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:10,773 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:10,778 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:10,778 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.1s, 857080 effective words/s\n",
      "2020-04-17 14:59:10,904 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:10,911 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:10,916 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:10,917 : INFO : EPOCH - 3 : training on 175599 raw words (110352 effective words) took 0.1s, 886643 effective words/s\n",
      "2020-04-17 14:59:11,044 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:11,052 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:11,057 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:11,058 : INFO : EPOCH - 4 : training on 175599 raw words (110233 effective words) took 0.1s, 863029 effective words/s\n",
      "2020-04-17 14:59:11,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:11,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:11,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:11,200 : INFO : EPOCH - 5 : training on 175599 raw words (110132 effective words) took 0.1s, 851833 effective words/s\n",
      "2020-04-17 14:59:11,201 : INFO : training on a 877995 raw words (551128 effective words) took 0.7s, 769815 effective words/s\n",
      "2020-04-17 14:59:11,205 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:11,215 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:11,246 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:11,247 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:11,256 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:11,257 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:11,266 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:11,267 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:11,267 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:11,272 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:11,346 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:11,351 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:11,351 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #10: {'train_data': '1MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 1.4909920692443848, 'train_time_std': 0.024463411032697953}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:12,003 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:12,127 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:12,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:12,134 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:12,134 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.1s, 919642 effective words/s\n",
      "2020-04-17 14:59:12,258 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:12,265 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:12,267 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:12,267 : INFO : EPOCH - 2 : training on 175599 raw words (110182 effective words) took 0.1s, 907933 effective words/s\n",
      "2020-04-17 14:59:12,389 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:12,397 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:12,400 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:12,400 : INFO : EPOCH - 3 : training on 175599 raw words (110325 effective words) took 0.1s, 912179 effective words/s\n",
      "2020-04-17 14:59:12,521 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:12,527 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:12,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:12,530 : INFO : EPOCH - 4 : training on 175599 raw words (110336 effective words) took 0.1s, 936558 effective words/s\n",
      "2020-04-17 14:59:12,654 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:12,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:12,664 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:12,664 : INFO : EPOCH - 5 : training on 175599 raw words (110291 effective words) took 0.1s, 900854 effective words/s\n",
      "2020-04-17 14:59:12,665 : INFO : training on a 877995 raw words (551128 effective words) took 0.7s, 833256 effective words/s\n",
      "2020-04-17 14:59:12,669 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:12,679 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:12,708 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:12,708 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:12,717 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:12,718 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:12,728 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:12,729 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:12,729 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:12,732 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:12,806 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:12,811 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:12,812 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:13,458 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:13,579 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:13,588 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:13,591 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:13,591 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.1s, 906092 effective words/s\n",
      "2020-04-17 14:59:13,718 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:13,719 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:13,724 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:13,725 : INFO : EPOCH - 2 : training on 175599 raw words (110178 effective words) took 0.1s, 916081 effective words/s\n",
      "2020-04-17 14:59:13,844 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:13,854 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:13,857 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:13,857 : INFO : EPOCH - 3 : training on 175599 raw words (110145 effective words) took 0.1s, 911142 effective words/s\n",
      "2020-04-17 14:59:13,986 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:13,990 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:13,991 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:13,991 : INFO : EPOCH - 4 : training on 175599 raw words (110095 effective words) took 0.1s, 904727 effective words/s\n",
      "2020-04-17 14:59:14,114 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:14,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:14,123 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:14,124 : INFO : EPOCH - 5 : training on 175599 raw words (110138 effective words) took 0.1s, 913771 effective words/s\n",
      "2020-04-17 14:59:14,124 : INFO : training on a 877995 raw words (550550 effective words) took 0.7s, 827499 effective words/s\n",
      "2020-04-17 14:59:14,128 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:14,140 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:14,172 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:14,172 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:14,182 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:14,182 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:14,192 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:14,193 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:14,194 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:14,197 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:14,271 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:14,276 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:14,277 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:14,923 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:15,059 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:15,066 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:15,069 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:15,070 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.1s, 812716 effective words/s\n",
      "2020-04-17 14:59:15,198 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:15,204 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:15,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:15,209 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.1s, 863830 effective words/s\n",
      "2020-04-17 14:59:15,339 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:15,345 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:15,347 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:15,347 : INFO : EPOCH - 3 : training on 175599 raw words (109913 effective words) took 0.1s, 884991 effective words/s\n",
      "2020-04-17 14:59:15,476 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:15,478 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:15,481 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:15,481 : INFO : EPOCH - 4 : training on 175599 raw words (110284 effective words) took 0.1s, 905940 effective words/s\n",
      "2020-04-17 14:59:15,608 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:15,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:15,613 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:15,613 : INFO : EPOCH - 5 : training on 175599 raw words (110445 effective words) took 0.1s, 915664 effective words/s\n",
      "2020-04-17 14:59:15,614 : INFO : training on a 877995 raw words (551053 effective words) took 0.7s, 797860 effective words/s\n",
      "2020-04-17 14:59:15,618 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:15,629 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:15,661 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:15,661 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:15,671 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:15,672 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:15,681 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:15,682 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:15,682 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:15,689 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:15,690 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #11: {'train_data': '1MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 1.4708325862884521, 'train_time_std': 0.013612271737445957}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:16,332 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:16,547 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:16,553 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:16,559 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:16,559 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.2s, 510674 effective words/s\n",
      "2020-04-17 14:59:16,771 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:16,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:16,784 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:16,784 : INFO : EPOCH - 2 : training on 175599 raw words (110177 effective words) took 0.2s, 520576 effective words/s\n",
      "2020-04-17 14:59:17,002 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:17,003 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:17,014 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:17,015 : INFO : EPOCH - 3 : training on 175599 raw words (110292 effective words) took 0.2s, 508327 effective words/s\n",
      "2020-04-17 14:59:17,224 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:17,228 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:17,233 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:17,234 : INFO : EPOCH - 4 : training on 175599 raw words (110180 effective words) took 0.2s, 533387 effective words/s\n",
      "2020-04-17 14:59:17,444 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:17,448 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:17,457 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:17,458 : INFO : EPOCH - 5 : training on 175599 raw words (110449 effective words) took 0.2s, 520396 effective words/s\n",
      "2020-04-17 14:59:17,458 : INFO : training on a 877995 raw words (551092 effective words) took 1.1s, 489732 effective words/s\n",
      "2020-04-17 14:59:17,461 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:17,474 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:17,504 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:17,505 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:17,514 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:17,515 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:17,524 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:17,525 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:17,525 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:17,532 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:17,533 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:18,168 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:18,377 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:18,383 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:18,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:18,387 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.2s, 530108 effective words/s\n",
      "2020-04-17 14:59:18,600 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:18,605 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:18,610 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:18,610 : INFO : EPOCH - 2 : training on 175599 raw words (110105 effective words) took 0.2s, 520599 effective words/s\n",
      "2020-04-17 14:59:18,822 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:18,825 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:18,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:18,832 : INFO : EPOCH - 3 : training on 175599 raw words (110301 effective words) took 0.2s, 525454 effective words/s\n",
      "2020-04-17 14:59:19,040 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:19,046 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:19,052 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:19,052 : INFO : EPOCH - 4 : training on 175599 raw words (110247 effective words) took 0.2s, 529317 effective words/s\n",
      "2020-04-17 14:59:19,265 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:19,270 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:19,275 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:19,276 : INFO : EPOCH - 5 : training on 175599 raw words (110237 effective words) took 0.2s, 520357 effective words/s\n",
      "2020-04-17 14:59:19,276 : INFO : training on a 877995 raw words (550884 effective words) took 1.1s, 497322 effective words/s\n",
      "2020-04-17 14:59:19,278 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:19,288 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:19,318 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:19,319 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:19,328 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:19,329 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:19,339 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:19,340 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:19,340 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:19,347 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:19,347 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:19,981 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:20,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:20,199 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:20,203 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:20,204 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.2s, 523463 effective words/s\n",
      "2020-04-17 14:59:20,411 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:20,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:20,424 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:20,424 : INFO : EPOCH - 2 : training on 175599 raw words (110067 effective words) took 0.2s, 524126 effective words/s\n",
      "2020-04-17 14:59:20,637 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:20,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:20,647 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:20,648 : INFO : EPOCH - 3 : training on 175599 raw words (109913 effective words) took 0.2s, 524937 effective words/s\n",
      "2020-04-17 14:59:20,856 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:20,863 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:20,867 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:20,868 : INFO : EPOCH - 4 : training on 175599 raw words (110284 effective words) took 0.2s, 530668 effective words/s\n",
      "2020-04-17 14:59:21,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:21,080 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:21,090 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:21,091 : INFO : EPOCH - 5 : training on 175599 raw words (110128 effective words) took 0.2s, 520804 effective words/s\n",
      "2020-04-17 14:59:21,091 : INFO : training on a 877995 raw words (550736 effective words) took 1.1s, 496405 effective words/s\n",
      "2020-04-17 14:59:21,093 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:21,105 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:21,133 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:21,134 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:21,145 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:21,146 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:21,155 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:21,157 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:21,157 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:21,164 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:21,165 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #12: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 1.8248923619588215, 'train_time_std': 0.013058244416970654}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:21,812 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:22,019 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:22,023 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:22,027 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:22,028 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.2s, 536314 effective words/s\n",
      "2020-04-17 14:59:22,234 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:22,240 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:22,245 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:22,245 : INFO : EPOCH - 2 : training on 175599 raw words (110105 effective words) took 0.2s, 535263 effective words/s\n",
      "2020-04-17 14:59:22,451 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:22,455 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:22,463 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:22,464 : INFO : EPOCH - 3 : training on 175599 raw words (110001 effective words) took 0.2s, 532053 effective words/s\n",
      "2020-04-17 14:59:22,668 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:22,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:22,678 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:22,679 : INFO : EPOCH - 4 : training on 175599 raw words (110202 effective words) took 0.2s, 541696 effective words/s\n",
      "2020-04-17 14:59:22,888 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:22,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:22,899 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:22,900 : INFO : EPOCH - 5 : training on 175599 raw words (110104 effective words) took 0.2s, 527136 effective words/s\n",
      "2020-04-17 14:59:22,900 : INFO : training on a 877995 raw words (550406 effective words) took 1.1s, 506008 effective words/s\n",
      "2020-04-17 14:59:22,902 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:22,912 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:22,942 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:22,942 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:22,952 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:22,952 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:22,961 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:22,963 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:22,963 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:22,972 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:22,972 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:23,606 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:23,818 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:23,825 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:23,829 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:23,829 : INFO : EPOCH - 1 : training on 175599 raw words (110344 effective words) took 0.2s, 524194 effective words/s\n",
      "2020-04-17 14:59:24,035 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:24,044 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:24,046 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:24,047 : INFO : EPOCH - 2 : training on 175599 raw words (110115 effective words) took 0.2s, 534503 effective words/s\n",
      "2020-04-17 14:59:24,255 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:24,257 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:24,266 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:24,266 : INFO : EPOCH - 3 : training on 175599 raw words (110076 effective words) took 0.2s, 529211 effective words/s\n",
      "2020-04-17 14:59:24,472 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:24,476 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:24,482 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:24,482 : INFO : EPOCH - 4 : training on 175599 raw words (110172 effective words) took 0.2s, 538235 effective words/s\n",
      "2020-04-17 14:59:24,692 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:24,694 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:24,701 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:24,702 : INFO : EPOCH - 5 : training on 175599 raw words (110348 effective words) took 0.2s, 529970 effective words/s\n",
      "2020-04-17 14:59:24,702 : INFO : training on a 877995 raw words (551055 effective words) took 1.1s, 503283 effective words/s\n",
      "2020-04-17 14:59:24,704 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:24,714 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:24,744 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:24,745 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:24,754 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:24,755 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:24,764 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:24,765 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:24,766 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:24,775 : INFO : estimated required memory for 4125 words and 100 dimensions: 5362500 bytes\n",
      "2020-04-17 14:59:24,776 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:25,414 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:25,623 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:25,625 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:25,633 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:25,634 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.2s, 527441 effective words/s\n",
      "2020-04-17 14:59:25,842 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:25,843 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:25,851 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:25,851 : INFO : EPOCH - 2 : training on 175599 raw words (110105 effective words) took 0.2s, 535306 effective words/s\n",
      "2020-04-17 14:59:26,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:26,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:26,073 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:26,073 : INFO : EPOCH - 3 : training on 175599 raw words (109961 effective words) took 0.2s, 520472 effective words/s\n",
      "2020-04-17 14:59:26,281 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:26,288 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:26,292 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:26,292 : INFO : EPOCH - 4 : training on 175599 raw words (110184 effective words) took 0.2s, 532419 effective words/s\n",
      "2020-04-17 14:59:26,500 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:26,504 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:26,512 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:26,513 : INFO : EPOCH - 5 : training on 175599 raw words (110174 effective words) took 0.2s, 526822 effective words/s\n",
      "2020-04-17 14:59:26,513 : INFO : training on a 877995 raw words (550418 effective words) took 1.1s, 500913 effective words/s\n",
      "2020-04-17 14:59:26,515 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:26,526 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:26,557 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:26,557 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:26,567 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:26,569 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:26,578 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:26,579 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:26,579 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:26,582 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:26,655 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:26,660 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:26,660 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #13: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 1.8072483539581299, 'train_time_std': 0.0038839340637318305}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:27,302 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:27,719 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:27,742 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:27,747 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:27,747 : INFO : EPOCH - 1 : training on 175599 raw words (110227 effective words) took 0.4s, 253871 effective words/s\n",
      "2020-04-17 14:59:28,178 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:28,202 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:28,203 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:28,204 : INFO : EPOCH - 2 : training on 175599 raw words (110383 effective words) took 0.4s, 250170 effective words/s\n",
      "2020-04-17 14:59:28,632 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:28,649 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:28,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:28,661 : INFO : EPOCH - 3 : training on 175599 raw words (110170 effective words) took 0.4s, 247373 effective words/s\n",
      "2020-04-17 14:59:29,088 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:29,104 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:29,109 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:29,110 : INFO : EPOCH - 4 : training on 175599 raw words (110208 effective words) took 0.4s, 254411 effective words/s\n",
      "2020-04-17 14:59:29,535 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:29,560 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:29,561 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:29,562 : INFO : EPOCH - 5 : training on 175599 raw words (110305 effective words) took 0.4s, 250350 effective words/s\n",
      "2020-04-17 14:59:29,562 : INFO : training on a 877995 raw words (551293 effective words) took 2.3s, 243981 effective words/s\n",
      "2020-04-17 14:59:29,564 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:29,576 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:29,606 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:29,606 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:29,616 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:29,617 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:29,626 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:29,627 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:29,628 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:29,631 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:29,703 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:29,708 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:29,708 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:30,362 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:30,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:30,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:30,810 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:30,811 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.4s, 251359 effective words/s\n",
      "2020-04-17 14:59:31,238 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:31,251 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:31,258 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:31,259 : INFO : EPOCH - 2 : training on 175599 raw words (110178 effective words) took 0.4s, 252879 effective words/s\n",
      "2020-04-17 14:59:31,696 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:31,714 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:31,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:31,719 : INFO : EPOCH - 3 : training on 175599 raw words (110272 effective words) took 0.4s, 246331 effective words/s\n",
      "2020-04-17 14:59:32,140 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:32,163 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:32,170 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:32,171 : INFO : EPOCH - 4 : training on 175599 raw words (110184 effective words) took 0.4s, 249893 effective words/s\n",
      "2020-04-17 14:59:32,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:32,614 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:32,621 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:32,621 : INFO : EPOCH - 5 : training on 175599 raw words (110252 effective words) took 0.4s, 251294 effective words/s\n",
      "2020-04-17 14:59:32,622 : INFO : training on a 877995 raw words (550880 effective words) took 2.3s, 243783 effective words/s\n",
      "2020-04-17 14:59:32,626 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:32,637 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:32,669 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:32,669 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:32,679 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:32,679 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:32,688 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:32,689 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:32,690 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:32,693 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:32,768 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:32,773 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:32,774 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:33,421 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:33,840 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:33,857 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:33,864 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:33,864 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.4s, 255050 effective words/s\n",
      "2020-04-17 14:59:34,291 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:34,307 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:34,313 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:34,314 : INFO : EPOCH - 2 : training on 175599 raw words (110177 effective words) took 0.4s, 252326 effective words/s\n",
      "2020-04-17 14:59:34,746 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:34,754 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:34,771 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:34,771 : INFO : EPOCH - 3 : training on 175599 raw words (110272 effective words) took 0.4s, 247661 effective words/s\n",
      "2020-04-17 14:59:35,200 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:35,220 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:35,223 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:35,224 : INFO : EPOCH - 4 : training on 175599 raw words (110180 effective words) took 0.4s, 250027 effective words/s\n",
      "2020-04-17 14:59:35,647 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:35,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:35,672 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:35,672 : INFO : EPOCH - 5 : training on 175599 raw words (110246 effective words) took 0.4s, 254488 effective words/s\n",
      "2020-04-17 14:59:35,672 : INFO : training on a 877995 raw words (550869 effective words) took 2.3s, 244689 effective words/s\n",
      "2020-04-17 14:59:35,676 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:35,687 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:35,716 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:35,717 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:35,726 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:35,727 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:35,736 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:35,737 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:35,738 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:35,741 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:35,813 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:35,818 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:35,819 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #14: {'train_data': '1MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 3.0536507765452066, 'train_time_std': 0.005384403896102122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:36,467 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:36,890 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:36,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:36,913 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:36,914 : INFO : EPOCH - 1 : training on 175599 raw words (110284 effective words) took 0.4s, 253568 effective words/s\n",
      "2020-04-17 14:59:37,325 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:37,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:37,353 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:37,354 : INFO : EPOCH - 2 : training on 175599 raw words (110008 effective words) took 0.4s, 257318 effective words/s\n",
      "2020-04-17 14:59:37,766 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:37,786 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:37,792 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:37,792 : INFO : EPOCH - 3 : training on 175599 raw words (110261 effective words) took 0.4s, 258658 effective words/s\n",
      "2020-04-17 14:59:38,206 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:38,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:38,228 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:38,228 : INFO : EPOCH - 4 : training on 175599 raw words (110414 effective words) took 0.4s, 261481 effective words/s\n",
      "2020-04-17 14:59:38,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:38,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:38,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:38,664 : INFO : EPOCH - 5 : training on 175599 raw words (110270 effective words) took 0.4s, 260332 effective words/s\n",
      "2020-04-17 14:59:38,664 : INFO : training on a 877995 raw words (551237 effective words) took 2.2s, 250951 effective words/s\n",
      "2020-04-17 14:59:38,668 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:38,679 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:38,707 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:38,708 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:38,717 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:38,717 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:38,726 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:38,728 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:38,728 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:38,731 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:38,804 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:38,809 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:38,810 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:39,445 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:39,859 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:39,877 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:39,881 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:39,882 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.4s, 259359 effective words/s\n",
      "2020-04-17 14:59:40,299 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:40,312 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:40,317 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:40,318 : INFO : EPOCH - 2 : training on 175599 raw words (110178 effective words) took 0.4s, 259333 effective words/s\n",
      "2020-04-17 14:59:40,733 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:40,745 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:40,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:40,752 : INFO : EPOCH - 3 : training on 175599 raw words (110068 effective words) took 0.4s, 261115 effective words/s\n",
      "2020-04-17 14:59:41,165 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:41,181 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:41,188 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:41,188 : INFO : EPOCH - 4 : training on 175599 raw words (110173 effective words) took 0.4s, 260002 effective words/s\n",
      "2020-04-17 14:59:41,610 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:41,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:41,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:41,642 : INFO : EPOCH - 5 : training on 175599 raw words (110060 effective words) took 0.4s, 249613 effective words/s\n",
      "2020-04-17 14:59:41,642 : INFO : training on a 877995 raw words (550473 effective words) took 2.2s, 250605 effective words/s\n",
      "2020-04-17 14:59:41,646 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:41,658 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:41,688 : INFO : collected 17251 word types from a corpus of 175599 raw words and 18 sentences\n",
      "2020-04-17 14:59:41,688 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:41,698 : INFO : effective_min_count=5 retains 4125 unique words (23% of original 17251, drops 13126)\n",
      "2020-04-17 14:59:41,699 : INFO : effective_min_count=5 leaves 154201 word corpus (87% of original 175599, drops 21398)\n",
      "2020-04-17 14:59:41,708 : INFO : deleting the raw counts dictionary of 17251 items\n",
      "2020-04-17 14:59:41,709 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2020-04-17 14:59:41,710 : INFO : downsampling leaves estimated 110199 word corpus (71.5% of prior 154201)\n",
      "2020-04-17 14:59:41,713 : INFO : constructing a huffman tree from 4125 words\n",
      "2020-04-17 14:59:41,785 : INFO : built huffman tree with maximum node depth 15\n",
      "2020-04-17 14:59:41,790 : INFO : estimated required memory for 4125 words and 100 dimensions: 7837500 bytes\n",
      "2020-04-17 14:59:41,791 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:42,448 : INFO : training model with 3 workers on 4125 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:42,865 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:42,879 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:42,886 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:42,886 : INFO : EPOCH - 1 : training on 175599 raw words (109994 effective words) took 0.4s, 258278 effective words/s\n",
      "2020-04-17 14:59:43,303 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:43,319 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:43,321 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:43,321 : INFO : EPOCH - 2 : training on 175599 raw words (110037 effective words) took 0.4s, 261456 effective words/s\n",
      "2020-04-17 14:59:43,738 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:43,750 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:43,761 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:43,761 : INFO : EPOCH - 3 : training on 175599 raw words (110198 effective words) took 0.4s, 257415 effective words/s\n",
      "2020-04-17 14:59:44,178 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:44,193 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:44,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:44,200 : INFO : EPOCH - 4 : training on 175599 raw words (110412 effective words) took 0.4s, 259036 effective words/s\n",
      "2020-04-17 14:59:44,617 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:44,635 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:44,638 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:44,639 : INFO : EPOCH - 5 : training on 175599 raw words (110397 effective words) took 0.4s, 258997 effective words/s\n",
      "2020-04-17 14:59:44,639 : INFO : training on a 877995 raw words (551038 effective words) took 2.2s, 251600 effective words/s\n",
      "2020-04-17 14:59:44,643 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:44,815 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #15: {'train_data': '1MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 2.9887211322784424, 'train_time_std': 0.008065168496341799}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 14:59:45,111 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 14:59:45,111 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:45,152 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 14:59:45,152 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 14:59:45,197 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 14:59:45,202 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 14:59:45,202 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 14:59:45,251 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 14:59:45,252 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:48,388 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 14:59:49,362 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:49,366 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:49,369 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:49,370 : INFO : EPOCH - 1 : training on 1788017 raw words (1242503 effective words) took 0.9s, 1431556 effective words/s\n",
      "2020-04-17 14:59:50,393 : INFO : EPOCH 2 - PROGRESS: at 75.98% examples, 944091 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 14:59:50,868 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:50,871 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:50,875 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:50,876 : INFO : EPOCH - 2 : training on 1788017 raw words (1242314 effective words) took 1.5s, 836199 effective words/s\n",
      "2020-04-17 14:59:51,917 : INFO : EPOCH 3 - PROGRESS: at 78.21% examples, 968874 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 14:59:52,114 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:52,120 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:52,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:52,122 : INFO : EPOCH - 3 : training on 1788017 raw words (1242329 effective words) took 1.2s, 1027158 effective words/s\n",
      "2020-04-17 14:59:53,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:53,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:53,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:53,107 : INFO : EPOCH - 4 : training on 1788017 raw words (1243008 effective words) took 1.0s, 1282987 effective words/s\n",
      "2020-04-17 14:59:54,130 : INFO : EPOCH 5 - PROGRESS: at 98.32% examples, 1215065 words/s, in_qsize 3, out_qsize 0\n",
      "2020-04-17 14:59:54,132 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 14:59:54,137 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 14:59:54,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 14:59:54,142 : INFO : EPOCH - 5 : training on 1788017 raw words (1242469 effective words) took 1.0s, 1219381 effective words/s\n",
      "2020-04-17 14:59:54,143 : INFO : training on a 8940085 raw words (6212623 effective words) took 5.8s, 1079601 effective words/s\n",
      "2020-04-17 14:59:54,149 : INFO : collecting all words and their counts\n",
      "2020-04-17 14:59:54,261 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 14:59:54,689 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 14:59:54,690 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 14:59:54,752 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 14:59:54,753 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 14:59:54,818 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 14:59:54,822 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 14:59:54,823 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 14:59:54,886 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 14:59:54,886 : INFO : resetting layer weights\n",
      "2020-04-17 14:59:59,207 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:00:00,152 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:00,160 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:00,163 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:00,164 : INFO : EPOCH - 1 : training on 1788017 raw words (1241427 effective words) took 0.9s, 1447225 effective words/s\n",
      "2020-04-17 15:00:01,294 : INFO : EPOCH 2 - PROGRESS: at 89.39% examples, 1083318 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:00:01,823 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:01,845 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:01,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:01,847 : INFO : EPOCH - 2 : training on 1788017 raw words (1242386 effective words) took 1.6s, 786176 effective words/s\n",
      "2020-04-17 15:00:03,007 : INFO : EPOCH 3 - PROGRESS: at 69.27% examples, 835477 words/s, in_qsize 5, out_qsize 1\n",
      "2020-04-17 15:00:03,846 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:03,851 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:03,856 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:03,857 : INFO : EPOCH - 3 : training on 1788017 raw words (1242603 effective words) took 1.9s, 660868 effective words/s\n",
      "2020-04-17 15:00:04,749 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:04,756 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:04,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:04,757 : INFO : EPOCH - 4 : training on 1788017 raw words (1242924 effective words) took 0.8s, 1555150 effective words/s\n",
      "2020-04-17 15:00:05,860 : INFO : EPOCH 5 - PROGRESS: at 89.39% examples, 1104970 words/s, in_qsize 5, out_qsize 1\n",
      "2020-04-17 15:00:06,110 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:06,120 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:06,124 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:06,125 : INFO : EPOCH - 5 : training on 1788017 raw words (1242830 effective words) took 1.3s, 977259 effective words/s\n",
      "2020-04-17 15:00:06,125 : INFO : training on a 8940085 raw words (6212170 effective words) took 6.9s, 897990 effective words/s\n",
      "2020-04-17 15:00:06,146 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:00:06,313 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:00:06,632 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:00:06,633 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:00:06,674 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:00:06,674 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:00:06,718 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:00:06,722 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:00:06,722 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:00:06,759 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 15:00:06,760 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:00:10,487 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:00:11,475 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:11,479 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:11,482 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:11,482 : INFO : EPOCH - 1 : training on 1788017 raw words (1242352 effective words) took 1.0s, 1288968 effective words/s\n",
      "2020-04-17 15:00:12,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:12,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:12,472 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:12,473 : INFO : EPOCH - 2 : training on 1788017 raw words (1241918 effective words) took 0.9s, 1396194 effective words/s\n",
      "2020-04-17 15:00:13,540 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:13,545 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:13,548 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:13,549 : INFO : EPOCH - 3 : training on 1788017 raw words (1241956 effective words) took 1.0s, 1282390 effective words/s\n",
      "2020-04-17 15:00:14,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:14,473 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:14,477 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:14,478 : INFO : EPOCH - 4 : training on 1788017 raw words (1243126 effective words) took 0.9s, 1367302 effective words/s\n",
      "2020-04-17 15:00:15,385 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:15,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:15,395 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:15,397 : INFO : EPOCH - 5 : training on 1788017 raw words (1241913 effective words) took 0.8s, 1515256 effective words/s\n",
      "2020-04-17 15:00:15,398 : INFO : training on a 8940085 raw words (6211265 effective words) took 4.9s, 1264885 effective words/s\n",
      "2020-04-17 15:00:15,408 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:00:15,534 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #16: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 0, 'train_time_mean': 10.25504732131958, 'train_time_std': 1.2357424930850787}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:00:15,873 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:00:15,874 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:00:15,915 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:00:15,916 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:00:15,959 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:00:15,962 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:00:15,963 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:00:16,002 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 15:00:16,003 : INFO : resetting layer weights\n",
      "2020-04-17 15:00:19,220 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:00:20,138 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:20,141 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:20,143 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:20,143 : INFO : EPOCH - 1 : training on 1788017 raw words (1243085 effective words) took 0.9s, 1371828 effective words/s\n",
      "2020-04-17 15:00:21,036 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:21,039 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:21,041 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:21,041 : INFO : EPOCH - 2 : training on 1788017 raw words (1241507 effective words) took 0.8s, 1556620 effective words/s\n",
      "2020-04-17 15:00:21,987 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:21,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:21,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:21,995 : INFO : EPOCH - 3 : training on 1788017 raw words (1242079 effective words) took 0.8s, 1478478 effective words/s\n",
      "2020-04-17 15:00:22,923 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:22,928 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:22,929 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:22,930 : INFO : EPOCH - 4 : training on 1788017 raw words (1242664 effective words) took 0.9s, 1353416 effective words/s\n",
      "2020-04-17 15:00:23,874 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:23,880 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:23,882 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:23,882 : INFO : EPOCH - 5 : training on 1788017 raw words (1242528 effective words) took 0.9s, 1327768 effective words/s\n",
      "2020-04-17 15:00:23,883 : INFO : training on a 8940085 raw words (6211863 effective words) took 4.7s, 1332463 effective words/s\n",
      "2020-04-17 15:00:23,888 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:00:23,987 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:00:24,288 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:00:24,288 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:00:24,329 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:00:24,329 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:00:24,372 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:00:24,376 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:00:24,377 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:00:24,419 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 15:00:24,420 : INFO : resetting layer weights\n",
      "2020-04-17 15:00:27,673 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:00:28,697 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 1103442 words/s, in_qsize 5, out_qsize 1\n",
      "2020-04-17 15:00:28,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:28,802 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:28,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:28,803 : INFO : EPOCH - 1 : training on 1788017 raw words (1241656 effective words) took 1.1s, 1115464 effective words/s\n",
      "2020-04-17 15:00:29,835 : INFO : EPOCH 2 - PROGRESS: at 94.97% examples, 1165744 words/s, in_qsize 6, out_qsize 1\n",
      "2020-04-17 15:00:29,884 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:29,891 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:29,896 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:29,897 : INFO : EPOCH - 2 : training on 1788017 raw words (1242413 effective words) took 1.1s, 1155090 effective words/s\n",
      "2020-04-17 15:00:30,929 : INFO : EPOCH 3 - PROGRESS: at 73.74% examples, 915652 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:00:31,258 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:31,266 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:31,267 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:31,267 : INFO : EPOCH - 3 : training on 1788017 raw words (1242504 effective words) took 1.3s, 927533 effective words/s\n",
      "2020-04-17 15:00:32,293 : INFO : EPOCH 4 - PROGRESS: at 83.80% examples, 1041516 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:00:32,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:32,448 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:32,450 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:32,451 : INFO : EPOCH - 4 : training on 1788017 raw words (1243037 effective words) took 1.2s, 1072392 effective words/s\n",
      "2020-04-17 15:00:33,419 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:33,425 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:33,427 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:33,427 : INFO : EPOCH - 5 : training on 1788017 raw words (1242612 effective words) took 0.9s, 1423297 effective words/s\n",
      "2020-04-17 15:00:33,428 : INFO : training on a 8940085 raw words (6212222 effective words) took 5.8s, 1079543 effective words/s\n",
      "2020-04-17 15:00:33,434 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:00:33,543 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:00:34,016 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:00:34,016 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:00:34,070 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:00:34,072 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:00:34,133 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:00:34,138 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:00:34,140 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:00:34,201 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 15:00:34,202 : INFO : resetting layer weights\n",
      "2020-04-17 15:00:37,811 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:00:38,701 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:00:38,709 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:38,710 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:38,710 : INFO : EPOCH - 1 : training on 1788017 raw words (1242948 effective words) took 0.8s, 1564843 effective words/s\n",
      "2020-04-17 15:00:39,592 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:39,599 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:39,600 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:39,601 : INFO : EPOCH - 2 : training on 1788017 raw words (1241864 effective words) took 0.8s, 1572117 effective words/s\n",
      "2020-04-17 15:00:40,624 : INFO : EPOCH 3 - PROGRESS: at 93.30% examples, 1153899 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:00:40,736 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:40,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:40,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:40,752 : INFO : EPOCH - 3 : training on 1788017 raw words (1242469 effective words) took 1.1s, 1096190 effective words/s\n",
      "2020-04-17 15:00:41,897 : INFO : EPOCH 4 - PROGRESS: at 81.01% examples, 1006074 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:00:42,137 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:42,146 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:42,150 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:42,151 : INFO : EPOCH - 4 : training on 1788017 raw words (1243145 effective words) took 1.3s, 989264 effective words/s\n",
      "2020-04-17 15:00:43,320 : INFO : EPOCH 5 - PROGRESS: at 93.85% examples, 1166976 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:00:43,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:43,411 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:43,413 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:43,414 : INFO : EPOCH - 5 : training on 1788017 raw words (1242532 effective words) took 1.1s, 1135296 effective words/s\n",
      "2020-04-17 15:00:43,414 : INFO : training on a 8940085 raw words (6212958 effective words) took 5.6s, 1108911 effective words/s\n",
      "2020-04-17 15:00:43,425 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:00:43,541 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #17: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 0, 'train_time_mean': 9.338944673538208, 'train_time_std': 0.6340272309613076}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:00:43,913 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:00:43,914 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:00:43,970 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:00:43,971 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:00:44,028 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:00:44,032 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:00:44,032 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:00:44,054 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:00:44,584 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:00:44,629 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:00:44,630 : INFO : resetting layer weights\n",
      "2020-04-17 15:00:48,263 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:00:49,296 : INFO : EPOCH 1 - PROGRESS: at 48.04% examples, 598229 words/s, in_qsize 4, out_qsize 1\n",
      "2020-04-17 15:00:50,091 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:50,110 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:50,112 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:50,113 : INFO : EPOCH - 1 : training on 1788017 raw words (1241830 effective words) took 1.8s, 680632 effective words/s\n",
      "2020-04-17 15:00:51,142 : INFO : EPOCH 2 - PROGRESS: at 58.66% examples, 720977 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:00:51,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:51,828 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:51,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:51,832 : INFO : EPOCH - 2 : training on 1788017 raw words (1242528 effective words) took 1.7s, 729547 effective words/s\n",
      "2020-04-17 15:00:52,945 : INFO : EPOCH 3 - PROGRESS: at 63.69% examples, 788133 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:00:53,496 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:53,511 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:53,512 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:53,513 : INFO : EPOCH - 3 : training on 1788017 raw words (1242218 effective words) took 1.6s, 790171 effective words/s\n",
      "2020-04-17 15:00:54,615 : INFO : EPOCH 4 - PROGRESS: at 63.13% examples, 784092 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:00:55,191 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:55,206 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:55,206 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:55,207 : INFO : EPOCH - 4 : training on 1788017 raw words (1242772 effective words) took 1.6s, 780408 effective words/s\n",
      "2020-04-17 15:00:56,238 : INFO : EPOCH 5 - PROGRESS: at 58.66% examples, 719651 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:00:56,873 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:00:56,889 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:00:56,890 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:00:56,890 : INFO : EPOCH - 5 : training on 1788017 raw words (1241825 effective words) took 1.7s, 744905 effective words/s\n",
      "2020-04-17 15:00:56,891 : INFO : training on a 8940085 raw words (6211173 effective words) took 8.6s, 720006 effective words/s\n",
      "2020-04-17 15:00:56,896 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:00:56,994 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:00:57,301 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:00:57,302 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:00:57,343 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:00:57,344 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:00:57,389 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:00:57,392 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:00:57,393 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:00:57,409 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:00:57,819 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:00:57,846 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:00:57,847 : INFO : resetting layer weights\n",
      "2020-04-17 15:01:01,005 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:01:02,123 : INFO : EPOCH 1 - PROGRESS: at 64.80% examples, 798866 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:02,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:02,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:02,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:02,666 : INFO : EPOCH - 1 : training on 1788017 raw words (1242442 effective words) took 1.6s, 800965 effective words/s\n",
      "2020-04-17 15:01:03,689 : INFO : EPOCH 2 - PROGRESS: at 59.22% examples, 733370 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:04,298 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:04,309 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:04,313 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:04,314 : INFO : EPOCH - 2 : training on 1788017 raw words (1242308 effective words) took 1.6s, 761896 effective words/s\n",
      "2020-04-17 15:01:05,416 : INFO : EPOCH 3 - PROGRESS: at 61.45% examples, 760889 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:06,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:06,029 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:06,031 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:06,031 : INFO : EPOCH - 3 : training on 1788017 raw words (1242037 effective words) took 1.6s, 767109 effective words/s\n",
      "2020-04-17 15:01:07,134 : INFO : EPOCH 4 - PROGRESS: at 62.57% examples, 775626 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:07,839 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:07,857 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:07,858 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:07,858 : INFO : EPOCH - 4 : training on 1788017 raw words (1242219 effective words) took 1.7s, 719573 effective words/s\n",
      "2020-04-17 15:01:08,986 : INFO : EPOCH 5 - PROGRESS: at 50.28% examples, 626470 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:09,946 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:09,968 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:09,968 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:09,969 : INFO : EPOCH - 5 : training on 1788017 raw words (1242730 effective words) took 2.0s, 624717 effective words/s\n",
      "2020-04-17 15:01:09,969 : INFO : training on a 8940085 raw words (6211736 effective words) took 9.0s, 693027 effective words/s\n",
      "2020-04-17 15:01:09,988 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:01:10,112 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:01:10,514 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:01:10,515 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:01:10,569 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:01:10,570 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:01:10,619 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:01:10,625 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:01:10,627 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:01:10,648 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:01:11,136 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:01:11,177 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:01:11,178 : INFO : resetting layer weights\n",
      "2020-04-17 15:01:14,703 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:01:15,813 : INFO : EPOCH 1 - PROGRESS: at 58.66% examples, 723893 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:16,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:16,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:16,672 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:16,673 : INFO : EPOCH - 1 : training on 1788017 raw words (1242419 effective words) took 1.9s, 664673 effective words/s\n",
      "2020-04-17 15:01:17,804 : INFO : EPOCH 2 - PROGRESS: at 48.04% examples, 597423 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:18,808 : INFO : EPOCH 2 - PROGRESS: at 97.77% examples, 603896 words/s, in_qsize 4, out_qsize 0\n",
      "2020-04-17 15:01:18,814 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:18,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:18,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:18,837 : INFO : EPOCH - 2 : training on 1788017 raw words (1241806 effective words) took 2.0s, 608116 effective words/s\n",
      "2020-04-17 15:01:19,967 : INFO : EPOCH 3 - PROGRESS: at 49.72% examples, 622975 words/s, in_qsize 4, out_qsize 1\n",
      "2020-04-17 15:01:20,872 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:20,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:20,888 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:20,889 : INFO : EPOCH - 3 : training on 1788017 raw words (1241828 effective words) took 1.9s, 646006 effective words/s\n",
      "2020-04-17 15:01:21,991 : INFO : EPOCH 4 - PROGRESS: at 54.75% examples, 682047 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:22,704 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:22,719 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:22,720 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:22,721 : INFO : EPOCH - 4 : training on 1788017 raw words (1242612 effective words) took 1.7s, 717150 effective words/s\n",
      "2020-04-17 15:01:23,830 : INFO : EPOCH 5 - PROGRESS: at 63.13% examples, 780402 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:24,393 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:24,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:24,409 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:24,409 : INFO : EPOCH - 5 : training on 1788017 raw words (1242068 effective words) took 1.6s, 784302 effective words/s\n",
      "2020-04-17 15:01:24,410 : INFO : training on a 8940085 raw words (6210733 effective words) took 9.7s, 639861 effective words/s\n",
      "2020-04-17 15:01:24,430 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:01:24,526 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #18: {'train_data': '10MB', 'compute_loss': True, 'sg': 0, 'hs': 1, 'train_time_mean': 13.668074687321981, 'train_time_std': 0.5688892683694853}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:01:24,821 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:01:24,821 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:01:24,862 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:01:24,862 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:01:24,905 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:01:24,908 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:01:24,909 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:01:24,924 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:01:25,318 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:01:25,344 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:01:25,345 : INFO : resetting layer weights\n",
      "2020-04-17 15:01:28,520 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:01:29,639 : INFO : EPOCH 1 - PROGRESS: at 62.57% examples, 768732 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:30,220 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:30,234 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:30,235 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:30,235 : INFO : EPOCH - 1 : training on 1788017 raw words (1242590 effective words) took 1.6s, 772435 effective words/s\n",
      "2020-04-17 15:01:31,260 : INFO : EPOCH 2 - PROGRESS: at 54.19% examples, 671693 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:31,959 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:31,972 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:31,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:31,974 : INFO : EPOCH - 2 : training on 1788017 raw words (1241977 effective words) took 1.7s, 720856 effective words/s\n",
      "2020-04-17 15:01:33,079 : INFO : EPOCH 3 - PROGRESS: at 65.92% examples, 816841 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:33,587 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:33,600 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:33,602 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:33,602 : INFO : EPOCH - 3 : training on 1788017 raw words (1242070 effective words) took 1.5s, 814228 effective words/s\n",
      "2020-04-17 15:01:34,622 : INFO : EPOCH 4 - PROGRESS: at 62.01% examples, 768128 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:35,180 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:35,193 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:35,195 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:35,196 : INFO : EPOCH - 4 : training on 1788017 raw words (1242471 effective words) took 1.6s, 787810 effective words/s\n",
      "2020-04-17 15:01:36,215 : INFO : EPOCH 5 - PROGRESS: at 46.93% examples, 586749 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:37,081 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:37,095 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:37,096 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:37,097 : INFO : EPOCH - 5 : training on 1788017 raw words (1242314 effective words) took 1.9s, 658868 effective words/s\n",
      "2020-04-17 15:01:37,097 : INFO : training on a 8940085 raw words (6211422 effective words) took 8.6s, 724296 effective words/s\n",
      "2020-04-17 15:01:37,115 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:01:37,211 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:01:37,504 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:01:37,505 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:01:37,546 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:01:37,546 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:01:37,590 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:01:37,594 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:01:37,594 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:01:37,609 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:01:38,024 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:01:38,062 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:01:38,062 : INFO : resetting layer weights\n",
      "2020-04-17 15:01:41,462 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:01:42,488 : INFO : EPOCH 1 - PROGRESS: at 40.22% examples, 502504 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:43,495 : INFO : EPOCH 1 - PROGRESS: at 91.06% examples, 562447 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:43,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:43,666 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:43,672 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:43,673 : INFO : EPOCH - 1 : training on 1788017 raw words (1242808 effective words) took 2.2s, 566602 effective words/s\n",
      "2020-04-17 15:01:44,695 : INFO : EPOCH 2 - PROGRESS: at 52.51% examples, 656809 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:45,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:45,444 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:45,449 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:45,449 : INFO : EPOCH - 2 : training on 1788017 raw words (1242498 effective words) took 1.8s, 707844 effective words/s\n",
      "2020-04-17 15:01:46,479 : INFO : EPOCH 3 - PROGRESS: at 52.51% examples, 648423 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:47,190 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:47,201 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:47,205 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:47,205 : INFO : EPOCH - 3 : training on 1788017 raw words (1241879 effective words) took 1.7s, 713617 effective words/s\n",
      "2020-04-17 15:01:48,243 : INFO : EPOCH 4 - PROGRESS: at 53.63% examples, 665924 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:48,978 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:48,995 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:48,996 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:48,997 : INFO : EPOCH - 4 : training on 1788017 raw words (1242439 effective words) took 1.8s, 705595 effective words/s\n",
      "2020-04-17 15:01:50,129 : INFO : EPOCH 5 - PROGRESS: at 50.28% examples, 623789 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:51,084 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:51,085 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:51,086 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:51,086 : INFO : EPOCH - 5 : training on 1788017 raw words (1241779 effective words) took 2.0s, 631286 effective words/s\n",
      "2020-04-17 15:01:51,087 : INFO : training on a 8940085 raw words (6211403 effective words) took 9.6s, 645365 effective words/s\n",
      "2020-04-17 15:01:51,106 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:01:51,219 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:01:51,612 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:01:51,612 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:01:51,662 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:01:51,663 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:01:51,710 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:01:51,713 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:01:51,714 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:01:51,735 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:01:52,194 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:01:52,227 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:01:52,227 : INFO : resetting layer weights\n",
      "2020-04-17 15:01:55,462 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:01:56,562 : INFO : EPOCH 1 - PROGRESS: at 65.92% examples, 816484 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:57,069 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:57,083 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:57,084 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:57,084 : INFO : EPOCH - 1 : training on 1788017 raw words (1242948 effective words) took 1.5s, 814323 effective words/s\n",
      "2020-04-17 15:01:58,192 : INFO : EPOCH 2 - PROGRESS: at 64.80% examples, 798929 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:01:58,789 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:01:58,803 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:01:58,804 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:01:58,805 : INFO : EPOCH - 2 : training on 1788017 raw words (1242043 effective words) took 1.6s, 766816 effective words/s\n",
      "2020-04-17 15:01:59,824 : INFO : EPOCH 3 - PROGRESS: at 58.10% examples, 722639 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:00,450 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:00,465 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:00,466 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:00,467 : INFO : EPOCH - 3 : training on 1788017 raw words (1242147 effective words) took 1.6s, 755433 effective words/s\n",
      "2020-04-17 15:02:01,598 : INFO : EPOCH 4 - PROGRESS: at 63.69% examples, 769233 words/s, in_qsize 5, out_qsize 1\n",
      "2020-04-17 15:02:02,284 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:02,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:02,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:02,302 : INFO : EPOCH - 4 : training on 1788017 raw words (1242755 effective words) took 1.7s, 717446 effective words/s\n",
      "2020-04-17 15:02:03,429 : INFO : EPOCH 5 - PROGRESS: at 51.40% examples, 640084 words/s, in_qsize 6, out_qsize 1\n",
      "2020-04-17 15:02:04,256 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:04,272 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:04,277 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:04,278 : INFO : EPOCH - 5 : training on 1788017 raw words (1241397 effective words) took 1.9s, 669464 effective words/s\n",
      "2020-04-17 15:02:04,278 : INFO : training on a 8940085 raw words (6211290 effective words) took 8.8s, 704536 effective words/s\n",
      "2020-04-17 15:02:04,300 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:02:04,409 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #19: {'train_data': '10MB', 'compute_loss': False, 'sg': 0, 'hs': 1, 'train_time_mean': 13.289937257766724, 'train_time_std': 0.5378709545717524}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:02:04,776 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:02:04,777 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:02:04,826 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:02:04,827 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:02:04,874 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:02:04,878 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:02:04,879 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:02:04,926 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 15:02:04,927 : INFO : resetting layer weights\n",
      "2020-04-17 15:02:08,160 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:02:09,266 : INFO : EPOCH 1 - PROGRESS: at 35.75% examples, 447285 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:10,285 : INFO : EPOCH 1 - PROGRESS: at 73.18% examples, 449362 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:10,971 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:11,002 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:11,008 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:11,009 : INFO : EPOCH - 1 : training on 1788017 raw words (1242948 effective words) took 2.7s, 452068 effective words/s\n",
      "2020-04-17 15:02:12,115 : INFO : EPOCH 2 - PROGRESS: at 32.40% examples, 407192 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:13,126 : INFO : EPOCH 2 - PROGRESS: at 60.89% examples, 375885 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:14,143 : INFO : EPOCH 2 - PROGRESS: at 90.50% examples, 371754 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:14,407 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:14,438 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:14,444 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:14,445 : INFO : EPOCH - 2 : training on 1788017 raw words (1242572 effective words) took 3.3s, 372822 effective words/s\n",
      "2020-04-17 15:02:15,569 : INFO : EPOCH 3 - PROGRESS: at 34.08% examples, 419969 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:16,581 : INFO : EPOCH 3 - PROGRESS: at 68.16% examples, 416123 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:17,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:17,459 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:17,465 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:17,466 : INFO : EPOCH - 3 : training on 1788017 raw words (1242651 effective words) took 2.9s, 425623 effective words/s\n",
      "2020-04-17 15:02:18,585 : INFO : EPOCH 4 - PROGRESS: at 35.75% examples, 443449 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:19,586 : INFO : EPOCH 4 - PROGRESS: at 65.92% examples, 405981 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:20,614 : INFO : EPOCH 4 - PROGRESS: at 94.97% examples, 387935 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:20,730 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:20,767 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:20,774 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:20,775 : INFO : EPOCH - 4 : training on 1788017 raw words (1242029 effective words) took 3.2s, 387547 effective words/s\n",
      "2020-04-17 15:02:21,916 : INFO : EPOCH 5 - PROGRESS: at 27.93% examples, 349286 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:22,927 : INFO : EPOCH 5 - PROGRESS: at 62.01% examples, 380488 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:23,929 : INFO : EPOCH 5 - PROGRESS: at 92.74% examples, 381072 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:24,127 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:24,165 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:24,176 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:24,177 : INFO : EPOCH - 5 : training on 1788017 raw words (1242311 effective words) took 3.3s, 379245 effective words/s\n",
      "2020-04-17 15:02:24,178 : INFO : training on a 8940085 raw words (6212511 effective words) took 16.0s, 387837 effective words/s\n",
      "2020-04-17 15:02:24,202 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:02:24,321 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:02:24,693 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:02:24,693 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:02:24,738 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:02:24,739 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:02:24,789 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:02:24,793 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:02:24,793 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:02:24,838 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 15:02:24,839 : INFO : resetting layer weights\n",
      "2020-04-17 15:02:28,143 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:02:29,176 : INFO : EPOCH 1 - PROGRESS: at 30.73% examples, 382211 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:30,188 : INFO : EPOCH 1 - PROGRESS: at 64.25% examples, 393683 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:31,157 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:31,195 : INFO : EPOCH 1 - PROGRESS: at 99.44% examples, 406871 words/s, in_qsize 1, out_qsize 1\n",
      "2020-04-17 15:02:31,196 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:31,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:31,199 : INFO : EPOCH - 1 : training on 1788017 raw words (1241447 effective words) took 3.0s, 408630 effective words/s\n",
      "2020-04-17 15:02:32,230 : INFO : EPOCH 2 - PROGRESS: at 27.37% examples, 343702 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:33,253 : INFO : EPOCH 2 - PROGRESS: at 60.89% examples, 372550 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:34,257 : INFO : EPOCH 2 - PROGRESS: at 93.30% examples, 382232 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:34,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:34,500 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:34,504 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:34,505 : INFO : EPOCH - 2 : training on 1788017 raw words (1242625 effective words) took 3.3s, 378250 effective words/s\n",
      "2020-04-17 15:02:35,532 : INFO : EPOCH 3 - PROGRESS: at 29.05% examples, 367379 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:36,537 : INFO : EPOCH 3 - PROGRESS: at 58.66% examples, 363759 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:37,545 : INFO : EPOCH 3 - PROGRESS: at 89.94% examples, 371160 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:37,800 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:37,843 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:37,851 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:37,852 : INFO : EPOCH - 3 : training on 1788017 raw words (1241973 effective words) took 3.3s, 373920 effective words/s\n",
      "2020-04-17 15:02:38,956 : INFO : EPOCH 4 - PROGRESS: at 36.31% examples, 455069 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:39,961 : INFO : EPOCH 4 - PROGRESS: at 74.86% examples, 463302 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:02:40,591 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:40,622 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:40,630 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:40,630 : INFO : EPOCH - 4 : training on 1788017 raw words (1242407 effective words) took 2.7s, 463784 effective words/s\n",
      "2020-04-17 15:02:41,740 : INFO : EPOCH 5 - PROGRESS: at 36.87% examples, 461560 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:42,742 : INFO : EPOCH 5 - PROGRESS: at 74.30% examples, 460543 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:43,392 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:43,442 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:43,448 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:43,448 : INFO : EPOCH - 5 : training on 1788017 raw words (1243078 effective words) took 2.7s, 458065 effective words/s\n",
      "2020-04-17 15:02:43,448 : INFO : training on a 8940085 raw words (6211530 effective words) took 15.3s, 405864 effective words/s\n",
      "2020-04-17 15:02:43,454 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:02:43,557 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:02:43,883 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:02:43,884 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:02:43,925 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:02:43,926 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:02:43,970 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:02:43,974 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:02:43,974 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:02:44,014 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 15:02:44,014 : INFO : resetting layer weights\n",
      "2020-04-17 15:02:47,255 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:02:48,281 : INFO : EPOCH 1 - PROGRESS: at 26.26% examples, 329199 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:49,290 : INFO : EPOCH 1 - PROGRESS: at 59.22% examples, 364857 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:50,298 : INFO : EPOCH 1 - PROGRESS: at 87.71% examples, 360316 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:50,657 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:50,695 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:50,702 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:50,703 : INFO : EPOCH - 1 : training on 1788017 raw words (1242626 effective words) took 3.4s, 361972 effective words/s\n",
      "2020-04-17 15:02:51,734 : INFO : EPOCH 2 - PROGRESS: at 29.61% examples, 371893 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:52,740 : INFO : EPOCH 2 - PROGRESS: at 67.60% examples, 416592 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:53,637 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:53,669 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:53,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:53,677 : INFO : EPOCH - 2 : training on 1788017 raw words (1242192 effective words) took 3.0s, 420923 effective words/s\n",
      "2020-04-17 15:02:54,697 : INFO : EPOCH 3 - PROGRESS: at 33.52% examples, 420691 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:55,723 : INFO : EPOCH 3 - PROGRESS: at 65.92% examples, 403462 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:56,759 : INFO : EPOCH 3 - PROGRESS: at 96.09% examples, 390026 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:56,820 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:02:56,856 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:02:56,864 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:02:56,864 : INFO : EPOCH - 3 : training on 1788017 raw words (1242433 effective words) took 3.2s, 391820 effective words/s\n",
      "2020-04-17 15:02:57,996 : INFO : EPOCH 4 - PROGRESS: at 30.73% examples, 384688 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:02:59,011 : INFO : EPOCH 4 - PROGRESS: at 62.57% examples, 384239 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:00,049 : INFO : EPOCH 4 - PROGRESS: at 97.77% examples, 397220 words/s, in_qsize 4, out_qsize 0\n",
      "2020-04-17 15:03:00,053 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:00,084 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:00,092 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:00,092 : INFO : EPOCH - 4 : training on 1788017 raw words (1242073 effective words) took 3.1s, 400114 effective words/s\n",
      "2020-04-17 15:03:01,209 : INFO : EPOCH 5 - PROGRESS: at 35.75% examples, 443895 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:02,215 : INFO : EPOCH 5 - PROGRESS: at 73.18% examples, 450261 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:03,058 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:03,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:03,097 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:03,097 : INFO : EPOCH - 5 : training on 1788017 raw words (1242506 effective words) took 2.9s, 428072 effective words/s\n",
      "2020-04-17 15:03:03,098 : INFO : training on a 8940085 raw words (6211830 effective words) took 15.8s, 392104 effective words/s\n",
      "2020-04-17 15:03:03,104 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:03:03,206 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #20: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 0, 'train_time_mean': 19.60117761294047, 'train_time_std': 0.26749512954468235}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:03:03,541 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:03:03,542 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:03:03,584 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:03:03,585 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:03:03,630 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:03:03,634 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:03:03,634 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:03:03,682 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 15:03:03,683 : INFO : resetting layer weights\n",
      "2020-04-17 15:03:06,930 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:03:08,064 : INFO : EPOCH 1 - PROGRESS: at 32.40% examples, 400286 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:09,072 : INFO : EPOCH 1 - PROGRESS: at 71.51% examples, 438084 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:09,798 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:09,830 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:09,835 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:09,836 : INFO : EPOCH - 1 : training on 1788017 raw words (1241630 effective words) took 2.8s, 444522 effective words/s\n",
      "2020-04-17 15:03:10,966 : INFO : EPOCH 2 - PROGRESS: at 35.75% examples, 437135 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:11,978 : INFO : EPOCH 2 - PROGRESS: at 72.63% examples, 442254 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:12,885 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:12,933 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:12,948 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:12,948 : INFO : EPOCH - 2 : training on 1788017 raw words (1242413 effective words) took 3.0s, 412563 effective words/s\n",
      "2020-04-17 15:03:14,067 : INFO : EPOCH 3 - PROGRESS: at 29.05% examples, 367121 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:15,068 : INFO : EPOCH 3 - PROGRESS: at 55.87% examples, 348138 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:16,075 : INFO : EPOCH 3 - PROGRESS: at 82.12% examples, 339137 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:16,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:16,699 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:16,707 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:16,708 : INFO : EPOCH - 3 : training on 1788017 raw words (1242111 effective words) took 3.6s, 340944 effective words/s\n",
      "2020-04-17 15:03:17,841 : INFO : EPOCH 4 - PROGRESS: at 30.73% examples, 382526 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:18,853 : INFO : EPOCH 4 - PROGRESS: at 67.60% examples, 414220 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:19,664 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:19,693 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:19,699 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:19,700 : INFO : EPOCH - 4 : training on 1788017 raw words (1241881 effective words) took 2.9s, 432351 effective words/s\n",
      "2020-04-17 15:03:20,807 : INFO : EPOCH 5 - PROGRESS: at 37.43% examples, 468286 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:21,826 : INFO : EPOCH 5 - PROGRESS: at 76.54% examples, 470424 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:22,405 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:22,433 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:22,439 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:22,440 : INFO : EPOCH - 5 : training on 1788017 raw words (1241761 effective words) took 2.6s, 470779 effective words/s\n",
      "2020-04-17 15:03:22,440 : INFO : training on a 8940085 raw words (6209796 effective words) took 15.5s, 400374 effective words/s\n",
      "2020-04-17 15:03:22,446 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:03:22,547 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:03:22,863 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:03:22,864 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:03:22,916 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:03:22,916 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:03:22,964 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:03:22,967 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:03:22,968 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:03:23,020 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 15:03:23,020 : INFO : resetting layer weights\n",
      "2020-04-17 15:03:26,351 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:03:27,470 : INFO : EPOCH 1 - PROGRESS: at 32.40% examples, 406111 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:28,472 : INFO : EPOCH 1 - PROGRESS: at 71.51% examples, 442716 words/s, in_qsize 6, out_qsize 0\n",
      "2020-04-17 15:03:29,181 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:29,212 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:29,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:29,219 : INFO : EPOCH - 1 : training on 1788017 raw words (1242943 effective words) took 2.8s, 450913 effective words/s\n",
      "2020-04-17 15:03:30,239 : INFO : EPOCH 2 - PROGRESS: at 34.08% examples, 428058 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:31,248 : INFO : EPOCH 2 - PROGRESS: at 73.74% examples, 455593 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:31,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:31,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:31,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:31,951 : INFO : EPOCH - 2 : training on 1788017 raw words (1242210 effective words) took 2.7s, 457526 effective words/s\n",
      "2020-04-17 15:03:33,056 : INFO : EPOCH 3 - PROGRESS: at 37.43% examples, 470210 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:34,074 : INFO : EPOCH 3 - PROGRESS: at 76.54% examples, 471909 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:34,643 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:34,677 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:34,683 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:34,683 : INFO : EPOCH - 3 : training on 1788017 raw words (1242679 effective words) took 2.6s, 472698 effective words/s\n",
      "2020-04-17 15:03:35,702 : INFO : EPOCH 4 - PROGRESS: at 34.08% examples, 428222 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:36,718 : INFO : EPOCH 4 - PROGRESS: at 73.18% examples, 450672 words/s, in_qsize 6, out_qsize 0\n",
      "2020-04-17 15:03:37,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:37,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:37,413 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:37,414 : INFO : EPOCH - 4 : training on 1788017 raw words (1242404 effective words) took 2.7s, 457595 effective words/s\n",
      "2020-04-17 15:03:38,521 : INFO : EPOCH 5 - PROGRESS: at 37.43% examples, 467833 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:03:39,526 : INFO : EPOCH 5 - PROGRESS: at 77.09% examples, 477482 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:40,156 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:40,192 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:40,201 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:40,202 : INFO : EPOCH - 5 : training on 1788017 raw words (1242507 effective words) took 2.7s, 462411 effective words/s\n",
      "2020-04-17 15:03:40,202 : INFO : training on a 8940085 raw words (6212743 effective words) took 13.9s, 448534 effective words/s\n",
      "2020-04-17 15:03:40,213 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:03:40,328 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:03:40,696 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:03:40,696 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:03:40,745 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:03:40,745 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:03:40,793 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:03:40,796 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:03:40,797 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:03:40,848 : INFO : estimated required memory for 20167 words and 100 dimensions: 26217100 bytes\n",
      "2020-04-17 15:03:40,849 : INFO : resetting layer weights\n",
      "2020-04-17 15:03:44,149 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:03:45,165 : INFO : EPOCH 1 - PROGRESS: at 27.93% examples, 353779 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:46,166 : INFO : EPOCH 1 - PROGRESS: at 66.48% examples, 412229 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:47,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:47,046 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:47,051 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:47,052 : INFO : EPOCH - 1 : training on 1788017 raw words (1242512 effective words) took 2.9s, 430153 effective words/s\n",
      "2020-04-17 15:03:48,077 : INFO : EPOCH 2 - PROGRESS: at 32.40% examples, 405469 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:49,092 : INFO : EPOCH 2 - PROGRESS: at 71.51% examples, 439573 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:49,817 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:49,848 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:49,855 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:49,856 : INFO : EPOCH - 2 : training on 1788017 raw words (1242748 effective words) took 2.8s, 445809 effective words/s\n",
      "2020-04-17 15:03:50,980 : INFO : EPOCH 3 - PROGRESS: at 37.43% examples, 461166 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:51,989 : INFO : EPOCH 3 - PROGRESS: at 75.98% examples, 465629 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:52,596 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:52,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:52,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:52,640 : INFO : EPOCH - 3 : training on 1788017 raw words (1241895 effective words) took 2.7s, 463311 effective words/s\n",
      "2020-04-17 15:03:53,754 : INFO : EPOCH 4 - PROGRESS: at 37.43% examples, 464935 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:54,761 : INFO : EPOCH 4 - PROGRESS: at 76.54% examples, 471870 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:55,332 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:55,364 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:55,367 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:55,368 : INFO : EPOCH - 4 : training on 1788017 raw words (1242422 effective words) took 2.6s, 472992 effective words/s\n",
      "2020-04-17 15:03:56,385 : INFO : EPOCH 5 - PROGRESS: at 34.08% examples, 429152 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:57,389 : INFO : EPOCH 5 - PROGRESS: at 73.18% examples, 453735 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:03:58,049 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:03:58,079 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:03:58,087 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:03:58,088 : INFO : EPOCH - 5 : training on 1788017 raw words (1242005 effective words) took 2.7s, 459455 effective words/s\n",
      "2020-04-17 15:03:58,088 : INFO : training on a 8940085 raw words (6211582 effective words) took 13.9s, 445619 effective words/s\n",
      "2020-04-17 15:03:58,094 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:03:58,200 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #21: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 0, 'train_time_mean': 18.330134630203247, 'train_time_std': 0.7170737128106401}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:03:58,527 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:03:58,528 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:03:58,570 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:03:58,570 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:03:58,614 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:03:58,617 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:03:58,618 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:03:58,633 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:03:59,043 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:03:59,071 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:03:59,072 : INFO : resetting layer weights\n",
      "2020-04-17 15:04:02,270 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:04:03,379 : INFO : EPOCH 1 - PROGRESS: at 13.97% examples, 163029 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:04,391 : INFO : EPOCH 1 - PROGRESS: at 29.61% examples, 178558 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:05,445 : INFO : EPOCH 1 - PROGRESS: at 45.81% examples, 182330 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:06,451 : INFO : EPOCH 1 - PROGRESS: at 60.34% examples, 180517 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:07,488 : INFO : EPOCH 1 - PROGRESS: at 78.21% examples, 187291 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:08,505 : INFO : EPOCH 1 - PROGRESS: at 96.09% examples, 192412 words/s, in_qsize 4, out_qsize 1\n",
      "2020-04-17 15:04:08,647 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:04:08,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:04:08,689 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:04:08,690 : INFO : EPOCH - 1 : training on 1788017 raw words (1242649 effective words) took 6.4s, 194204 effective words/s\n",
      "2020-04-17 15:04:09,833 : INFO : EPOCH 2 - PROGRESS: at 17.32% examples, 210908 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:10,878 : INFO : EPOCH 2 - PROGRESS: at 34.64% examples, 209032 words/s, in_qsize 4, out_qsize 1\n",
      "2020-04-17 15:04:11,961 : INFO : EPOCH 2 - PROGRESS: at 50.84% examples, 200789 words/s, in_qsize 6, out_qsize 0\n",
      "2020-04-17 15:04:12,967 : INFO : EPOCH 2 - PROGRESS: at 68.72% examples, 204335 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:14,009 : INFO : EPOCH 2 - PROGRESS: at 83.80% examples, 199715 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:14,948 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:04:15,020 : INFO : EPOCH 2 - PROGRESS: at 99.44% examples, 198267 words/s, in_qsize 1, out_qsize 1\n",
      "2020-04-17 15:04:15,021 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:04:15,045 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:04:15,045 : INFO : EPOCH - 2 : training on 1788017 raw words (1242168 effective words) took 6.3s, 198588 effective words/s\n",
      "2020-04-17 15:04:16,127 : INFO : EPOCH 3 - PROGRESS: at 15.64% examples, 186695 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:17,137 : INFO : EPOCH 3 - PROGRESS: at 34.08% examples, 206974 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:18,157 : INFO : EPOCH 3 - PROGRESS: at 52.51% examples, 212314 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:19,174 : INFO : EPOCH 3 - PROGRESS: at 71.51% examples, 216117 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:20,192 : INFO : EPOCH 3 - PROGRESS: at 89.94% examples, 218153 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:20,664 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:04:20,710 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:04:20,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:04:20,712 : INFO : EPOCH - 3 : training on 1788017 raw words (1241389 effective words) took 5.6s, 219797 effective words/s\n",
      "2020-04-17 15:04:21,865 : INFO : EPOCH 4 - PROGRESS: at 17.32% examples, 209283 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:22,870 : INFO : EPOCH 4 - PROGRESS: at 35.75% examples, 218832 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:23,878 : INFO : EPOCH 4 - PROGRESS: at 54.19% examples, 220980 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:24,900 : INFO : EPOCH 4 - PROGRESS: at 73.18% examples, 222646 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:25,906 : INFO : EPOCH 4 - PROGRESS: at 91.62% examples, 223842 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:26,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:04:26,343 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:04:26,363 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:04:26,364 : INFO : EPOCH - 4 : training on 1788017 raw words (1242251 effective words) took 5.5s, 223847 effective words/s\n",
      "2020-04-17 15:04:27,510 : INFO : EPOCH 5 - PROGRESS: at 17.32% examples, 210712 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:28,517 : INFO : EPOCH 5 - PROGRESS: at 35.75% examples, 219566 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:29,583 : INFO : EPOCH 5 - PROGRESS: at 54.19% examples, 217392 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:30,591 : INFO : EPOCH 5 - PROGRESS: at 70.95% examples, 213796 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:31,615 : INFO : EPOCH 5 - PROGRESS: at 87.15% examples, 210579 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:32,327 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:04:32,376 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:04:32,385 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:04:32,385 : INFO : EPOCH - 5 : training on 1788017 raw words (1242083 effective words) took 5.9s, 209865 effective words/s\n",
      "2020-04-17 15:04:32,386 : INFO : training on a 8940085 raw words (6210540 effective words) took 30.1s, 206225 effective words/s\n",
      "2020-04-17 15:04:32,392 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:04:32,510 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:04:32,877 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:04:32,878 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:04:32,922 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:04:32,923 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:04:32,975 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:04:32,978 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:04:32,979 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:04:32,997 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:04:33,445 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:04:33,477 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:04:33,478 : INFO : resetting layer weights\n",
      "2020-04-17 15:04:36,674 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:04:37,722 : INFO : EPOCH 1 - PROGRESS: at 15.64% examples, 192277 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:38,741 : INFO : EPOCH 1 - PROGRESS: at 34.08% examples, 209584 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:39,744 : INFO : EPOCH 1 - PROGRESS: at 52.51% examples, 215371 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:40,766 : INFO : EPOCH 1 - PROGRESS: at 71.51% examples, 218267 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:41,781 : INFO : EPOCH 1 - PROGRESS: at 89.94% examples, 220027 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:04:42,263 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:04:42,312 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:04:42,331 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:04:42,332 : INFO : EPOCH - 1 : training on 1788017 raw words (1242948 effective words) took 5.6s, 220313 effective words/s\n",
      "2020-04-17 15:04:43,380 : INFO : EPOCH 2 - PROGRESS: at 15.64% examples, 192195 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:44,408 : INFO : EPOCH 2 - PROGRESS: at 34.64% examples, 211720 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:45,436 : INFO : EPOCH 2 - PROGRESS: at 53.63% examples, 217081 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:46,447 : INFO : EPOCH 2 - PROGRESS: at 72.07% examples, 218454 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:47,472 : INFO : EPOCH 2 - PROGRESS: at 90.50% examples, 219731 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:47,916 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:04:47,964 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:04:47,979 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:04:47,980 : INFO : EPOCH - 2 : training on 1788017 raw words (1241864 effective words) took 5.6s, 220506 effective words/s\n",
      "2020-04-17 15:04:49,030 : INFO : EPOCH 3 - PROGRESS: at 15.64% examples, 192002 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:50,043 : INFO : EPOCH 3 - PROGRESS: at 34.08% examples, 209720 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:51,061 : INFO : EPOCH 3 - PROGRESS: at 52.51% examples, 214418 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:52,081 : INFO : EPOCH 3 - PROGRESS: at 71.51% examples, 217661 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:53,122 : INFO : EPOCH 3 - PROGRESS: at 90.50% examples, 219740 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:53,568 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:04:53,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:04:53,631 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:04:53,631 : INFO : EPOCH - 3 : training on 1788017 raw words (1242439 effective words) took 5.6s, 220466 effective words/s\n",
      "2020-04-17 15:04:54,670 : INFO : EPOCH 4 - PROGRESS: at 15.64% examples, 194162 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:55,679 : INFO : EPOCH 4 - PROGRESS: at 34.08% examples, 211341 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:56,707 : INFO : EPOCH 4 - PROGRESS: at 52.51% examples, 214808 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:57,715 : INFO : EPOCH 4 - PROGRESS: at 71.51% examples, 218680 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:58,718 : INFO : EPOCH 4 - PROGRESS: at 89.94% examples, 220851 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:04:59,203 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:04:59,265 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:04:59,278 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:04:59,278 : INFO : EPOCH - 4 : training on 1788017 raw words (1242778 effective words) took 5.6s, 220689 effective words/s\n",
      "2020-04-17 15:05:00,420 : INFO : EPOCH 5 - PROGRESS: at 17.32% examples, 211536 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:01,431 : INFO : EPOCH 5 - PROGRESS: at 35.75% examples, 219514 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:02,443 : INFO : EPOCH 5 - PROGRESS: at 54.19% examples, 221053 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:03,487 : INFO : EPOCH 5 - PROGRESS: at 68.72% examples, 207798 words/s, in_qsize 6, out_qsize 0\n",
      "2020-04-17 15:05:04,504 : INFO : EPOCH 5 - PROGRESS: at 83.80% examples, 203388 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:05,415 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:05:05,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:05:05,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:05:05,481 : INFO : EPOCH - 5 : training on 1788017 raw words (1241765 effective words) took 6.1s, 203582 effective words/s\n",
      "2020-04-17 15:05:05,481 : INFO : training on a 8940085 raw words (6211794 effective words) took 28.8s, 215633 effective words/s\n",
      "2020-04-17 15:05:05,499 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:05:05,604 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:05:06,039 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:05:06,040 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:05:06,125 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:05:06,126 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:05:06,185 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:05:06,197 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:05:06,197 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:05:06,225 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:05:06,991 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:05:07,035 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:05:07,036 : INFO : resetting layer weights\n",
      "2020-04-17 15:05:12,736 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:05:13,897 : INFO : EPOCH 1 - PROGRESS: at 15.64% examples, 189664 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:14,917 : INFO : EPOCH 1 - PROGRESS: at 34.08% examples, 207798 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:15,951 : INFO : EPOCH 1 - PROGRESS: at 52.51% examples, 211963 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:16,964 : INFO : EPOCH 1 - PROGRESS: at 71.51% examples, 216194 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:17,980 : INFO : EPOCH 1 - PROGRESS: at 89.39% examples, 216891 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:18,490 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:05:18,552 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:05:18,572 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:05:18,573 : INFO : EPOCH - 1 : training on 1788017 raw words (1242948 effective words) took 5.7s, 217150 effective words/s\n",
      "2020-04-17 15:05:19,718 : INFO : EPOCH 2 - PROGRESS: at 17.32% examples, 211036 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:20,721 : INFO : EPOCH 2 - PROGRESS: at 35.75% examples, 220176 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:21,753 : INFO : EPOCH 2 - PROGRESS: at 54.19% examples, 220128 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:22,786 : INFO : EPOCH 2 - PROGRESS: at 73.18% examples, 221402 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:23,803 : INFO : EPOCH 2 - PROGRESS: at 91.62% examples, 222313 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:24,195 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:05:24,260 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:05:24,272 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:05:24,273 : INFO : EPOCH - 2 : training on 1788017 raw words (1242293 effective words) took 5.6s, 221965 effective words/s\n",
      "2020-04-17 15:05:25,469 : INFO : EPOCH 3 - PROGRESS: at 15.64% examples, 192212 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:26,514 : INFO : EPOCH 3 - PROGRESS: at 32.40% examples, 196570 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:27,540 : INFO : EPOCH 3 - PROGRESS: at 50.84% examples, 205189 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:28,571 : INFO : EPOCH 3 - PROGRESS: at 70.39% examples, 211500 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:29,579 : INFO : EPOCH 3 - PROGRESS: at 88.83% examples, 214769 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:05:30,118 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:05:30,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:05:30,196 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:05:30,196 : INFO : EPOCH - 3 : training on 1788017 raw words (1241916 effective words) took 5.8s, 215587 effective words/s\n",
      "2020-04-17 15:05:31,325 : INFO : EPOCH 4 - PROGRESS: at 17.32% examples, 214495 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:32,330 : INFO : EPOCH 4 - PROGRESS: at 35.75% examples, 221842 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:33,360 : INFO : EPOCH 4 - PROGRESS: at 54.75% examples, 223537 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:34,393 : INFO : EPOCH 4 - PROGRESS: at 73.74% examples, 224047 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:35,396 : INFO : EPOCH 4 - PROGRESS: at 92.18% examples, 225031 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:35,758 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:05:35,800 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:05:35,813 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:05:35,813 : INFO : EPOCH - 4 : training on 1788017 raw words (1242417 effective words) took 5.5s, 225346 effective words/s\n",
      "2020-04-17 15:05:36,850 : INFO : EPOCH 5 - PROGRESS: at 15.64% examples, 194661 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:37,860 : INFO : EPOCH 5 - PROGRESS: at 34.08% examples, 211419 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:38,863 : INFO : EPOCH 5 - PROGRESS: at 52.51% examples, 216646 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:39,890 : INFO : EPOCH 5 - PROGRESS: at 71.51% examples, 218880 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:40,915 : INFO : EPOCH 5 - PROGRESS: at 90.50% examples, 221480 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:41,370 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:05:41,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:05:41,446 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:05:41,446 : INFO : EPOCH - 5 : training on 1788017 raw words (1242091 effective words) took 5.6s, 221179 effective words/s\n",
      "2020-04-17 15:05:41,447 : INFO : training on a 8940085 raw words (6211665 effective words) took 28.7s, 216357 effective words/s\n",
      "2020-04-17 15:05:41,465 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:05:41,566 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #22: {'train_data': '10MB', 'compute_loss': True, 'sg': 1, 'hs': 1, 'train_time_mean': 34.45679942766825, 'train_time_std': 1.1719151413204352}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:05:41,874 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:05:41,874 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:05:41,915 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:05:41,916 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:05:41,959 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:05:41,963 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:05:41,964 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:05:41,980 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:05:44,951 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:05:44,983 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:05:44,984 : INFO : resetting layer weights\n",
      "2020-04-17 15:05:48,172 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:05:49,243 : INFO : EPOCH 1 - PROGRESS: at 15.64% examples, 190160 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:50,256 : INFO : EPOCH 1 - PROGRESS: at 34.64% examples, 212061 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:51,322 : INFO : EPOCH 1 - PROGRESS: at 54.19% examples, 216821 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:52,322 : INFO : EPOCH 1 - PROGRESS: at 73.18% examples, 220604 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:53,328 : INFO : EPOCH 1 - PROGRESS: at 92.18% examples, 223567 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:53,687 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:05:53,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:05:53,753 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:05:53,753 : INFO : EPOCH - 1 : training on 1788017 raw words (1242505 effective words) took 5.6s, 223658 effective words/s\n",
      "2020-04-17 15:05:54,774 : INFO : EPOCH 2 - PROGRESS: at 15.64% examples, 197570 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:55,778 : INFO : EPOCH 2 - PROGRESS: at 34.64% examples, 217351 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:56,783 : INFO : EPOCH 2 - PROGRESS: at 53.63% examples, 222558 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:57,792 : INFO : EPOCH 2 - PROGRESS: at 72.63% examples, 224514 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:58,803 : INFO : EPOCH 2 - PROGRESS: at 91.06% examples, 225095 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:05:59,206 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:05:59,265 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:05:59,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:05:59,280 : INFO : EPOCH - 2 : training on 1788017 raw words (1242078 effective words) took 5.5s, 225414 effective words/s\n",
      "2020-04-17 15:06:00,393 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 218046 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:01,410 : INFO : EPOCH 3 - PROGRESS: at 36.31% examples, 225598 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:02,465 : INFO : EPOCH 3 - PROGRESS: at 55.87% examples, 226305 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:03,468 : INFO : EPOCH 3 - PROGRESS: at 74.86% examples, 228013 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:04,524 : INFO : EPOCH 3 - PROGRESS: at 94.41% examples, 228424 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:04,735 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:06:04,800 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:06:04,819 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:06:04,819 : INFO : EPOCH - 3 : training on 1788017 raw words (1241931 effective words) took 5.4s, 228519 effective words/s\n",
      "2020-04-17 15:06:05,934 : INFO : EPOCH 4 - PROGRESS: at 17.32% examples, 217172 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:06,940 : INFO : EPOCH 4 - PROGRESS: at 35.75% examples, 223047 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:07,940 : INFO : EPOCH 4 - PROGRESS: at 55.31% examples, 228752 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:08,946 : INFO : EPOCH 4 - PROGRESS: at 73.74% examples, 227810 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:09,978 : INFO : EPOCH 4 - PROGRESS: at 92.74% examples, 228200 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:10,288 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:06:10,343 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:06:10,360 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:06:10,360 : INFO : EPOCH - 4 : training on 1788017 raw words (1242647 effective words) took 5.4s, 228467 effective words/s\n",
      "2020-04-17 15:06:11,470 : INFO : EPOCH 5 - PROGRESS: at 17.32% examples, 218559 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:12,482 : INFO : EPOCH 5 - PROGRESS: at 36.31% examples, 226185 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:13,526 : INFO : EPOCH 5 - PROGRESS: at 55.87% examples, 227693 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:14,530 : INFO : EPOCH 5 - PROGRESS: at 74.86% examples, 228926 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:15,557 : INFO : EPOCH 5 - PROGRESS: at 93.85% examples, 229123 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:15,822 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:06:15,863 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:06:15,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:06:15,869 : INFO : EPOCH - 5 : training on 1788017 raw words (1242013 effective words) took 5.4s, 229800 effective words/s\n",
      "2020-04-17 15:06:15,870 : INFO : training on a 8940085 raw words (6211174 effective words) took 27.7s, 224249 effective words/s\n",
      "2020-04-17 15:06:15,888 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:06:15,988 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:06:16,290 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:06:16,291 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:06:16,334 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:06:16,334 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:06:16,380 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:06:16,384 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:06:16,385 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:06:16,401 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:06:16,813 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:06:16,841 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:06:16,841 : INFO : resetting layer weights\n",
      "2020-04-17 15:06:19,968 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:06:21,091 : INFO : EPOCH 1 - PROGRESS: at 17.32% examples, 215051 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:22,110 : INFO : EPOCH 1 - PROGRESS: at 36.31% examples, 224014 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:23,162 : INFO : EPOCH 1 - PROGRESS: at 55.87% examples, 225482 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:24,191 : INFO : EPOCH 1 - PROGRESS: at 75.42% examples, 227690 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:25,220 : INFO : EPOCH 1 - PROGRESS: at 94.41% examples, 227852 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:25,446 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:06:25,500 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:06:25,509 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:06:25,509 : INFO : EPOCH - 1 : training on 1788017 raw words (1241447 effective words) took 5.4s, 228204 effective words/s\n",
      "2020-04-17 15:06:26,641 : INFO : EPOCH 2 - PROGRESS: at 17.32% examples, 214132 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:27,643 : INFO : EPOCH 2 - PROGRESS: at 36.31% examples, 225250 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:28,707 : INFO : EPOCH 2 - PROGRESS: at 55.87% examples, 225452 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:29,755 : INFO : EPOCH 2 - PROGRESS: at 74.30% examples, 223118 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:30,755 : INFO : EPOCH 2 - PROGRESS: at 93.30% examples, 225659 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:31,055 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:06:31,121 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:06:31,131 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:06:31,132 : INFO : EPOCH - 2 : training on 1788017 raw words (1242104 effective words) took 5.5s, 225093 effective words/s\n",
      "2020-04-17 15:06:32,265 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 213315 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:33,274 : INFO : EPOCH 3 - PROGRESS: at 36.31% examples, 224071 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:34,325 : INFO : EPOCH 3 - PROGRESS: at 55.87% examples, 225764 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:35,348 : INFO : EPOCH 3 - PROGRESS: at 75.42% examples, 228182 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:36,375 : INFO : EPOCH 3 - PROGRESS: at 94.41% examples, 228476 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:36,602 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:06:36,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:06:36,678 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:06:36,679 : INFO : EPOCH - 3 : training on 1788017 raw words (1242455 effective words) took 5.4s, 228213 effective words/s\n",
      "2020-04-17 15:06:37,720 : INFO : EPOCH 4 - PROGRESS: at 16.20% examples, 200833 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:38,728 : INFO : EPOCH 4 - PROGRESS: at 35.20% examples, 218124 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:39,766 : INFO : EPOCH 4 - PROGRESS: at 54.19% examples, 220592 words/s, in_qsize 6, out_qsize 0\n",
      "2020-04-17 15:06:40,788 : INFO : EPOCH 4 - PROGRESS: at 73.74% examples, 224092 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:41,809 : INFO : EPOCH 4 - PROGRESS: at 92.74% examples, 225617 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:42,130 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:06:42,183 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:06:42,192 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:06:42,192 : INFO : EPOCH - 4 : training on 1788017 raw words (1242586 effective words) took 5.5s, 226018 effective words/s\n",
      "2020-04-17 15:06:43,313 : INFO : EPOCH 5 - PROGRESS: at 17.32% examples, 216034 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:44,336 : INFO : EPOCH 5 - PROGRESS: at 36.87% examples, 227312 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:45,359 : INFO : EPOCH 5 - PROGRESS: at 55.87% examples, 227653 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:46,360 : INFO : EPOCH 5 - PROGRESS: at 74.86% examples, 229083 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:47,396 : INFO : EPOCH 5 - PROGRESS: at 93.85% examples, 228854 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:47,662 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:06:47,698 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:06:47,712 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:06:47,712 : INFO : EPOCH - 5 : training on 1788017 raw words (1242547 effective words) took 5.4s, 229374 effective words/s\n",
      "2020-04-17 15:06:47,713 : INFO : training on a 8940085 raw words (6211139 effective words) took 27.7s, 223868 effective words/s\n",
      "2020-04-17 15:06:47,730 : INFO : collecting all words and their counts\n",
      "2020-04-17 15:06:47,832 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-17 15:06:48,133 : INFO : collected 73167 word types from a corpus of 1788017 raw words and 179 sentences\n",
      "2020-04-17 15:06:48,133 : INFO : Loading a fresh vocabulary\n",
      "2020-04-17 15:06:48,178 : INFO : effective_min_count=5 retains 20167 unique words (27% of original 73167, drops 53000)\n",
      "2020-04-17 15:06:48,179 : INFO : effective_min_count=5 leaves 1703716 word corpus (95% of original 1788017, drops 84301)\n",
      "2020-04-17 15:06:48,223 : INFO : deleting the raw counts dictionary of 73167 items\n",
      "2020-04-17 15:06:48,226 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-04-17 15:06:48,227 : INFO : downsampling leaves estimated 1242287 word corpus (72.9% of prior 1703716)\n",
      "2020-04-17 15:06:48,243 : INFO : constructing a huffman tree from 20167 words\n",
      "2020-04-17 15:06:48,644 : INFO : built huffman tree with maximum node depth 18\n",
      "2020-04-17 15:06:48,672 : INFO : estimated required memory for 20167 words and 100 dimensions: 38317300 bytes\n",
      "2020-04-17 15:06:48,673 : INFO : resetting layer weights\n",
      "2020-04-17 15:06:51,932 : INFO : training model with 3 workers on 20167 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2020-04-17 15:06:53,070 : INFO : EPOCH 1 - PROGRESS: at 16.76% examples, 209547 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:54,103 : INFO : EPOCH 1 - PROGRESS: at 32.96% examples, 202908 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:55,109 : INFO : EPOCH 1 - PROGRESS: at 49.16% examples, 202028 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:56,121 : INFO : EPOCH 1 - PROGRESS: at 67.60% examples, 206478 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:57,163 : INFO : EPOCH 1 - PROGRESS: at 84.36% examples, 205530 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:06:58,175 : INFO : EPOCH 1 - PROGRESS: at 97.77% examples, 198755 words/s, in_qsize 4, out_qsize 0\n",
      "2020-04-17 15:06:58,183 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:06:58,269 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:06:58,281 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:06:58,282 : INFO : EPOCH - 1 : training on 1788017 raw words (1242808 effective words) took 6.2s, 199532 effective words/s\n",
      "2020-04-17 15:06:59,317 : INFO : EPOCH 2 - PROGRESS: at 12.85% examples, 161362 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:00,343 : INFO : EPOCH 2 - PROGRESS: at 31.28% examples, 193473 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:01,348 : INFO : EPOCH 2 - PROGRESS: at 50.28% examples, 206963 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:02,373 : INFO : EPOCH 2 - PROGRESS: at 69.83% examples, 213308 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:03,417 : INFO : EPOCH 2 - PROGRESS: at 88.83% examples, 216157 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:03,941 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:07:03,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:07:04,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:07:04,017 : INFO : EPOCH - 2 : training on 1788017 raw words (1242546 effective words) took 5.7s, 217499 effective words/s\n",
      "2020-04-17 15:07:05,133 : INFO : EPOCH 3 - PROGRESS: at 17.32% examples, 216402 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:06,143 : INFO : EPOCH 3 - PROGRESS: at 36.31% examples, 225331 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:07,188 : INFO : EPOCH 3 - PROGRESS: at 55.87% examples, 226839 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:08,191 : INFO : EPOCH 3 - PROGRESS: at 74.86% examples, 228429 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:09,221 : INFO : EPOCH 3 - PROGRESS: at 93.85% examples, 228536 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 15:07:09,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:07:09,527 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:07:09,540 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:07:09,541 : INFO : EPOCH - 3 : training on 1788017 raw words (1241166 effective words) took 5.4s, 228895 effective words/s\n",
      "2020-04-17 15:07:10,667 : INFO : EPOCH 4 - PROGRESS: at 17.88% examples, 221939 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:11,674 : INFO : EPOCH 4 - PROGRESS: at 36.31% examples, 225039 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:12,682 : INFO : EPOCH 4 - PROGRESS: at 54.75% examples, 225103 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:13,692 : INFO : EPOCH 4 - PROGRESS: at 73.74% examples, 226485 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:14,701 : INFO : EPOCH 4 - PROGRESS: at 92.74% examples, 228098 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:15,026 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:07:15,081 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:07:15,089 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:07:15,090 : INFO : EPOCH - 4 : training on 1788017 raw words (1242501 effective words) took 5.4s, 228105 effective words/s\n",
      "2020-04-17 15:07:16,129 : INFO : EPOCH 5 - PROGRESS: at 15.64% examples, 193821 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:17,153 : INFO : EPOCH 5 - PROGRESS: at 34.64% examples, 213196 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:18,203 : INFO : EPOCH 5 - PROGRESS: at 54.19% examples, 218665 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:19,207 : INFO : EPOCH 5 - PROGRESS: at 73.74% examples, 223506 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:20,254 : INFO : EPOCH 5 - PROGRESS: at 92.74% examples, 224005 words/s, in_qsize 5, out_qsize 0\n",
      "2020-04-17 15:07:20,564 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-17 15:07:20,622 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-17 15:07:20,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-17 15:07:20,642 : INFO : EPOCH - 5 : training on 1788017 raw words (1242068 effective words) took 5.5s, 224385 effective words/s\n",
      "2020-04-17 15:07:20,642 : INFO : training on a 8940085 raw words (6211089 effective words) took 28.7s, 216340 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model #23: {'train_data': '10MB', 'compute_loss': False, 'sg': 1, 'hs': 1, 'train_time_mean': 33.0646603902181, 'train_time_std': 1.0580181685249426}\n",
      "   train_data  compute_loss  sg  hs  train_time_mean  train_time_std\n",
      "4        25kB          True   1   0         0.641856        0.003553\n",
      "5        25kB         False   1   0         0.706347        0.041496\n",
      "6        25kB          True   1   1         1.084956        0.117828\n",
      "7        25kB         False   1   1         0.999427        0.022375\n",
      "0        25kB          True   0   0         0.469475        0.016243\n",
      "1        25kB         False   0   0         0.442190        0.003510\n",
      "2        25kB          True   0   1         0.563282        0.004206\n",
      "3        25kB         False   0   1         0.550286        0.001170\n",
      "12        1MB          True   1   0         1.824892        0.013058\n",
      "13        1MB         False   1   0         1.807248        0.003884\n",
      "14        1MB          True   1   1         3.053651        0.005384\n",
      "15        1MB         False   1   1         2.988721        0.008065\n",
      "8         1MB          True   0   0         1.150029        0.027173\n",
      "9         1MB         False   0   0         1.105867        0.013164\n",
      "10        1MB          True   0   1         1.490992        0.024463\n",
      "11        1MB         False   0   1         1.470833        0.013612\n",
      "20       10MB          True   1   0        19.601178        0.267495\n",
      "21       10MB         False   1   0        18.330135        0.717074\n",
      "22       10MB          True   1   1        34.456799        1.171915\n",
      "23       10MB         False   1   1        33.064660        1.058018\n",
      "16       10MB          True   0   0        10.255047        1.235742\n",
      "17       10MB         False   0   0         9.338945        0.634027\n",
      "18       10MB          True   0   1        13.668075        0.568889\n",
      "19       10MB         False   0   1        13.289937        0.537871\n"
     ]
    }
   ],
   "source": [
    "# Temporarily reduce logging verbosity\n",
    "logging.root.level = logging.ERROR\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_time_values = []\n",
    "seed_val = 42\n",
    "sg_values = [0, 1]\n",
    "hs_values = [0, 1]\n",
    "\n",
    "fast = True\n",
    "if fast:\n",
    "    input_data_subset = input_data[:3]\n",
    "else:\n",
    "    input_data_subset = input_data\n",
    "\n",
    "\n",
    "for data in input_data_subset:\n",
    "    for sg_val in sg_values:\n",
    "        for hs_val in hs_values:\n",
    "            for loss_flag in [True, False]:\n",
    "                time_taken_list = []\n",
    "                for i in range(3):\n",
    "                    start_time = time.time()\n",
    "                    w2v_model = gensim.models.Word2Vec(\n",
    "                        data,\n",
    "                        compute_loss=loss_flag,\n",
    "                        sg=sg_val,\n",
    "                        hs=hs_val,\n",
    "                        seed=seed_val,\n",
    "                    )\n",
    "                    time_taken_list.append(time.time() - start_time)\n",
    "\n",
    "                time_taken_list = np.array(time_taken_list)\n",
    "                time_mean = np.mean(time_taken_list)\n",
    "                time_std = np.std(time_taken_list)\n",
    "\n",
    "                model_result = {\n",
    "                    'train_data': data.name,\n",
    "                    'compute_loss': loss_flag,\n",
    "                    'sg': sg_val,\n",
    "                    'hs': hs_val,\n",
    "                    'train_time_mean': time_mean,\n",
    "                    'train_time_std': time_std,\n",
    "                }\n",
    "                print(\"Word2vec model #%i: %s\" % (len(train_time_values), model_result))\n",
    "                train_time_values.append(model_result)\n",
    "\n",
    "train_times_table = pd.DataFrame(train_time_values)\n",
    "train_times_table = train_times_table.sort_values(\n",
    "    by=['train_data', 'sg', 'hs', 'compute_loss'],\n",
    "    ascending=[False, False, True, False],\n",
    ")\n",
    "print(train_times_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Word2Vec \"model to dict\" method to production pipeline\n",
    "-------------------------------------------------------------\n",
    "\n",
    "Suppose, we still want more performance improvement in production.\n",
    "\n",
    "One good way is to cache all the similar words in a dictionary.\n",
    "\n",
    "So that next time when we get the similar query word, we'll search it first in the dict.\n",
    "\n",
    "And if it's a hit then we will show the result directly from the dictionary.\n",
    "\n",
    "otherwise we will query the word and then cache it so that it doesn't miss next time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-17 19:32:50,580 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the [('first', 0.9999039173126221), ('an', 0.9999021291732788), ('against', 0.9998972415924072), ('its', 0.9998953342437744), ('his', 0.9998934268951416), ('two', 0.9998933672904968), ('one', 0.999891996383667), ('and', 0.9998893141746521), ('after', 0.999887228012085), ('of', 0.9998849034309387)]\n",
      "to [('or', 0.9999405145645142), ('will', 0.9999387264251709), ('are', 0.9999384880065918), ('if', 0.999937891960144), ('out', 0.9999355673789978), ('has', 0.9999327659606934), ('about', 0.9999327659606934), ('from', 0.9999326467514038), ('and', 0.9999295473098755), ('with', 0.9999294281005859)]\n",
      "of [('first', 0.9999454617500305), ('by', 0.9999425411224365), ('on', 0.9999414682388306), ('after', 0.999940812587738), ('in', 0.9999327659606934), ('three', 0.9999324083328247), ('with', 0.9999293088912964), ('which', 0.9999275207519531), ('over', 0.999925971031189), ('at', 0.9999222755432129)]\n"
     ]
    }
   ],
   "source": [
    "# re-enable logging\n",
    "logging.root.level = logging.INFO\n",
    "\n",
    "most_similars_precalc = {word : model.wv.most_similar(word) for word in model.wv.index2word}\n",
    "for i, (key, value) in enumerate(most_similars_precalc.items()):\n",
    "    if i == 3:\n",
    "        break\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with and without caching\n",
    "-----------------------------------\n",
    "\n",
    "for time being lets take 4 words randomly\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "words = ['voted', 'few', 'their', 'around']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without caching\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('team', 0.9988727569580078), ('than', 0.9988700747489929), ('died', 0.9988337159156799), ('seekers', 0.998832106590271), ('australia', 0.9988315105438232), ('power', 0.998828649520874), ('killed', 0.9988218545913696), ('saying', 0.9988198280334473), ('hospital', 0.9988188147544861), ('meeting', 0.9988039135932922)]\n",
      "[('their', 0.9997981786727905), ('also', 0.9997972249984741), ('other', 0.9997957348823547), ('at', 0.9997896552085876), ('an', 0.9997894763946533), ('as', 0.9997888803482056), ('about', 0.9997838139533997), ('to', 0.9997806549072266), ('under', 0.9997791051864624), ('one', 0.9997783899307251)]\n",
      "[('and', 0.9999499320983887), ('about', 0.999947190284729), ('have', 0.9999425411224365), ('also', 0.9999412894248962), ('with', 0.9999408721923828), ('us', 0.9999403357505798), ('its', 0.9999401569366455), ('are', 0.9999364018440247), ('out', 0.9999362230300903), ('at', 0.9999358654022217)]\n",
      "[('as', 0.9999256134033203), ('today', 0.9999256134033203), ('over', 0.9999226927757263), ('about', 0.999922513961792), ('with', 0.9999223947525024), ('some', 0.9999220371246338), ('by', 0.9999199509620667), ('on', 0.9999194145202637), ('four', 0.9999187588691711), ('are', 0.9999184012413025)]\n",
      "0.002424955368041992\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for word in words:\n",
    "    result = model.wv.most_similar(word)\n",
    "    print(result)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with caching\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('team', 0.9988727569580078), ('than', 0.9988700747489929), ('died', 0.9988337159156799), ('seekers', 0.998832106590271), ('australia', 0.9988315105438232), ('power', 0.998828649520874), ('killed', 0.9988218545913696), ('saying', 0.9988198280334473), ('hospital', 0.9988188147544861), ('meeting', 0.9988039135932922)]\n",
      "[('their', 0.9997981786727905), ('also', 0.9997972249984741), ('other', 0.9997957348823547), ('at', 0.9997896552085876), ('an', 0.9997894763946533), ('as', 0.9997888803482056), ('about', 0.9997838139533997), ('to', 0.9997806549072266), ('under', 0.9997791051864624), ('one', 0.9997783899307251)]\n",
      "[('and', 0.9999499320983887), ('about', 0.999947190284729), ('have', 0.9999425411224365), ('also', 0.9999412894248962), ('with', 0.9999408721923828), ('us', 0.9999403357505798), ('its', 0.9999401569366455), ('are', 0.9999364018440247), ('out', 0.9999362230300903), ('at', 0.9999358654022217)]\n",
      "[('as', 0.9999256134033203), ('today', 0.9999256134033203), ('over', 0.9999226927757263), ('about', 0.999922513961792), ('with', 0.9999223947525024), ('some', 0.9999220371246338), ('by', 0.9999199509620667), ('on', 0.9999194145202637), ('four', 0.9999187588691711), ('are', 0.9999184012413025)]\n",
      "0.0006899833679199219\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for word in words:\n",
    "    if 'voted' in most_similars_precalc:\n",
    "        result = most_similars_precalc[word]\n",
    "        print(result)\n",
    "    else:\n",
    "        result = model.wv.most_similar(word)\n",
    "        most_similars_precalc[word] = result\n",
    "        print(result)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly you can see the improvement but this difference will be even larger\n",
    "when we take more words in the consideration.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising the Word Embeddings\n",
    "-------------------------------\n",
    "\n",
    "The word embeddings made by the model can be visualised by reducing\n",
    "dimensionality of the words to 2 dimensions using tSNE.\n",
    "\n",
    "Visualisations can be used to notice semantic and syntactic trends in the data.\n",
    "\n",
    "Example:\n",
    "\n",
    "* Semantic: words like cat, dog, cow, etc. have a tendency to lie close by\n",
    "* Syntactic: words like run, running or cut, cutting lie close together.\n",
    "\n",
    "Vector relations like vKing - vMan = vQueen - vWoman can also be noticed.\n",
    "\n",
    ".. Important::\n",
    "  The model used for the visualisation is trained on a small corpus. Thus\n",
    "  some of the relations might not be so clear.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "mode": "text",
         "text": [
          "hundreds",
          "of",
          "people",
          "have",
          "been",
          "forced",
          "to",
          "their",
          "homes",
          "in",
          "the",
          "southern",
          "new",
          "south",
          "wales",
          "as",
          "strong",
          "winds",
          "today",
          "huge",
          "towards",
          "town",
          "hill",
          "top",
          "blaze",
          "near",
          "west",
          "sydney",
          "has",
          "highway",
          "at",
          "about",
          "pm",
          "aedt",
          "weather",
          "storm",
          "moved",
          "east",
          "across",
          "blue",
          "mountains",
          "authorities",
          "make",
          "decision",
          "from",
          "streets",
          "an",
          "residents",
          "left",
          "for",
          "nearby",
          "rural",
          "fire",
          "service",
          "says",
          "conditions",
          "which",
          "caused",
          "now",
          "and",
          "around",
          "are",
          "all",
          "more",
          "than",
          "blazes",
          "on",
          "year",
          "eve",
          "crews",
          "called",
          "while",
          "few",
          "details",
          "available",
          "this",
          "stage",
          "it",
          "closed",
          "both",
          "meanwhile",
          "is",
          "no",
          "longer",
          "threatening",
          "area",
          "rain",
          "some",
          "parts",
          "illawarra",
          "hunter",
          "north",
          "coast",
          "but",
          "bureau",
          "done",
          "little",
          "any",
          "hundred",
          "fires",
          "still",
          "burning",
          "state",
          "quite",
          "those",
          "areas",
          "less",
          "five",
          "she",
          "said",
          "places",
          "really",
          "not",
          "significant",
          "so",
          "there",
          "much",
          "far",
          "concerned",
          "fact",
          "they",
          "ve",
          "probably",
          "efforts",
          "firefighters",
          "because",
          "wind",
          "that",
          "with",
          "indian",
          "security",
          "forces",
          "shot",
          "dead",
          "eight",
          "suspected",
          "militants",
          "night",
          "long",
          "kashmir",
          "took",
          "place",
          "capital",
          "deaths",
          "came",
          "pakistani",
          "police",
          "arrested",
          "two",
          "groups",
          "accused",
          "attack",
          "india",
          "parliament",
          "pakistan",
          "based",
          "mohammad",
          "carrying",
          "out",
          "december",
          "military",
          "intelligence",
          "tensions",
          "since",
          "raid",
          "sides",
          "troops",
          "along",
          "border",
          "trading",
          "diplomatic",
          "yesterday",
          "announced",
          "had",
          "chief",
          "mohammed",
          "say",
          "likely",
          "raids",
          "will",
          "be",
          "launched",
          "against",
          "well",
          "other",
          "militant",
          "organisations",
          "between",
          "level",
          "seen",
          "war",
          "national",
          "road",
          "toll",
          "christmas",
          "holiday",
          "period",
          "same",
          "time",
          "last",
          "died",
          "roads",
          "queensland",
          "victoria",
          "western",
          "australia",
          "northern",
          "territory",
          "each",
          "recorded",
          "three",
          "act",
          "tasmania",
          "remain",
          "free",
          "argentina",
          "political",
          "economic",
          "crisis",
          "its",
          "interim",
          "president",
          "who",
          "office",
          "just",
          "week",
          "ago",
          "told",
          "nation",
          "he",
          "could",
          "rescue",
          "key",
          "fellow",
          "would",
          "support",
          "his",
          "massive",
          "foreign",
          "debt",
          "or",
          "plan",
          "was",
          "only",
          "million",
          "jobs",
          "end",
          "four",
          "years",
          "recession",
          "days",
          "after",
          "following",
          "series",
          "failed",
          "senate",
          "leader",
          "until",
          "government",
          "too",
          "another",
          "senior",
          "role",
          "elections",
          "scheduled",
          "march",
          "leaving",
          "worst",
          "by",
          "international",
          "six",
          "suspended",
          "hospital",
          "inappropriate",
          "use",
          "during",
          "work",
          "hours",
          "women",
          "were",
          "labour",
          "health",
          "investigation",
          "further",
          "within",
          "executive",
          "officer",
          "tony",
          "one",
          "put",
          "risk",
          "staff",
          "involved",
          "able",
          "take",
          "over",
          "we",
          "re",
          "very",
          "body",
          "our",
          "these",
          "should",
          "know",
          "better",
          "why",
          "action",
          "them",
          "ll",
          "next",
          "federal",
          "asylum",
          "seekers",
          "return",
          "home",
          "when",
          "environment",
          "secure",
          "kabul",
          "affairs",
          "minister",
          "alexander",
          "downer",
          "refused",
          "how",
          "claims",
          "process",
          "hold",
          "major",
          "threat",
          "most",
          "seeking",
          "many",
          "tried",
          "get",
          "into",
          "matter",
          "britain",
          "countries",
          "europe",
          "claimed",
          "fleeing",
          "taliban",
          "power",
          "afghanistan",
          "finished",
          "mass",
          "detainees",
          "island",
          "pacific",
          "nauru",
          "total",
          "operations",
          "using",
          "aircraft",
          "second",
          "delivered",
          "where",
          "temporary",
          "department",
          "immigration",
          "remaining",
          "spokesman",
          "future",
          "yet",
          "made",
          "united",
          "states",
          "team",
          "seles",
          "michael",
          "scored",
          "victory",
          "france",
          "first",
          "hopman",
          "cup",
          "match",
          "perth",
          "up",
          "event",
          "won",
          "singles",
          "give",
          "us",
          "lead",
          "old",
          "currently",
          "start",
          "fight",
          "hard",
          "winning",
          "then",
          "st",
          "down",
          "determined",
          "th",
          "win",
          "americans",
          "go",
          "swiss",
          "final",
          "great",
          "way",
          "tennis",
          "got",
          "my",
          "am",
          "beat",
          "him",
          "even",
          "though",
          "bit",
          "here",
          "keep",
          "if",
          "do",
          "think",
          "chance",
          "anyone",
          "playing",
          "before",
          "taking",
          "set",
          "american",
          "breaking",
          "third",
          "games",
          "expected",
          "her",
          "tough",
          "player",
          "world",
          "position",
          "you",
          "play",
          "want",
          "try",
          "early",
          "season",
          "opening",
          "quickly",
          "game",
          "completed",
          "despite",
          "celebrations",
          "river",
          "kilometres",
          "battling",
          "hot",
          "melbourne",
          "strongly",
          "contested",
          "afternoon",
          "thursday",
          "line",
          "others",
          "fell",
          "red",
          "cross",
          "overnight",
          "containment",
          "lines",
          "severe",
          "getting",
          "forecast",
          "continue",
          "temperatures",
          "high",
          "least",
          "friday",
          "means",
          "fighters",
          "guard",
          "lot",
          "known",
          "contained",
          "however",
          "given",
          "coming",
          "property",
          "greater",
          "brought",
          "under",
          "control",
          "spencer",
          "city",
          "lower",
          "kilometre",
          "protect",
          "communities",
          "morning",
          "large",
          "above",
          "also",
          "used",
          "drop",
          "commissioner",
          "activity",
          "smoke",
          "being",
          "asked",
          "avoid",
          "reduced",
          "hour",
          "access",
          "royal",
          "park",
          "local",
          "allowed",
          "continuing",
          "thousands",
          "storms",
          "struck",
          "force",
          "trees",
          "cars",
          "energy",
          "every",
          "person",
          "working",
          "through",
          "brisbane",
          "toowoomba",
          "car",
          "inside",
          "fierce",
          "sent",
          "tree",
          "house",
          "injured",
          "entered",
          "official",
          "killed",
          "destroyed",
          "part",
          "began",
          "heritage",
          "traditional",
          "trapped",
          "flames",
          "markets",
          "buildings",
          "blame",
          "death",
          "themselves",
          "victims",
          "public",
          "cut",
          "short",
          "inquiry",
          "general",
          "musharraf",
          "wants",
          "prepared",
          "respond",
          "peace",
          "reduce",
          "tension",
          "move",
          "taken",
          "measures",
          "armed",
          "face",
          "might",
          "received",
          "parties",
          "welcomed",
          "community",
          "trying",
          "like",
          "positive",
          "union",
          "group",
          "nations",
          "among",
          "resolve",
          "stand",
          "off",
          "offer",
          "holding",
          "talks",
          "prime",
          "saying",
          "gives",
          "me",
          "accept",
          "reject",
          "meet",
          "january",
          "regional",
          "cooperation",
          "summit",
          "ruled",
          "assault",
          "warned",
          "saturday",
          "dispute",
          "growing",
          "small",
          "conflict",
          "sunday",
          "meeting",
          "situation",
          "domestic",
          "society",
          "form",
          "terrorism",
          "eastern",
          "afghan",
          "british",
          "officials",
          "ended",
          "without",
          "agreement",
          "lack",
          "document",
          "delay",
          "giving",
          "weeks",
          "number",
          "peacekeepers",
          "allow",
          "dr",
          "appeared",
          "signed",
          "already",
          "soon",
          "nothing",
          "sign",
          "proposals",
          "commanders",
          "occupation",
          "israeli",
          "army",
          "palestinian",
          "attacked",
          "gaza",
          "strip",
          "palestinians",
          "opened",
          "vehicle",
          "jewish",
          "edge",
          "sources",
          "post",
          "gunmen",
          "killing",
          "months",
          "including",
          "israelis",
          "october",
          "radical",
          "islamic",
          "hamas",
          "settlement",
          "can",
          "stop",
          "overall",
          "honours",
          "hobart",
          "yacht",
          "race",
          "ian",
          "boat",
          "appears",
          "title",
          "rival",
          "away",
          "nine",
          "metre",
          "boats",
          "australian",
          "losing",
          "geoff",
          "point",
          "apparently",
          "reported",
          "injuries",
          "africa",
          "spinner",
          "test",
          "african",
          "squad",
          "tour",
          "due",
          "injury",
          "captain",
          "shaun",
          "pollock",
          "hopes",
          "prepare",
          "ready",
          "going",
          "come",
          "best",
          "possible",
          "begun",
          "campaign",
          "doubles",
          "hoping",
          "nice",
          "always",
          "good",
          "looking",
          "forward",
          "see",
          "again",
          "hewitt",
          "putting",
          "pressure",
          "himself",
          "month",
          "open",
          "switzerland",
          "tie",
          "reach",
          "grand",
          "per",
          "cent",
          "happens",
          "times",
          "sort",
          "zealand",
          "lord",
          "director",
          "peter",
          "list",
          "seven",
          "classic",
          "country",
          "order",
          "budget",
          "biggest",
          "ever",
          "become",
          "dropped",
          "front",
          "predicted",
          "change",
          "mark",
          "williams",
          "incident",
          "region",
          "back",
          "close",
          "mr",
          "something",
          "don",
          "banks",
          "help",
          "payment",
          "workers",
          "issued",
          "leaders",
          "banking",
          "what",
          "happened",
          "monday",
          "man",
          "crash",
          "mid",
          "boy",
          "hit",
          "telephone",
          "remains",
          "condition",
          "petrol",
          "david",
          "laws",
          "hoped",
          "built",
          "prior",
          "required",
          "such",
          "increase",
          "separate",
          "flights",
          "gun",
          "carry",
          "finally",
          "stopped",
          "plane",
          "travelled",
          "attempting",
          "board",
          "flight",
          "personnel",
          "hand",
          "released",
          "planning",
          "terrorist",
          "ability",
          "airline",
          "problems",
          "follows",
          "paris",
          "explosives",
          "shoes",
          "tourists",
          "safety",
          "central",
          "emergency",
          "search",
          "became",
          "soft",
          "ground",
          "unit",
          "officers",
          "walk",
          "winner",
          "decided",
          "gary",
          "crossed",
          "almost",
          "half",
          "fleet",
          "leading",
          "victorian",
          "minute",
          "clear",
          "fast",
          "skipper",
          "blake",
          "successful",
          "weekend",
          "lost",
          "greatest",
          "concern",
          "changes",
          "extensive",
          "conducted",
          "heading",
          "battle",
          "suicide",
          "backed",
          "never",
          "mind",
          "side",
          "round",
          "ocean",
          "assa",
          "abloy",
          "accompanied",
          "light",
          "starting",
          "crowd",
          "behind",
          "crew",
          "yachts",
          "rest",
          "laden",
          "hearing",
          "court",
          "richard",
          "reid",
          "placed",
          "wall",
          "created",
          "grant",
          "possibility",
          "later",
          "charged",
          "jail",
          "terms",
          "charges",
          "allegedly",
          "airlines",
          "enough",
          "disaster",
          "leadership",
          "calling",
          "envoy",
          "anthony",
          "zinni",
          "cease",
          "retired",
          "marine",
          "late",
          "november",
          "secretary",
          "colin",
          "powell",
          "earlier",
          "bring",
          "halt",
          "statement",
          "yasser",
          "arafat",
          "calls",
          "violence",
          "confidence",
          "building",
          "agreed",
          "several",
          "played",
          "administration",
          "believe",
          "presence",
          "effective",
          "bringing",
          "council",
          "rate",
          "hiv",
          "male",
          "sex",
          "twice",
          "report",
          "centre",
          "disease",
          "need",
          "feel",
          "statistics",
          "show",
          "previous",
          "figures",
          "wake",
          "call",
          "rise",
          "sea",
          "levels",
          "global",
          "according",
          "survey",
          "antarctic",
          "organisation",
          "giant",
          "ice",
          "vaughan",
          "case",
          "serious",
          "increased",
          "water",
          "did",
          "metres",
          "break",
          "related",
          "impact",
          "human",
          "industrial",
          "cannot",
          "problem",
          "potential",
          "cities",
          "low",
          "september",
          "shane",
          "may",
          "room",
          "outlook",
          "certainly",
          "ahead",
          "concerns",
          "continues",
          "carried",
          "mt",
          "targeted",
          "boys",
          "heights",
          "ministry",
          "embassy",
          "representation",
          "ban",
          "planes",
          "delhi",
          "ahmed",
          "actions",
          "complex",
          "mission",
          "movement",
          "added",
          "result",
          "non",
          "operating",
          "threatened",
          "defence",
          "osama",
          "bin",
          "saudi",
          "protection",
          "supporters",
          "helped",
          "create",
          "sure",
          "lives",
          "information",
          "men",
          "arrest",
          "head",
          "party",
          "al",
          "qaeda",
          "network",
          "attacks",
          "york",
          "washington",
          "collapsed",
          "completely",
          "individuals",
          "resistance",
          "mayor",
          "giuliani",
          "led",
          "past",
          "trade",
          "speaking",
          "day",
          "crime",
          "source",
          "difficult",
          "deadly",
          "comes",
          "ensure",
          "your",
          "felt",
          "job",
          "turn",
          "believed",
          "served",
          "term",
          "prevent",
          "media",
          "batsmen",
          "boxing",
          "wicket",
          "runs",
          "andy",
          "bichel",
          "langer",
          "matthew",
          "hayden",
          "went",
          "innings",
          "bowling",
          "jacques",
          "kallis",
          "neil",
          "mckenzie",
          "wickets",
          "balls",
          "caught",
          "although",
          "showed",
          "ball",
          "klusener",
          "boucher",
          "adding",
          "waugh",
          "paid",
          "brett",
          "lee",
          "leg",
          "continued",
          "field",
          "running",
          "henderson",
          "direct",
          "allan",
          "donald",
          "ricky",
          "ponting",
          "returning",
          "glenn",
          "mcgrath",
          "rafter",
          "swept",
          "nearly",
          "whether",
          "survived",
          "pulled",
          "member",
          "found",
          "helicopter",
          "big",
          "wave",
          "knew",
          "arrived",
          "damage",
          "news",
          "radio",
          "suburbs",
          "throughout",
          "average",
          "things",
          "expects",
          "john",
          "confirm",
          "criminal",
          "muslim",
          "extremists",
          "jihad",
          "beginning",
          "television",
          "held",
          "virgin",
          "attempt",
          "ansett",
          "internet",
          "travel",
          "adelaide",
          "launceston",
          "canberra",
          "customers",
          "largest",
          "base",
          "market",
          "press",
          "main",
          "business",
          "endeavour",
          "claim",
          "suffered",
          "life",
          "run",
          "land",
          "bank",
          "heavy",
          "tanks",
          "helicopters",
          "jenin",
          "attacking",
          "immediately",
          "israel",
          "soldiers",
          "returned",
          "escaped",
          "self",
          "rule",
          "authority",
          "injuring",
          "slightly",
          "fired",
          "exchange",
          "sir",
          "actor",
          "civil",
          "yes",
          "wednesday",
          "heart",
          "aged",
          "cancer",
          "having",
          "treatment",
          "awards",
          "approval",
          "range",
          "king",
          "george",
          "secret",
          "thing",
          "cricket",
          "proteas",
          "resume",
          "affected",
          "flying",
          "band",
          "expect",
          "population",
          "passed",
          "mountain",
          "confident",
          "tomorrow",
          "services",
          "whole",
          "fair",
          "share",
          "find",
          "expressed",
          "circumstances",
          "whatever",
          "needs",
          "annual",
          "speech",
          "changed",
          "itself",
          "beyond",
          "america",
          "history",
          "humanity",
          "live",
          "terror",
          "wounded",
          "fighter",
          "weapons",
          "kandahar",
          "governor",
          "custody",
          "surrender",
          "bombing",
          "airport",
          "militia",
          "handed",
          "russian",
          "important",
          "republic",
          "spread",
          "money",
          "look",
          "system",
          "project",
          "ways",
          "prisoners",
          "justice",
          "coalition",
          "families",
          "financial",
          "rights",
          "spokeswoman",
          "trial",
          "education",
          "programs",
          "ms",
          "centrelink",
          "income",
          "employment",
          "pay",
          "child",
          "shopping",
          "sergeant",
          "shortly",
          "members",
          "stuart",
          "bush",
          "question",
          "improve",
          "receiving",
          "questions",
          "pace",
          "jason",
          "gillespie",
          "right",
          "hopefully",
          "provide",
          "bowler",
          "jets",
          "saw",
          "passengers",
          "ceremony",
          "hamid",
          "karzai",
          "cabinet",
          "economy",
          "cost",
          "dollars",
          "must",
          "plans",
          "projects",
          "various",
          "believes",
          "tora",
          "bora",
          "caves",
          "visit",
          "bid",
          "does",
          "enter",
          "searching",
          "signs",
          "suspect",
          "warplanes",
          "commander",
          "charge",
          "gone",
          "pentagon",
          "macgill",
          "full",
          "steve",
          "adam",
          "warne",
          "rejected",
          "terrorists",
          "ariel",
          "sharon",
          "declared",
          "staying",
          "bombings",
          "smaller",
          "follow",
          "save",
          "young",
          "requested",
          "normal",
          "technology",
          "ill",
          "professor",
          "deputy",
          "institute",
          "law",
          "opposition",
          "thought",
          "family",
          "making",
          "japanese",
          "unidentified",
          "reports",
          "japan",
          "warning",
          "approach",
          "church",
          "handling",
          "alleged",
          "abuse",
          "anglican",
          "school",
          "howard",
          "hollingworth",
          "criticism",
          "archbishop",
          "resign",
          "costello",
          "explanation",
          "needed",
          "step",
          "understanding",
          "simon",
          "crean",
          "described",
          "legal",
          "advice",
          "heard",
          "understand",
          "gave",
          "confirmed",
          "timor",
          "comment",
          "responsibility",
          "leave",
          "company",
          "guess",
          "unity",
          "followed",
          "program",
          "fund",
          "policy",
          "effort",
          "freeze",
          "qantas",
          "maintenance",
          "relations",
          "commission",
          "employees",
          "billion",
          "gas",
          "reached",
          "phillips",
          "deal",
          "offered",
          "ministers",
          "abu",
          "worked",
          "documents",
          "factory",
          "former",
          "true",
          "read",
          "tell",
          "real",
          "detail",
          "names",
          "premier",
          "facility",
          "allegations",
          "knowledge",
          "evidence",
          "voted",
          "deployed",
          "initial",
          "mandate",
          "assistance",
          "un",
          "resolution",
          "numbers",
          "eventually",
          "germany",
          "bonn",
          "anti",
          "nuclear",
          "assisting",
          "bomb",
          "provided",
          "crackdown",
          "food",
          "clashes",
          "powers",
          "fear",
          "unrest",
          "own",
          "woomera",
          "detention",
          "visa",
          "outside",
          "recent",
          "bill",
          "private",
          "sector",
          "credit",
          "data",
          "doctors",
          "ask",
          "research",
          "companies",
          "medical",
          "record",
          "often",
          "solution",
          "consumers",
          "dozens",
          "seriously",
          "roof",
          "children",
          "witnesses",
          "collapse",
          "everything",
          "fine",
          "manager",
          "afp",
          "agency",
          "corporation",
          "son",
          "zimbabwe",
          "white",
          "commonwealth",
          "mean",
          "issue",
          "declaration",
          "table",
          "waiting",
          "response",
          "request",
          "observers",
          "election",
          "territories",
          "nablus",
          "improved",
          "pre",
          "bombers",
          "jerusalem",
          "haifa",
          "interest",
          "unfortunately",
          "robert",
          "august",
          "senator",
          "whereabouts",
          "hicks",
          "fighting",
          "alongside",
          "vote",
          "relationship",
          "operation",
          "latest",
          "stay",
          "assembly",
          "elders",
          "draft",
          "damaged",
          "current",
          "voice",
          "twenty",
          "reveal",
          "refugees",
          "australians",
          "detain",
          "transport",
          "air",
          "strachan",
          "training",
          "crashed",
          "strike",
          "accident",
          "students",
          "findings",
          "harris",
          "investment",
          "asic",
          "include",
          "counts",
          "acting",
          "management",
          "coroner",
          "investigating",
          "hearings",
          "ray",
          "qc",
          "representing",
          "experts",
          "begin",
          "named",
          "sometimes",
          "advance",
          "marines",
          "revealed",
          "captured",
          "hunt",
          "jalalabad",
          "bomber",
          "strikes",
          "actually",
          "responding",
          "insurance",
          "alliance",
          "approached",
          "july",
          "proposed",
          "labor",
          "issues",
          "options",
          "didn",
          "single",
          "anything",
          "fatah",
          "factions",
          "rather",
          "offices",
          "started",
          "tuesday",
          "focus",
          "strategic",
          "targets",
          "review",
          "meetings",
          "violent",
          "farm",
          "discussions",
          "debate",
          "disappointed",
          "philip",
          "ruddock",
          "understood",
          "attorney",
          "daryl",
          "aboard",
          "asio",
          "appropriate",
          "present",
          "finding",
          "tribal",
          "doubt",
          "pilot",
          "procedures",
          "aboriginal",
          "sentence",
          "administrators",
          "paying",
          "entitlements",
          "redundancy",
          "decide",
          "absolutely",
          "hih",
          "creditors",
          "firm",
          "chairman",
          "finance",
          "directors",
          "receive",
          "tailenders",
          "scene",
          "channel",
          "facilities",
          "whose",
          "examination",
          "unions",
          "adequate",
          "together",
          "necessary",
          "rumsfeld",
          "networks",
          "recovery",
          "decisions",
          "oil",
          "growth",
          "structure",
          "university",
          "cause",
          "negotiations",
          "club",
          "elected",
          "happy",
          "picked",
          "outcome",
          "treated",
          "hope",
          "headquarters",
          "cave",
          "interview",
          "different",
          "investigate",
          "escalating",
          "doing",
          "french",
          "negotiating",
          "address",
          "middle",
          "wanted",
          "locked",
          "wage",
          "manufacturing",
          "doug",
          "cameron",
          "seemed",
          "sharing",
          "sending",
          "quarter",
          "coup",
          "invasion",
          "shows",
          "volunteers",
          "clean",
          "track",
          "space",
          "shuttle",
          "station",
          "landed",
          "trip",
          "walked",
          "proposal",
          "publicly",
          "hotel",
          "indonesian",
          "suharto",
          "vice",
          "indonesia",
          "solomon",
          "islands",
          "ballot",
          "positions",
          "ethnic",
          "success",
          "conference",
          "met",
          "words",
          "target",
          "fall",
          "special",
          "interests",
          "promised",
          "doesn",
          "costs",
          "yallourn",
          "mining",
          "convicted",
          "whiting",
          "murder",
          "sarah",
          "career",
          "hijacked",
          "tape",
          "sheikh",
          "aware",
          "denied",
          "connection",
          "underway",
          "woman",
          "infected",
          "gunships",
          "bus",
          "ambush",
          "blasted",
          "ramallah",
          "wing",
          "responsible",
          "unemployment",
          "westpac",
          "anz",
          "bargaining",
          "industry",
          "lording",
          "construction",
          "cfmeu",
          "martin",
          "kingham",
          "faces",
          "bob",
          "neville",
          "headed",
          "clearly",
          "unable",
          "guilty",
          "verdict",
          "ford",
          "lockett",
          "interlaken",
          "tragedy",
          "adventure",
          "canyoning",
          "manslaughter",
          "guides",
          "farmers",
          "coach",
          "co",
          "friedli",
          "francs",
          "gang",
          "reserve",
          "committee",
          "drug",
          "study",
          "decades",
          "results",
          "doctor",
          "gambier",
          "path",
          "amin",
          "peres",
          "determine",
          "lung",
          "kieren",
          "champion",
          "suggested",
          "rates",
          "provisional",
          "liquidation",
          "civilians",
          "sultan",
          "course",
          "butterfly",
          "afroz",
          "goshen",
          "wayne",
          "flood",
          "gorge",
          "gerber",
          "kissinger",
          "stability",
          "replied",
          "launch",
          "davis",
          "krishna",
          "products",
          "chosen",
          "treasurer",
          "cuts",
          "natural",
          "races",
          "eliminated",
          "austar",
          "traveland",
          "apra",
          "masood",
          "tonight",
          "rabbani",
          "virus",
          "ses",
          "harrison",
          "ashes",
          "benares",
          "beatle",
          "hare",
          "choosing",
          "owen"
         ],
         "type": "scatter",
         "x": [
          6.987914085388184,
          43.54826354980469,
          35.50959396362305,
          43.52037811279297,
          35.78676223754883,
          9.408696174621582,
          44.26482009887695,
          41.10158920288086,
          4.35351037979126,
          44.0360221862793,
          39.77569580078125,
          19.828943252563477,
          41.52598190307617,
          40.75772476196289,
          47.62147521972656,
          44.56865310668945,
          45.20519256591797,
          46.80210876464844,
          36.45764923095703,
          -4.531875133514404,
          13.258060455322266,
          7.208590507507324,
          35.82487106323242,
          0.015487306751310825,
          -18.836143493652344,
          31.63606071472168,
          30.606521606445312,
          31.184629440307617,
          44.952816009521484,
          1.820544719696045,
          44.482418060302734,
          39.08378601074219,
          14.32950210571289,
          6.109614849090576,
          43.34783172607422,
          12.776952743530273,
          -9.690340995788574,
          30.935749053955078,
          44.03907012939453,
          31.785642623901367,
          44.15387725830078,
          43.7311897277832,
          44.90947341918945,
          29.260555267333984,
          44.77316665649414,
          -10.582367897033691,
          42.31787872314453,
          -20.57769012451172,
          38.344966888427734,
          43.925071716308594,
          -30.62425994873047,
          -31.286195755004883,
          33.98409652709961,
          45.71174240112305,
          44.59746551513672,
          40.229515075683594,
          40.199214935302734,
          2.1224355697631836,
          33.80079650878906,
          44.06654739379883,
          31.74947166442871,
          44.917667388916016,
          32.04639434814453,
          39.25639724731445,
          34.252689361572266,
          1.6829642057418823,
          44.97629165649414,
          38.4842643737793,
          4.953417778015137,
          0.12010091543197632,
          45.33171463012695,
          30.543581008911133,
          40.73332595825195,
          -19.884334564208984,
          -6.378032684326172,
          39.718666076660156,
          -34.588096618652344,
          39.447601318359375,
          -38.648624420166016,
          39.20075988769531,
          35.07774353027344,
          42.974761962890625,
          33.48638916015625,
          -37.96833801269531,
          1.1315548419952393,
          38.929508209228516,
          -38.97389221191406,
          33.73031997680664,
          -3.689572334289551,
          -16.913692474365234,
          3.8091561794281006,
          32.83778381347656,
          10.422080039978027,
          41.169761657714844,
          30.576438903808594,
          -39.01204299926758,
          -38.79668426513672,
          33.507503509521484,
          0.4290851652622223,
          27.455852508544922,
          31.342607498168945,
          3.3961212635040283,
          31.280067443847656,
          0.8443487286567688,
          31.42483139038086,
          33.4640007019043,
          -11.676936149597168,
          30.642818450927734,
          31.407878875732422,
          37.928951263427734,
          -39.71798324584961,
          23.265094757080078,
          39.02363586425781,
          -4.766316890716553,
          30.669742584228516,
          34.81159210205078,
          41.51511001586914,
          1.8216581344604492,
          3.230426788330078,
          -29.724624633789062,
          41.610435485839844,
          38.55814743041992,
          4.961911201477051,
          -17.809228897094727,
          43.71324920654297,
          33.74075698852539,
          -9.594724655151367,
          41.8658561706543,
          44.47113800048828,
          39.58608627319336,
          32.275848388671875,
          30.413436889648438,
          30.654552459716797,
          45.67177963256836,
          37.3435173034668,
          -3.1648926734924316,
          46.12940216064453,
          32.87460708618164,
          37.88063049316406,
          -0.8963136076927185,
          44.50675964355469,
          42.38731384277344,
          6.059698581695557,
          16.76644515991211,
          20.714794158935547,
          -1.725038766860962,
          33.465885162353516,
          35.674251556396484,
          43.87411117553711,
          42.20578384399414,
          14.957456588745117,
          35.10203552246094,
          41.15818405151367,
          7.337830066680908,
          30.620838165283203,
          10.800344467163086,
          -7.088927745819092,
          10.21823787689209,
          37.92285919189453,
          35.28931427001953,
          30.644384384155273,
          3.161557197570801,
          -24.59817886352539,
          33.06184768676758,
          2.408963203430176,
          -40.75481033325195,
          46.6843147277832,
          24.679819107055664,
          -1.7499948740005493,
          2.2572884559631348,
          -30.464757919311523,
          31.477127075195312,
          -7.487878322601318,
          40.508811950683594,
          40.0385627746582,
          5.448762893676758,
          32.967777252197266,
          1.0540947914123535,
          2.695711612701416,
          41.1400032043457,
          38.28944396972656,
          29.052671432495117,
          37.4753303527832,
          39.109134674072266,
          30.557401657104492,
          9.087465286254883,
          -29.13863754272461,
          30.3985652923584,
          -40.323280334472656,
          -36.71302795410156,
          44.4515495300293,
          32.254791259765625,
          -6.908594131469727,
          -4.832961082458496,
          46.66563415527344,
          4.0289306640625,
          -16.521997451782227,
          14.979515075683594,
          30.622661590576172,
          36.50160217285156,
          34.97077941894531,
          3.0028676986694336,
          46.544254302978516,
          -18.78224754333496,
          18.842397689819336,
          34.46419143676758,
          38.59358596801758,
          8.573155403137207,
          7.378965377807617,
          -36.03740692138672,
          36.95685577392578,
          28.101688385009766,
          -38.110877990722656,
          22.634031295776367,
          -16.722131729125977,
          -33.120208740234375,
          24.365354537963867,
          41.878318786621094,
          -39.22502517700195,
          39.25395584106445,
          46.12675476074219,
          33.126930236816406,
          41.017784118652344,
          -31.565813064575195,
          31.044876098632812,
          33.96295928955078,
          38.36670684814453,
          34.89316177368164,
          -38.479591369628906,
          34.8917236328125,
          33.85917282104492,
          -14.288857460021973,
          23.27981185913086,
          -38.04118347167969,
          36.01324462890625,
          41.68567657470703,
          40.69356918334961,
          -9.179267883300781,
          33.65803909301758,
          -35.8206787109375,
          33.81858825683594,
          1.5209753513336182,
          40.450008392333984,
          41.52452850341797,
          28.722030639648438,
          16.969324111938477,
          46.62752914428711,
          34.988197326660156,
          33.123939514160156,
          -19.801910400390625,
          30.38943099975586,
          44.8870735168457,
          38.503562927246094,
          10.265264511108398,
          9.58420467376709,
          -6.579433917999268,
          33.93428421020508,
          3.056546211242676,
          34.53274917602539,
          44.47311019897461,
          35.103919982910156,
          45.75296401977539,
          35.97626876831055,
          -38.8570442199707,
          -23.687551498413086,
          22.26546287536621,
          4.873266696929932,
          -39.77747344970703,
          44.413883209228516,
          30.83382797241211,
          33.4128303527832,
          2.3104336261749268,
          44.309326171875,
          -0.16860094666481018,
          27.545230865478516,
          34.15947341918945,
          39.789756774902344,
          36.21385955810547,
          16.762060165405273,
          43.41785430908203,
          -38.96147918701172,
          44.735633850097656,
          0.5461201071739197,
          37.5681266784668,
          8.606614112854004,
          17.68642234802246,
          -6.0369486808776855,
          -23.14546012878418,
          34.27471923828125,
          42.744815826416016,
          25.148984909057617,
          33.10593032836914,
          -3.485119104385376,
          6.474118232727051,
          38.204654693603516,
          37.035400390625,
          41.61960220336914,
          31.413101196289062,
          30.566335678100586,
          3.080000877380371,
          30.66030502319336,
          37.606109619140625,
          35.37531661987305,
          39.00955581665039,
          46.730865478515625,
          -10.749066352844238,
          30.92176628112793,
          31.718204498291016,
          -24.872760772705078,
          30.91973304748535,
          33.540771484375,
          45.08011245727539,
          46.62805938720703,
          23.170753479003906,
          33.69126892089844,
          41.30034637451172,
          -18.676288604736328,
          0.38898664712905884,
          13.314428329467773,
          -34.817501068115234,
          42.50593185424805,
          3.309807538986206,
          13.424405097961426,
          -33.231510162353516,
          43.4218864440918,
          36.98371505737305,
          22.048812866210938,
          -28.517663955688477,
          39.61042785644531,
          -39.394893646240234,
          38.80303955078125,
          -39.671905517578125,
          43.50227737426758,
          -38.275943756103516,
          33.3244514465332,
          41.87975311279297,
          -13.986112594604492,
          14.97903823852539,
          4.372488021850586,
          -9.640256881713867,
          19.131181716918945,
          -39.139678955078125,
          31.957197189331055,
          39.81092834472656,
          33.39731979370117,
          -0.9364049434661865,
          -10.115472793579102,
          38.87342071533203,
          5.15298318862915,
          12.909181594848633,
          -3.6102101802825928,
          -37.54722595214844,
          3.7609565258026123,
          4.397212505340576,
          46.618980407714844,
          31.422822952270508,
          -8.552688598632812,
          31.229232788085938,
          -10.780303001403809,
          16.171871185302734,
          1.4773128032684326,
          -37.26283645629883,
          44.930294036865234,
          -30.4558162689209,
          -26.01015853881836,
          30.99540138244629,
          31.314443588256836,
          31.9460391998291,
          38.3482666015625,
          -40.082550048828125,
          -24.883760452270508,
          -30.563228607177734,
          19.36836814880371,
          -37.38439178466797,
          38.715518951416016,
          -21.24608039855957,
          45.554195404052734,
          46.69197463989258,
          0.7391449809074402,
          36.11983871459961,
          42.22426223754883,
          43.241241455078125,
          -33.3459587097168,
          33.101680755615234,
          37.75908660888672,
          30.86635971069336,
          30.03911018371582,
          -2.1928751468658447,
          45.361000061035156,
          4.050197601318359,
          19.16622543334961,
          -37.99555587768555,
          36.10865020751953,
          -2.897313356399536,
          30.312442779541016,
          -11.603132247924805,
          22.775999069213867,
          46.57080078125,
          3.5254290103912354,
          35.45911407470703,
          5.0444135665893555,
          13.298770904541016,
          25.438161849975586,
          45.318809509277344,
          8.289924621582031,
          36.60539627075195,
          3.2120583057403564,
          39.27069091796875,
          -28.848066329956055,
          30.80890464782715,
          35.65361022949219,
          2.653472900390625,
          0.3370293378829956,
          35.31343078613281,
          -3.4422500133514404,
          39.104549407958984,
          43.112823486328125,
          30.44879722595215,
          -37.29481887817383,
          -37.00472640991211,
          -27.455867767333984,
          36.85045623779297,
          6.647802352905273,
          41.50067138671875,
          19.802261352539062,
          -1.0905125141143799,
          43.059593200683594,
          -10.098258972167969,
          46.69983673095703,
          46.746192932128906,
          -30.95551109313965,
          3.4251809120178223,
          37.50702667236328,
          9.43423843383789,
          37.23810577392578,
          46.421443939208984,
          39.59982681274414,
          -17.21309471130371,
          40.207977294921875,
          -2.9564664363861084,
          3.622525453567505,
          -5.5845489501953125,
          -37.66145324707031,
          2.6973206996917725,
          40.766536712646484,
          2.381126642227173,
          46.27322769165039,
          0.7768768072128296,
          -11.243324279785156,
          1.3919874429702759,
          32.59164047241211,
          -33.787513732910156,
          -10.135204315185547,
          -12.664132118225098,
          -24.804943084716797,
          42.239810943603516,
          18.111595153808594,
          -13.048856735229492,
          -32.42976760864258,
          -7.3390069007873535,
          45.87506866455078,
          -3.6241374015808105,
          -23.24197769165039,
          -37.23949432373047,
          3.0690786838531494,
          -30.198802947998047,
          20.498441696166992,
          4.19891357421875,
          44.2864875793457,
          3.9857664108276367,
          -22.287883758544922,
          -5.30980920791626,
          42.04185104370117,
          -23.129453659057617,
          22.760910034179688,
          -5.981528282165527,
          -9.964923858642578,
          46.57651901245117,
          45.28959274291992,
          -4.0945353507995605,
          -22.185274124145508,
          -25.281627655029297,
          6.146195411682129,
          30.2860050201416,
          44.530029296875,
          3.306323766708374,
          31.401405334472656,
          -11.918787002563477,
          -3.8501250743865967,
          -24.508567810058594,
          -19.833070755004883,
          32.39167785644531,
          7.738851070404053,
          -40.0229606628418,
          39.89200973510742,
          17.22355079650879,
          3.560041666030884,
          22.813846588134766,
          -19.240009307861328,
          -22.47272491455078,
          30.25095558166504,
          46.610191345214844,
          -11.382123947143555,
          1.626249074935913,
          5.17249870300293,
          -11.925463676452637,
          43.718849182128906,
          -14.302512168884277,
          30.41241455078125,
          -7.948243618011475,
          14.693143844604492,
          -41.54827117919922,
          2.5690503120422363,
          -24.681846618652344,
          32.5852165222168,
          13.81973648071289,
          -34.814388275146484,
          28.47663116455078,
          27.356754302978516,
          15.226593971252441,
          42.124366760253906,
          31.57302474975586,
          4.45680570602417,
          -5.006656169891357,
          -19.75687599182129,
          -6.7215352058410645,
          -32.494293212890625,
          2.389669418334961,
          -39.20911407470703,
          34.75947570800781,
          45.36567306518555,
          -34.1177978515625,
          46.36918640136719,
          33.1237678527832,
          -35.83985900878906,
          46.53801345825195,
          3.0903499126434326,
          -27.82288932800293,
          -35.3547477722168,
          4.310983180999756,
          -34.74018096923828,
          -34.77788543701172,
          4.567836284637451,
          -16.731401443481445,
          20.207515716552734,
          -38.01221466064453,
          -15.796186447143555,
          43.9334831237793,
          26.99165916442871,
          10.052141189575195,
          1.2354998588562012,
          32.393436431884766,
          -40.40824508666992,
          12.343949317932129,
          -37.392398834228516,
          -39.86723327636719,
          44.83860778808594,
          -22.13370704650879,
          5.405575752258301,
          9.353686332702637,
          28.913925170898438,
          -16.650320053100586,
          19.73105812072754,
          5.939143657684326,
          10.608657836914062,
          30.124019622802734,
          2.5709540843963623,
          -1.6192123889923096,
          20.15826988220215,
          33.21281051635742,
          42.63196563720703,
          3.202834367752075,
          30.523540496826172,
          30.599855422973633,
          19.84734535217285,
          7.093409061431885,
          -38.971866607666016,
          3.83632493019104,
          32.80936813354492,
          46.39484405517578,
          -7.848150253295898,
          44.39549255371094,
          47.02067947387695,
          46.569358825683594,
          -32.476314544677734,
          4.35276985168457,
          -28.436687469482422,
          1.0598889589309692,
          -39.4668083190918,
          2.8658688068389893,
          -38.75562286376953,
          -7.391531944274902,
          -14.994138717651367,
          -17.4328670501709,
          -41.44701385498047,
          2.895458221435547,
          -22.655797958374023,
          19.180187225341797,
          -8.01951789855957,
          -27.926645278930664,
          -38.49063491821289,
          8.087684631347656,
          30.954835891723633,
          2.3553097248077393,
          -1.0088194608688354,
          -11.572550773620605,
          -17.76847267150879,
          35.50128936767578,
          34.78249740600586,
          30.44911766052246,
          28.628705978393555,
          30.586105346679688,
          -37.20915603637695,
          46.50250244140625,
          46.40445327758789,
          -5.2202911376953125,
          -20.201690673828125,
          -12.950730323791504,
          -38.86930847167969,
          13.835660934448242,
          37.51020050048828,
          0.1412144899368286,
          10.375284194946289,
          46.29214096069336,
          -29.751590728759766,
          -39.85382843017578,
          26.175838470458984,
          -3.559138774871826,
          2.24060320854187,
          -19.84421730041504,
          -2.1240270137786865,
          -24.626150131225586,
          -17.359325408935547,
          37.45723342895508,
          15.448837280273438,
          41.25409698486328,
          2.5458695888519287,
          34.266597747802734,
          4.197531223297119,
          23.70170783996582,
          7.061214447021484,
          -8.553293228149414,
          -26.139339447021484,
          3.7157137393951416,
          -3.574228048324585,
          -1.8223719596862793,
          -38.6463623046875,
          3.5413029193878174,
          36.89820098876953,
          30.77305030822754,
          23.83656120300293,
          -33.26697540283203,
          8.988468170166016,
          30.581666946411133,
          30.4708194732666,
          -26.311922073364258,
          31.221942901611328,
          43.902278900146484,
          -36.112552642822266,
          -20.264842987060547,
          -17.553499221801758,
          4.217087268829346,
          46.810569763183594,
          -34.830360412597656,
          11.295110702514648,
          -21.375946044921875,
          0.38611164689064026,
          -26.000722885131836,
          -23.376338958740234,
          -29.373022079467773,
          -13.151965141296387,
          -2.7674028873443604,
          40.45277404785156,
          -7.354918003082275,
          -7.045730113983154,
          7.525834083557129,
          -4.6912312507629395,
          -6.5183563232421875,
          -21.118045806884766,
          41.705467224121094,
          -34.848350524902344,
          31.42625617980957,
          16.44815444946289,
          -12.63595962524414,
          -26.870031356811523,
          30.877304077148438,
          -37.69163513183594,
          44.86909484863281,
          -15.723663330078125,
          -7.405544757843018,
          -36.443328857421875,
          4.628629684448242,
          2.37267804145813,
          44.31570053100586,
          46.4326057434082,
          16.852985382080078,
          40.461368560791016,
          -5.004666805267334,
          16.687002182006836,
          -14.988764762878418,
          -13.201125144958496,
          -5.175724029541016,
          3.580205202102661,
          41.94737243652344,
          46.43574905395508,
          3.725255012512207,
          12.508380889892578,
          14.209168434143066,
          2.741330862045288,
          1.825708031654358,
          39.887508392333984,
          12.343340873718262,
          35.449378967285156,
          11.165016174316406,
          -21.736129760742188,
          -28.638446807861328,
          -4.773890495300293,
          -23.252742767333984,
          30.445005416870117,
          30.087203979492188,
          -38.83573532104492,
          4.749671459197998,
          0.16850051283836365,
          5.967921733856201,
          -36.01292419433594,
          45.23099136352539,
          40.23668670654297,
          -11.596888542175293,
          8.912400245666504,
          -39.44232177734375,
          15.123340606689453,
          -10.448219299316406,
          4.703165054321289,
          1.6666476726531982,
          -20.48003387451172,
          5.12099552154541,
          -40.16194534301758,
          -31.45691680908203,
          -27.59099769592285,
          43.09778594970703,
          27.765823364257812,
          36.75101852416992,
          -41.131614685058594,
          20.683712005615234,
          32.870643615722656,
          46.57630920410156,
          40.261104583740234,
          -26.55837631225586,
          43.693241119384766,
          -15.329122543334961,
          44.530677795410156,
          -5.181879997253418,
          31.076101303100586,
          0.24352706968784332,
          45.631797790527344,
          -0.7939931154251099,
          30.667116165161133,
          -36.570404052734375,
          44.2816162109375,
          33.58568572998047,
          9.476958274841309,
          -38.89236068725586,
          -24.060209274291992,
          44.63960647583008,
          -1.0387322902679443,
          -28.97325897216797,
          -38.40336990356445,
          4.307667255401611,
          28.026548385620117,
          6.250770568847656,
          -17.23046112060547,
          -5.82049560546875,
          -38.99724197387695,
          -17.709182739257812,
          22.90721893310547,
          -36.64759063720703,
          -16.929048538208008,
          -2.746364116668701,
          1.0964970588684082,
          2.5554492473602295,
          -3.7813520431518555,
          -31.453340530395508,
          17.719404220581055,
          -17.85003662109375,
          -7.135383129119873,
          3.31199312210083,
          4.365799903869629,
          -9.072561264038086,
          -3.3111467361450195,
          46.36495590209961,
          -24.362140655517578,
          42.318092346191406,
          -19.44611930847168,
          46.42924499511719,
          -19.879194259643555,
          -12.339325904846191,
          3.4820122718811035,
          -12.380698204040527,
          -19.094568252563477,
          0.7160146832466125,
          45.0157356262207,
          -19.173219680786133,
          9.592169761657715,
          3.6433029174804688,
          -11.664464950561523,
          -38.812286376953125,
          2.0365262031555176,
          -13.725164413452148,
          18.735227584838867,
          -20.604915618896484,
          2.9450247287750244,
          -6.866117000579834,
          -24.934768676757812,
          -38.06116485595703,
          -39.512062072753906,
          7.447065353393555,
          -41.40126419067383,
          41.80908966064453,
          -39.304561614990234,
          -39.07060623168945,
          -38.177406311035156,
          6.6142425537109375,
          -10.579299926757812,
          -32.389591217041016,
          -19.585235595703125,
          7.391799449920654,
          -32.925804138183594,
          -17.87522315979004,
          -30.22321891784668,
          -29.48107147216797,
          -21.476383209228516,
          -41.08934020996094,
          -37.98040008544922,
          -36.64529037475586,
          31.568105697631836,
          -5.327345371246338,
          -37.6187858581543,
          -11.969548225402832,
          3.0956013202667236,
          -14.516249656677246,
          -40.16469192504883,
          -34.26705551147461,
          -31.777488708496094,
          -39.73296356201172,
          -31.319177627563477,
          -36.402366638183594,
          -2.7394495010375977,
          36.75777053833008,
          18.867847442626953,
          -35.856929779052734,
          -13.387465476989746,
          30.946016311645508,
          -37.04938507080078,
          41.192962646484375,
          -22.34206199645996,
          -3.056394577026367,
          -28.5662841796875,
          -37.18561553955078,
          -14.456131935119629,
          -35.92721939086914,
          -4.756899356842041,
          10.237160682678223,
          26.376054763793945,
          3.3635313510894775,
          -11.269497871398926,
          -2.452472448348999,
          -8.372174263000488,
          -24.072059631347656,
          -14.747310638427734,
          -12.864713668823242,
          5.230804443359375,
          -41.306400299072266,
          -2.3727774620056152,
          -18.684690475463867,
          34.197322845458984,
          -39.8109245300293,
          3.5569403171539307,
          -35.29767608642578,
          18.011627197265625,
          2.4445693492889404,
          40.93479919433594,
          1.3951983451843262,
          -12.887933731079102,
          32.72490310668945,
          -40.36249542236328,
          5.4369072914123535,
          39.72783660888672,
          46.05107879638672,
          33.21949768066406,
          -2.4597158432006836,
          29.955167770385742,
          -37.4271240234375,
          46.09315872192383,
          5.615592956542969,
          32.513343811035156,
          -38.12224578857422,
          39.05863571166992,
          17.4847354888916,
          3.6042749881744385,
          -12.882844924926758,
          -13.95071792602539,
          40.607383728027344,
          38.0936393737793,
          4.3920087814331055,
          -0.44013461470603943,
          5.4372358322143555,
          -33.7306022644043,
          35.415462493896484,
          32.470054626464844,
          6.930311679840088,
          37.61252212524414,
          -24.6911563873291,
          -34.258052825927734,
          1.2998360395431519,
          3.139800548553467,
          2.196168899536133,
          -40.01618957519531,
          12.382052421569824,
          -2.2514209747314453,
          -1.6304994821548462,
          -29.30659294128418,
          -13.947273254394531,
          7.395382404327393,
          -39.9395637512207,
          -24.680387496948242,
          -16.10759735107422,
          -24.763275146484375,
          -36.883399963378906,
          -18.580793380737305,
          -24.557865142822266,
          -0.6918429732322693,
          5.107859134674072,
          27.119600296020508,
          39.262088775634766,
          34.47248077392578,
          0.12355068325996399,
          -38.1002082824707,
          -17.65101432800293,
          3.4643733501434326,
          45.08343505859375,
          -35.73217010498047,
          -39.26047134399414,
          -29.944740295410156,
          -2.5572879314422607,
          -17.86081314086914,
          45.80552673339844,
          38.70759201049805,
          29.628223419189453,
          3.793299674987793,
          -0.8915375471115112,
          4.27268123626709,
          41.080387115478516,
          -0.4120195508003235,
          -5.134189128875732,
          -26.524269104003906,
          4.994804859161377,
          2.9872782230377197,
          -25.2308406829834,
          -4.967536449432373,
          -38.99348449707031,
          -3.4146485328674316,
          -31.319101333618164,
          -5.958591461181641,
          -31.912805557250977,
          -7.0008344650268555,
          -15.874014854431152,
          -19.619632720947266,
          -9.746774673461914,
          5.903580188751221,
          15.618148803710938,
          -2.7612266540527344,
          1.7769179344177246,
          -39.063724517822266,
          -40.31998062133789,
          -32.12040328979492,
          35.799949645996094,
          36.30110549926758,
          31.568246841430664,
          -39.477333068847656,
          3.208385705947876,
          -35.9024772644043,
          -29.4610652923584,
          -9.096212387084961,
          -6.6699628829956055,
          -35.035282135009766,
          28.95804214477539,
          44.55927276611328,
          45.01437759399414,
          40.65339279174805,
          24.82956886291504,
          30.95217514038086,
          30.167631149291992,
          11.608872413635254,
          31.459901809692383,
          12.997113227844238,
          4.361050605773926,
          -0.140577495098114,
          5.380342960357666,
          -5.732264041900635,
          -20.983970642089844,
          -11.828882217407227,
          2.5549142360687256,
          -10.696600914001465,
          18.09226417541504,
          3.0323362350463867,
          -40.37223434448242,
          31.61680793762207,
          -10.153655052185059,
          -11.453167915344238,
          -1.9753998517990112,
          -37.295780181884766,
          1.6498041152954102,
          -40.243282318115234,
          46.687957763671875,
          -32.8802375793457,
          18.42060661315918,
          2.3849730491638184,
          14.941025733947754,
          1.9139035940170288,
          -7.260364055633545,
          -28.575551986694336,
          -32.41139221191406,
          -16.166778564453125,
          -36.395973205566406,
          7.036972999572754,
          -9.477819442749023,
          -5.756246566772461,
          39.392120361328125,
          -8.25296401977539,
          -21.47645378112793,
          0.9888671040534973,
          -0.009984715841710567,
          5.694857597351074,
          -2.8896443843841553,
          1.4610675573349,
          13.849217414855957,
          -18.085206985473633,
          2.6594643592834473,
          -37.51676559448242,
          1.448747158050537,
          8.543251991271973,
          -13.233593940734863,
          -36.01041030883789,
          -39.33476257324219,
          -39.28976058959961,
          -36.107879638671875,
          5.246753692626953,
          45.751251220703125,
          -16.32201385498047,
          4.110673904418945,
          42.81619644165039,
          -13.627426147460938,
          -0.858349621295929,
          -37.72114944458008,
          -25.7553653717041,
          1.8506327867507935,
          -22.896486282348633,
          -22.93895149230957,
          1.8957240581512451,
          -37.44849395751953,
          -33.39180374145508,
          -0.5227232575416565,
          3.7399401664733887,
          23.690139770507812,
          -0.03660006448626518,
          3.066843032836914,
          -22.05489158630371,
          40.603309631347656,
          -24.471925735473633,
          3.23517107963562,
          14.533498764038086,
          41.51741409301758,
          -38.784149169921875,
          -15.533936500549316,
          -14.492898941040039,
          -0.20521360635757446,
          -39.739288330078125,
          35.22639083862305,
          46.74528121948242,
          46.27483367919922,
          -21.832998275756836,
          -4.786146640777588,
          -22.08363914489746,
          4.048473358154297,
          -38.66078567504883,
          46.607017517089844,
          -23.06275749206543,
          -13.005382537841797,
          -38.44484329223633,
          -25.238340377807617,
          8.4463529586792,
          -5.848818302154541,
          -16.303579330444336,
          36.615455627441406,
          -38.203067779541016,
          -19.92225456237793,
          -13.082282066345215,
          -27.66319465637207,
          4.118443012237549,
          45.237552642822266,
          4.247714519500732,
          -36.62266159057617,
          -0.6773244738578796,
          -9.368986129760742,
          -36.725791931152344,
          -30.504369735717773,
          -39.64708709716797,
          -22.154577255249023,
          -37.13240051269531,
          -15.115525245666504,
          2.709315061569214,
          -38.92259979248047,
          15.08123779296875,
          -2.514612913131714,
          -9.448507308959961,
          31.826047897338867,
          -26.630308151245117,
          -40.1028938293457,
          33.431602478027344,
          -16.290185928344727,
          -7.212026119232178,
          4.595632076263428,
          32.03566360473633,
          11.308089256286621,
          -29.264507293701172,
          -12.234833717346191,
          -36.09942626953125,
          8.717011451721191,
          42.118839263916016,
          -37.66972351074219,
          1.3691946268081665,
          -25.31962776184082,
          2.830867052078247,
          0.5420404672622681,
          -13.203938484191895,
          -21.673748016357422,
          -17.1990909576416,
          -11.909122467041016,
          -35.939361572265625,
          1.7289836406707764,
          36.61151123046875,
          2.043177604675293,
          -40.522178649902344,
          -18.754215240478516,
          -11.720965385437012,
          -25.72025489807129,
          -9.860654830932617,
          45.689674377441406,
          -26.933576583862305,
          -39.33458709716797,
          25.91316795349121,
          0.6096228957176208,
          -14.244093894958496,
          -25.019821166992188,
          11.17479133605957,
          1.8685576915740967,
          0.637451171875,
          -11.016653060913086,
          2.6160943508148193,
          -29.279863357543945,
          2.0405995845794678,
          28.110795974731445,
          44.926513671875,
          5.214176177978516,
          4.398808479309082,
          -18.269914627075195,
          1.6072237491607666,
          -12.699668884277344,
          -30.666427612304688,
          -27.8748779296875,
          3.5694966316223145,
          2.7791025638580322,
          -37.05656433105469,
          2.1046345233917236,
          -36.25349044799805,
          -13.633042335510254,
          -31.781702041625977,
          4.413998126983643,
          -15.315746307373047,
          -0.5108894109725952,
          -38.112464904785156,
          1.7413491010665894,
          9.57337474822998,
          11.952496528625488,
          37.965126037597656,
          30.000900268554688,
          0.7424514889717102,
          0.16290727257728577,
          13.352521896362305,
          15.502333641052246,
          4.704498291015625,
          -5.452127933502197,
          -39.1158332824707,
          -3.462080240249634,
          -1.72360098361969,
          -24.316986083984375,
          3.689737558364868,
          -36.32915496826172,
          3.83012056350708,
          4.00843620300293,
          -7.043853282928467,
          2.5551514625549316,
          10.547392845153809,
          -35.68305587768555,
          5.293129920959473,
          3.6223878860473633,
          5.504662990570068,
          -37.99687194824219,
          -11.96591854095459,
          -39.985137939453125,
          -5.680607318878174,
          27.098257064819336,
          -38.866455078125,
          -28.683822631835938,
          -36.97289276123047,
          40.27157211303711,
          34.95045471191406,
          2.92276668548584,
          -19.47966766357422,
          -11.054572105407715,
          31.127758026123047,
          -27.90160369873047,
          18.490421295166016,
          -17.03318977355957,
          -15.672249794006348,
          -38.50547409057617,
          3.993272542953491,
          -34.04118347167969,
          -14.973709106445312,
          5.5614013671875,
          13.413363456726074,
          -30.37192726135254,
          5.321133136749268,
          46.509185791015625,
          -26.78912925720215,
          1.6271089315414429,
          -14.757377624511719,
          -37.89452362060547,
          -17.499067306518555,
          -11.631083488464355,
          1.694825530052185,
          26.094099044799805,
          -36.595680236816406,
          -2.4208133220672607,
          46.3241081237793,
          17.047513961791992,
          -4.078090667724609,
          4.193572521209717,
          -18.245018005371094,
          40.5169792175293,
          39.83309555053711,
          -16.17180824279785,
          -4.0436296463012695,
          -11.03774356842041,
          30.623409271240234,
          -19.739118576049805,
          -15.657953262329102,
          -13.016716003417969,
          -22.751907348632812,
          5.502283573150635,
          5.863917827606201,
          -3.641972541809082,
          0.864633321762085,
          24.02347183227539,
          4.2042927742004395,
          4.979922771453857,
          -23.117368698120117,
          -32.140079498291016,
          24.782875061035156,
          0.669183075428009,
          -9.28821849822998,
          -29.614173889160156,
          40.99106979370117,
          -20.22412872314453,
          -6.648801326751709,
          3.4258148670196533,
          4.310786247253418,
          -18.085378646850586,
          -9.096504211425781,
          2.955397844314575,
          3.8309590816497803,
          -10.414898872375488,
          -7.901947975158691,
          4.145377159118652,
          -40.61806106567383,
          -15.620271682739258,
          -24.52188491821289,
          -40.72262191772461,
          31.42584800720215,
          -28.101177215576172,
          43.92412185668945,
          1.6887242794036865,
          -13.067407608032227,
          2.003898859024048,
          45.28566360473633,
          -38.75056457519531,
          -16.488277435302734,
          -6.384703159332275,
          -17.940364837646484,
          -12.253196716308594,
          -23.138158798217773,
          14.435599327087402,
          -4.220634460449219,
          13.254219055175781,
          4.235185146331787,
          24.325191497802734,
          -39.703365325927734,
          -5.639657974243164,
          2.5325260162353516,
          -22.589628219604492,
          2.8059000968933105,
          -14.195554733276367,
          -37.84335708618164,
          -8.160061836242676,
          -25.866531372070312,
          -4.659766674041748,
          -0.9725664854049683,
          22.352848052978516,
          -25.396333694458008,
          17.344186782836914,
          -10.547054290771484,
          -29.747901916503906,
          38.33896255493164,
          26.618526458740234,
          -19.383604049682617,
          -3.118666887283325,
          -13.750971794128418,
          33.130435943603516,
          -0.5846967697143555,
          -8.391495704650879,
          -21.933856964111328,
          -3.5208210945129395,
          -14.022516250610352,
          26.755979537963867,
          -19.517784118652344,
          15.919404029846191,
          31.851694107055664,
          45.479835510253906,
          7.703188896179199,
          30.42228126525879,
          -13.484579086303711,
          -31.595378875732422,
          -17.39850425720215,
          8.615372657775879,
          -12.665495872497559,
          6.720057487487793,
          -15.978789329528809,
          -16.007200241088867,
          -10.017236709594727,
          -8.842141151428223,
          0.4431982934474945,
          -41.05249786376953,
          37.20897674560547,
          -33.36479949951172,
          0.7910104393959045,
          -1.0612961053848267,
          5.0582661628723145,
          -6.918564796447754,
          -0.47674864530563354,
          1.893652319908142,
          -26.454309463500977,
          6.42510461807251,
          -6.915207862854004,
          -13.878973007202148,
          -24.7643985748291,
          3.7579293251037598,
          -12.474563598632812,
          -16.54059410095215,
          -32.99214172363281,
          11.072949409484863,
          -39.810203552246094,
          -24.464391708374023,
          4.361113548278809,
          -14.50041675567627,
          -16.17099952697754,
          22.584312438964844,
          1.5914733409881592,
          -10.82203483581543,
          1.2541303634643555,
          -12.466300964355469,
          -3.3580050468444824,
          5.513850212097168,
          -2.438937187194824,
          -21.157005310058594,
          -13.662504196166992,
          3.368295192718506,
          2.6899349689483643,
          1.8081731796264648,
          -17.3438720703125,
          3.172144651412964,
          8.53376579284668,
          -1.1735631227493286,
          12.162866592407227,
          -36.04804992675781,
          -19.083454132080078,
          3.1921753883361816,
          -14.575446128845215,
          -8.017965316772461,
          3.235220193862915,
          -37.81580352783203,
          -16.29322052001953,
          1.7063926458358765,
          -40.51750564575195,
          -1.2852933406829834,
          -27.6236572265625,
          -1.4497562646865845,
          0.168659970164299,
          -28.753395080566406,
          1.62604820728302,
          45.32689666748047,
          -21.59351921081543,
          3.691995859146118,
          -17.424436569213867,
          -23.776927947998047,
          -39.04216003417969,
          -30.84539222717285,
          2.9825057983398438,
          -4.99736213684082,
          -34.937660217285156,
          -38.41219711303711,
          -28.55207633972168,
          1.482234001159668,
          -40.33378601074219,
          17.526235580444336,
          -14.148930549621582,
          -22.470500946044922,
          -8.277813911437988,
          -6.888155460357666,
          1.5279755592346191,
          2.248906135559082,
          -3.4105446338653564,
          -14.113245964050293,
          2.016942024230957,
          -30.911300659179688,
          -26.407617568969727,
          3.9741721153259277,
          -6.198347091674805,
          -27.302446365356445,
          39.67497253417969,
          -1.1776857376098633,
          -36.4032096862793,
          -17.201993942260742,
          2.2733864784240723,
          -9.086202621459961,
          23.35650634765625,
          31.244230270385742,
          -2.0237948894500732,
          -38.862144470214844,
          -4.584836959838867,
          -8.02626895904541,
          18.613536834716797,
          -11.040556907653809,
          -12.101269721984863,
          0.619027853012085,
          -38.32036590576172,
          -16.706506729125977,
          -31.949214935302734,
          -15.173227310180664,
          2.15293550491333,
          -30.425783157348633,
          -39.77033996582031,
          32.63715744018555,
          1.5732080936431885,
          1.4303690195083618,
          39.28916549682617,
          1.1583755016326904,
          35.93294143676758,
          -2.3773739337921143,
          -37.3532829284668,
          -7.79773473739624,
          -3.414368152618408,
          -16.29705810546875,
          -8.165810585021973,
          -17.75159454345703,
          -30.03429412841797,
          -39.070404052734375,
          -30.690082550048828,
          -16.319629669189453,
          5.524180889129639,
          -19.970012664794922,
          2.2048068046569824,
          -1.3645050525665283,
          -25.90178871154785,
          -20.924701690673828,
          -10.409368515014648,
          1.593520998954773,
          -28.97871208190918,
          4.1615214347839355,
          0.1814020276069641,
          5.396295547485352,
          -2.5493295192718506,
          1.6123501062393188,
          17.448423385620117,
          1.5608307123184204,
          2.6867446899414062,
          -5.732601165771484,
          30.337881088256836,
          4.105705738067627,
          -13.438009262084961,
          -27.984519958496094,
          30.323524475097656,
          1.655562400817871,
          4.400761604309082,
          2.960050106048584,
          36.49358367919922,
          -8.897233963012695,
          -22.87485694885254,
          -35.31090545654297,
          -15.400956153869629,
          -1.1581432819366455,
          -16.233203887939453,
          -31.090476989746094,
          -2.209012269973755,
          -35.100276947021484,
          -31.580154418945312,
          -14.443120956420898,
          2.8513457775115967,
          -18.298856735229492,
          3.959690570831299,
          -32.54247283935547,
          -0.3693159818649292,
          -2.2808451652526855,
          3.812478542327881,
          -10.062054634094238,
          -30.018016815185547,
          -5.838962078094482,
          -41.0711555480957,
          -31.27757453918457,
          -2.1927175521850586,
          -10.890748977661133,
          -22.27727508544922,
          3.94174861907959,
          1.8044253587722778,
          1.2799456119537354,
          -25.786819458007812,
          -18.77276039123535,
          -39.21418762207031,
          2.3615076541900635,
          -39.66463088989258,
          -4.706277847290039,
          0.6611180901527405,
          -15.553709030151367,
          3.4019956588745117,
          -20.788921356201172,
          -38.287132263183594,
          -9.242613792419434,
          -5.4671478271484375,
          -14.278263092041016,
          22.786117553710938,
          4.171152591705322,
          0.3770877420902252,
          -25.176538467407227,
          -17.809450149536133,
          1.9897127151489258,
          -5.7386555671691895,
          -2.0682570934295654,
          -15.784689903259277,
          -16.769529342651367,
          0.6995654702186584,
          7.251498222351074,
          3.360912322998047,
          41.584144592285156,
          -5.1891703605651855,
          -27.3642578125,
          -16.954782485961914,
          -38.449485778808594,
          -15.842772483825684,
          -35.1736946105957,
          -11.24600887298584,
          -11.826170921325684,
          -4.625999927520752,
          -35.44071960449219,
          -5.388739109039307,
          -40.54948806762695,
          -30.38511085510254,
          -1.858169674873352,
          3.092115640640259,
          -20.906574249267578,
          -14.779520034790039,
          1.5141383409500122,
          -1.7426201105117798,
          -7.520579814910889,
          -4.455383777618408,
          -0.7685651779174805,
          -3.9637303352355957,
          24.251705169677734,
          -9.355188369750977,
          -19.737165451049805,
          -13.193379402160645,
          -25.41063117980957,
          -37.77260208129883,
          -7.979479789733887,
          19.322917938232422,
          -33.64534378051758,
          5.196836471557617,
          7.083828449249268,
          3.8506085872650146,
          -15.244266510009766,
          -36.6640510559082,
          -19.96379280090332,
          -1.2815358638763428,
          -7.665472507476807,
          -20.56283187866211,
          -3.7039458751678467,
          -31.368873596191406,
          -23.52789306640625,
          -19.812259674072266,
          -10.769295692443848,
          -17.233043670654297,
          41.67713928222656,
          -36.83451461791992,
          42.644474029541016,
          -16.226551055908203,
          -39.806663513183594,
          0.9725263118743896,
          -6.175349712371826,
          -0.09805956482887268,
          -35.86052703857422,
          4.365568161010742,
          -3.9652533531188965,
          -32.112308502197266,
          -33.80850601196289,
          -6.659698486328125,
          -27.09425163269043,
          -27.080522537231445,
          -16.164854049682617,
          -10.992804527282715,
          -8.43914794921875,
          -41.31871032714844,
          -37.668365478515625,
          1.4452673196792603,
          -0.4089850187301636,
          -28.739185333251953,
          13.060574531555176,
          -16.234539031982422,
          -33.005619049072266,
          -7.6584038734436035,
          -26.224273681640625,
          1.9248909950256348,
          -30.11958122253418,
          -10.570536613464355,
          -22.393632888793945,
          -31.140634536743164,
          -36.969825744628906,
          -29.301799774169922,
          4.31374454498291,
          -23.841825485229492,
          -38.37278366088867,
          -19.140485763549805,
          -9.76196575164795,
          4.706887722015381,
          1.6181260347366333,
          -10.36555004119873,
          2.989647626876831,
          -0.16461774706840515,
          10.795783996582031,
          -27.430931091308594,
          -31.420862197875977,
          -39.37876510620117,
          -23.882749557495117,
          2.091907501220703,
          -16.10919189453125,
          -11.308109283447266,
          -18.918540954589844,
          -17.08672523498535,
          15.897212982177734,
          -2.1196465492248535,
          1.9649916887283325,
          5.404397964477539,
          9.880634307861328,
          -27.863357543945312,
          -40.175254821777344,
          -5.313533782958984,
          -31.09767723083496,
          -2.3289477825164795,
          4.589580059051514,
          3.2413442134857178,
          37.320343017578125,
          -40.18357467651367,
          -37.8821907043457,
          -2.4368629455566406,
          -1.9522477388381958,
          -27.788991928100586,
          3.7798731327056885,
          28.388248443603516,
          -31.06997299194336,
          3.9399657249450684,
          -17.099178314208984,
          -33.06288528442383,
          -10.962403297424316,
          -26.1990966796875,
          -34.142234802246094,
          -39.11476135253906,
          7.572174072265625,
          -40.04143524169922,
          -38.98963165283203,
          -37.15925979614258,
          2.7669103145599365,
          3.4952526092529297,
          2.02835750579834,
          -10.925053596496582,
          -11.9108247756958,
          -21.632192611694336,
          -6.748457431793213,
          -32.98331832885742,
          -29.01176643371582,
          -3.568909168243408,
          -41.07646942138672,
          -22.747865676879883,
          43.157649993896484,
          -10.089658737182617,
          -4.0670671463012695,
          -25.7406005859375,
          2.022250175476074,
          2.7645959854125977,
          -11.55325698852539,
          -37.22403335571289,
          -13.507805824279785,
          -39.520118713378906,
          -35.10481643676758,
          -23.562931060791016,
          -3.1033544540405273,
          0.4217807948589325,
          -6.251979351043701,
          -5.41923189163208,
          -28.120166778564453,
          -40.829795837402344,
          -8.20405387878418,
          4.125303745269775,
          -14.608622550964355,
          2.472320556640625,
          -31.12278938293457,
          -14.588204383850098,
          -30.006919860839844,
          2.7163197994232178,
          -31.01382064819336,
          -17.919038772583008,
          3.6932880878448486,
          1.1064817905426025,
          -37.56631088256836,
          -11.00253963470459,
          0.6725674867630005,
          -23.393247604370117,
          13.937875747680664,
          5.498360633850098,
          3.389073371887207,
          -3.6703619956970215,
          -20.5777587890625,
          -18.0986385345459,
          -22.36763572692871
         ],
         "y": [
          -5.852118015289307,
          -42.61534118652344,
          -37.16272735595703,
          -42.587196350097656,
          -37.41513442993164,
          -2.95501971244812,
          -42.756195068359375,
          -41.35460662841797,
          -16.674209594726562,
          -43.060508728027344,
          -40.70439910888672,
          10.678156852722168,
          -41.71809005737305,
          -41.62645721435547,
          2.486205816268921,
          -43.4848518371582,
          9.637706756591797,
          2.4015274047851562,
          -37.962486267089844,
          -33.768829345703125,
          3.2253546714782715,
          -5.120482444763184,
          17.3554630279541,
          -30.347862243652344,
          12.375263214111328,
          -20.445199966430664,
          -22.962032318115234,
          -31.057361602783203,
          -43.18147277832031,
          -25.10930061340332,
          -42.86281204223633,
          -39.86176300048828,
          3.8510048389434814,
          -10.018165588378906,
          -5.015580654144287,
          1.5494016408920288,
          15.174556732177734,
          -23.125226974487305,
          11.570070266723633,
          17.270904541015625,
          10.965791702270508,
          12.3953275680542,
          -2.848613977432251,
          17.202585220336914,
          -42.98804473876953,
          13.861613273620605,
          -41.91545104980469,
          -31.804977416992188,
          -10.175382614135742,
          -42.81792449951172,
          10.64430046081543,
          -23.44777488708496,
          -35.50877380371094,
          -1.1731058359146118,
          -43.49315643310547,
          15.563348770141602,
          -40.715694427490234,
          -26.521080017089844,
          -35.64248275756836,
          -42.98019790649414,
          -32.33019256591797,
          -43.09187316894531,
          -32.92036437988281,
          -40.20941162109375,
          -36.05997848510742,
          42.015438079833984,
          -43.40392303466797,
          -39.5066032409668,
          31.77043342590332,
          46.996910095214844,
          -1.9432252645492554,
          -24.862056732177734,
          15.361470222473145,
          -32.83443069458008,
          -36.2935905456543,
          -40.20927810668945,
          -16.062402725219727,
          -39.91416931152344,
          -12.969366073608398,
          -9.405166625976562,
          -14.294425964355469,
          -42.254390716552734,
          -35.40631103515625,
          7.388576030731201,
          29.023090362548828,
          -9.95609188079834,
          1.1827179193496704,
          -35.18998718261719,
          20.3472957611084,
          13.904584884643555,
          28.426856994628906,
          -17.20416831970215,
          -0.9555498361587524,
          -40.916954040527344,
          17.109922409057617,
          -12.029370307922363,
          1.333734154701233,
          -35.47413635253906,
          25.409461975097656,
          16.77083969116211,
          -31.849079132080078,
          -16.265201568603516,
          -21.386262893676758,
          -28.659162521362305,
          -20.946060180664062,
          -16.922222137451172,
          -36.147403717041016,
          -27.492366790771484,
          -20.71866798400879,
          -39.06718063354492,
          -8.694506645202637,
          13.986557960510254,
          -39.73786163330078,
          -34.582942962646484,
          -27.70258331298828,
          -36.5731201171875,
          14.304636001586914,
          -28.663040161132812,
          -17.402942657470703,
          10.394699096679688,
          -41.24319839477539,
          -9.862682342529297,
          -12.690279960632324,
          12.666897773742676,
          12.134408950805664,
          -16.48504066467285,
          16.183752059936523,
          -41.47362518310547,
          -43.40296936035156,
          -9.194972038269043,
          -33.290283203125,
          -26.44922637939453,
          16.917938232421875,
          8.731624603271484,
          -11.56999397277832,
          -34.21370315551758,
          7.365176200866699,
          -17.259519577026367,
          -10.974510192871094,
          47.25785827636719,
          10.642464637756348,
          -6.129786014556885,
          -8.787965774536133,
          6.8440961837768555,
          11.225090026855469,
          -33.30252456665039,
          -35.013580322265625,
          16.948041915893555,
          -42.83420181274414,
          -6.340755939483643,
          4.3049492835998535,
          -14.263812065124512,
          -7.478363990783691,
          -6.792052745819092,
          -24.07805824279785,
          -2.2557449340820312,
          18.309900283813477,
          -2.1940994262695312,
          -39.06299591064453,
          17.24492835998535,
          -24.271259307861328,
          -19.437061309814453,
          11.296043395996094,
          -17.015361785888672,
          31.12819480895996,
          -7.114949703216553,
          0.954110324382782,
          14.622488975524902,
          -33.403953552246094,
          32.63785934448242,
          11.049837112426758,
          -31.947446823120117,
          -35.75212860107422,
          -40.53839874267578,
          -8.651717185974121,
          32.52046585083008,
          -34.385921478271484,
          -28.842700958251953,
          -21.589792251586914,
          -40.902061462402344,
          -39.29954147338867,
          17.188573837280273,
          -38.76496505737305,
          -9.326251029968262,
          -27.863834381103516,
          -3.207468271255493,
          -23.764028549194336,
          -25.97989845275879,
          -4.607408046722412,
          -14.978324890136719,
          11.375452995300293,
          -18.909330368041992,
          -34.62021255493164,
          50.01417541503906,
          2.782327175140381,
          30.814109802246094,
          -34.10951614379883,
          3.640664577484131,
          -23.96915626525879,
          -38.009559631347656,
          -14.446057319641113,
          40.82707595825195,
          0.8934673070907593,
          -34.13090896606445,
          8.18336009979248,
          -36.20378494262695,
          -10.502182006835938,
          -4.093618392944336,
          -7.078902721405029,
          8.342794418334961,
          -38.36467361450195,
          16.547962188720703,
          -14.650313377380371,
          13.052640914916992,
          56.08891296386719,
          -19.905742645263672,
          14.73849105834961,
          14.486043930053711,
          -11.215974807739258,
          -40.052001953125,
          7.367980480194092,
          -34.595191955566406,
          -41.206504821777344,
          8.509794235229492,
          -30.649389266967773,
          -15.798432350158691,
          -10.323972702026367,
          -36.62118148803711,
          -11.625631332397461,
          -36.660362243652344,
          -35.288028717041016,
          16.12945556640625,
          13.805644035339355,
          -13.538360595703125,
          -37.59921646118164,
          -6.9181318283081055,
          -41.108158111572266,
          -35.149662017822266,
          -16.15052032470703,
          -16.7908878326416,
          -35.673187255859375,
          25.20597267150879,
          -40.60614776611328,
          -7.124131202697754,
          16.31160545349121,
          7.337202548980713,
          4.873968601226807,
          -36.710391998291016,
          -17.685806274414062,
          13.044286727905273,
          -27.92951011657715,
          -43.36543273925781,
          -10.499923706054688,
          -1.7295093536376953,
          -2.2355360984802246,
          51.636993408203125,
          -15.825857162475586,
          -24.567890167236328,
          -36.34111785888672,
          11.523224830627441,
          -14.258615493774414,
          -1.0662593841552734,
          17.000106811523438,
          -9.811688423156738,
          11.298096656799316,
          12.739779472351074,
          39.29561233520508,
          -2.586592435836792,
          -43.3845100402832,
          -23.338207244873047,
          -17.154356002807617,
          24.890295028686523,
          -3.699450731277466,
          47.31707763671875,
          16.356185913085938,
          -15.55765151977539,
          -8.777929306030273,
          -12.870776176452637,
          6.571127414703369,
          -42.53343200683594,
          -9.551899909973145,
          11.072507858276367,
          -28.567590713500977,
          -11.328749656677246,
          -5.024940013885498,
          7.431629657745361,
          -35.78489685058594,
          -30.961811065673828,
          -36.01481246948242,
          -5.724868297576904,
          14.993463516235352,
          -16.864795684814453,
          -33.38582992553711,
          -9.535663604736328,
          -10.374357223510742,
          -38.42455291748047,
          -41.030662536621094,
          -20.685972213745117,
          -28.21696662902832,
          31.497690200805664,
          -27.095890045166016,
          -11.269306182861328,
          -13.917255401611328,
          -9.040721893310547,
          2.1078362464904785,
          52.53512954711914,
          -22.996490478515625,
          -32.28668212890625,
          -27.007225036621094,
          -22.66192054748535,
          -16.373065948486328,
          10.691898345947266,
          3.3672778606414795,
          14.095560073852539,
          17.346372604370117,
          -41.11406326293945,
          11.057119369506836,
          22.717548370361328,
          3.0176942348480225,
          8.337010383605957,
          -42.00782775878906,
          -19.191802978515625,
          2.622157335281372,
          -19.781606674194336,
          -4.895166873931885,
          -11.980522155761719,
          12.479339599609375,
          9.262083053588867,
          15.718713760375977,
          -9.274889945983887,
          -10.076493263244629,
          -8.505707740783691,
          -4.793968677520752,
          -10.409242630004883,
          -17.381948471069336,
          -41.676490783691406,
          -34.36235046386719,
          5.101744651794434,
          -14.00584602355957,
          17.412456512451172,
          9.614171028137207,
          -7.610135555267334,
          -32.78965377807617,
          -8.784551620483398,
          -34.94895553588867,
          21.507408142089844,
          51.772239685058594,
          16.0001277923584,
          -11.096575736999512,
          1.5495338439941406,
          -34.75990676879883,
          -16.069822311401367,
          -13.180204391479492,
          -12.188958168029785,
          2.844151496887207,
          -21.042028427124023,
          16.59469985961914,
          -31.37790298461914,
          16.657320022583008,
          6.937716007232666,
          -28.035676956176758,
          4.599451541900635,
          -2.552572727203369,
          10.024544715881348,
          -27.4210262298584,
          -22.438091278076172,
          -31.04344940185547,
          -32.376216888427734,
          -10.563688278198242,
          -3.7778067588806152,
          11.645584106445312,
          9.54284381866455,
          9.37617015838623,
          2.0161643028259277,
          -39.645660400390625,
          11.087254524230957,
          -1.5342825651168823,
          4.469498157501221,
          -29.743635177612305,
          -37.70108413696289,
          13.832867622375488,
          -5.132258892059326,
          10.154210090637207,
          17.352861404418945,
          -38.946678161621094,
          17.14301109313965,
          -27.213781356811523,
          -32.46529769897461,
          -1.9581191539764404,
          -15.6100435256958,
          9.785013198852539,
          4.644377708435059,
          -12.995782852172852,
          22.40249252319336,
          -26.790889739990234,
          53.844329833984375,
          13.168107032775879,
          1.6761021614074707,
          37.394535064697266,
          -13.806097030639648,
          -12.530360221862793,
          2.2014176845550537,
          15.191160202026367,
          10.237081527709961,
          -5.526419162750244,
          16.907651901245117,
          -16.725648880004883,
          -9.583500862121582,
          -24.28182601928711,
          -23.400226593017578,
          17.455787658691406,
          -24.530298233032227,
          25.88549041748047,
          17.522043228149414,
          49.01753616333008,
          -39.831363677978516,
          -5.286355495452881,
          -25.91062355041504,
          -11.063385963439941,
          -13.003442764282227,
          -24.70784568786621,
          -38.277587890625,
          -7.810775279998779,
          -7.12365198135376,
          10.410545349121094,
          24.805063247680664,
          -5.346645355224609,
          51.970558166503906,
          1.8060778379440308,
          2.5308032035827637,
          10.998912811279297,
          33.19120407104492,
          -38.765464782714844,
          -1.763439416885376,
          -38.563812255859375,
          6.255399227142334,
          15.447619438171387,
          -33.54308319091797,
          15.308497428894043,
          -34.478885650634766,
          -20.32216453552246,
          -35.70552444458008,
          -11.847981452941895,
          35.895870208740234,
          15.058600425720215,
          25.800561904907227,
          0.3935142755508423,
          -27.800519943237305,
          14.556198120117188,
          25.23358726501465,
          -18.037580490112305,
          7.536343097686768,
          16.962430953979492,
          -35.21141815185547,
          -29.424962997436523,
          13.748388290405273,
          7.868879795074463,
          12.718878746032715,
          -19.89692497253418,
          17.52909278869629,
          8.128511428833008,
          21.069372177124023,
          -29.280160903930664,
          -12.542470932006836,
          -20.765823364257812,
          -22.707109451293945,
          10.874964714050293,
          31.56787872314453,
          -3.7178361415863037,
          -17.800046920776367,
          -29.807743072509766,
          -34.914649963378906,
          -6.5365777015686035,
          10.374215126037598,
          13.822683334350586,
          -34.773162841796875,
          52.84846496582031,
          5.302839279174805,
          -2.1011955738067627,
          50.26743698120117,
          -30.603120803833008,
          -27.514633178710938,
          -7.846433639526367,
          -27.631376266479492,
          11.742621421813965,
          29.391315460205078,
          -21.049985885620117,
          -36.20143127441406,
          20.83224105834961,
          -29.41501808166504,
          56.77047348022461,
          -17.626543045043945,
          -4.374062538146973,
          -7.903671741485596,
          -40.36860656738281,
          7.332202434539795,
          -17.750967025756836,
          13.249510765075684,
          -33.164554595947266,
          12.394989013671875,
          -26.999208450317383,
          4.054445743560791,
          13.505264282226562,
          23.58144760131836,
          -13.206250190734863,
          -35.22782897949219,
          -4.51057767868042,
          12.680678367614746,
          -26.41402816772461,
          51.87812423706055,
          3.8282599449157715,
          -1.5507593154907227,
          -24.1368408203125,
          -30.59598731994629,
          -18.189205169677734,
          4.146796703338623,
          7.081033706665039,
          16.341176986694336,
          16.142465591430664,
          5.01747989654541,
          13.602296829223633,
          -20.634355545043945,
          -14.773857116699219,
          21.15616226196289,
          -32.08552551269531,
          -34.65480422973633,
          9.131194114685059,
          -21.74892234802246,
          3.6759531497955322,
          17.290916442871094,
          9.936750411987305,
          8.474609375,
          0.7792072892189026,
          -16.56816864013672,
          -15.915307998657227,
          5.522094249725342,
          -21.44866943359375,
          12.359023094177246,
          -17.958843231201172,
          38.689491271972656,
          -18.19158172607422,
          6.150826930999756,
          -14.123458862304688,
          55.607269287109375,
          10.617233276367188,
          -13.036296844482422,
          14.855752944946289,
          -4.223571300506592,
          16.25723648071289,
          -1.0707849264144897,
          -26.59079933166504,
          -33.482234954833984,
          3.7196998596191406,
          0.9702826142311096,
          -13.597737312316895,
          5.887918472290039,
          -2.700377941131592,
          11.415324211120605,
          34.03912353515625,
          -3.886061906814575,
          16.92482566833496,
          -33.576560974121094,
          10.195441246032715,
          -9.590704917907715,
          -0.4596942365169525,
          16.850391387939453,
          -24.994779586791992,
          47.12183380126953,
          10.452354431152344,
          17.35110855102539,
          -5.84704065322876,
          30.59733772277832,
          -26.95508575439453,
          -24.695938110351562,
          10.150131225585938,
          -6.556545734405518,
          -14.138704299926758,
          34.943660736083984,
          -18.124774932861328,
          6.313364028930664,
          51.13335418701172,
          -3.5508313179016113,
          3.4205546379089355,
          1.6819870471954346,
          -21.74078941345215,
          -12.582527160644531,
          -23.552717208862305,
          27.069063186645508,
          2.5035336017608643,
          26.907447814941406,
          -13.848885536193848,
          51.051292419433594,
          11.294027328491211,
          15.097336769104004,
          -1.6063603162765503,
          -19.631383895874023,
          -31.91365623474121,
          8.97509765625,
          16.9647159576416,
          10.031159400939941,
          2.889434337615967,
          -6.900503635406494,
          -22.567123413085938,
          -21.34830665588379,
          21.610855102539062,
          13.15707015991211,
          -33.67363739013672,
          17.549102783203125,
          17.404138565063477,
          -25.672157287597656,
          16.408218383789062,
          -24.689199447631836,
          -15.456746101379395,
          5.9745192527771,
          0.6973513960838318,
          17.45646858215332,
          13.359222412109375,
          54.413150787353516,
          5.20293664932251,
          2.814788818359375,
          -11.393664360046387,
          45.99848937988281,
          -1.5848668813705444,
          0.4587395489215851,
          11.441973686218262,
          -4.061037063598633,
          15.644165992736816,
          -34.92142868041992,
          37.055179595947266,
          11.85496711730957,
          20.496315002441406,
          -28.289987564086914,
          56.0997314453125,
          -38.76132583618164,
          6.121220111846924,
          -41.66946029663086,
          40.50615692138672,
          -15.366873741149902,
          -22.055469512939453,
          13.946943283081055,
          -7.716467380523682,
          53.294281005859375,
          -29.03180694580078,
          38.83545684814453,
          -35.2592658996582,
          -32.949440002441406,
          -11.217470169067383,
          -20.96573257446289,
          -12.080690383911133,
          -23.49806022644043,
          14.493209838867188,
          -19.565841674804688,
          -4.509716510772705,
          -24.73013687133789,
          -27.853673934936523,
          -28.041311264038086,
          -31.320697784423828,
          12.011778831481934,
          -17.631488800048828,
          12.280840873718262,
          -34.333988189697266,
          -20.984281539916992,
          2.9874751567840576,
          8.415326118469238,
          -0.0947212353348732,
          13.76541519165039,
          24.684799194335938,
          10.734583854675293,
          -30.396907806396484,
          -23.344505310058594,
          13.993644714355469,
          19.394729614257812,
          -40.99393844604492,
          50.573917388916016,
          -35.302734375,
          -5.617327690124512,
          20.9885311126709,
          -35.636600494384766,
          12.982388496398926,
          15.157470703125,
          -15.835659980773926,
          -31.55305290222168,
          7.224542617797852,
          14.149847030639648,
          -28.142446517944336,
          17.31271743774414,
          6.296378135681152,
          10.022363662719727,
          -35.83674621582031,
          -36.232933044433594,
          -15.73828411102295,
          36.97426986694336,
          45.32155227661133,
          -3.6971192359924316,
          2.446667194366455,
          7.225032329559326,
          15.296239852905273,
          50.07212448120117,
          6.541576862335205,
          -35.26328659057617,
          15.397216796875,
          50.2320442199707,
          -19.73444366455078,
          14.040031433105469,
          6.213736057281494,
          -13.396276473999023,
          2.290118455886841,
          4.750053882598877,
          -17.831144332885742,
          23.691316604614258,
          15.888401985168457,
          1.325715184211731,
          -13.815083503723145,
          -0.7576612234115601,
          10.024210929870605,
          11.08782958984375,
          20.324275970458984,
          11.364333152770996,
          -23.331350326538086,
          -27.382587432861328,
          -3.0470001697540283,
          -13.17680835723877,
          24.289058685302734,
          -7.113954067230225,
          -13.145007133483887,
          -2.2791330814361572,
          -8.483497619628906,
          -34.780006408691406,
          -3.334775686264038,
          -6.935920715332031,
          4.174124240875244,
          -35.60638427734375,
          34.94375991821289,
          -27.62804412841797,
          -31.40256690979004,
          -13.657609939575195,
          -2.038602590560913,
          -21.86798667907715,
          10.62430191040039,
          12.87649154663086,
          15.894780158996582,
          17.1691951751709,
          -2.2738568782806396,
          11.120302200317383,
          -17.91493034362793,
          5.560961723327637,
          -40.35759353637695,
          -26.133548736572266,
          -4.552865028381348,
          -35.67836380004883,
          10.52935791015625,
          19.299177169799805,
          -30.83673667907715,
          47.4384765625,
          8.85081958770752,
          47.92023468017578,
          -27.001237869262695,
          -11.982834815979004,
          11.372308731079102,
          -16.403562545776367,
          -2.457165241241455,
          3.846672534942627,
          -29.330049514770508,
          -3.198528528213501,
          20.04477882385254,
          -24.331472396850586,
          5.118788719177246,
          32.89270782470703,
          16.52431297302246,
          -7.472360134124756,
          56.21580505371094,
          50.59288787841797,
          -0.41226181387901306,
          56.331966400146484,
          13.081576347351074,
          -12.823253631591797,
          56.00641632080078,
          -34.02910232543945,
          43.40439224243164,
          28.334749221801758,
          19.271926879882812,
          -20.381792068481445,
          7.9035844802856445,
          12.54338264465332,
          50.85159683227539,
          -14.337276458740234,
          -12.886204719543457,
          52.95529556274414,
          48.704498291015625,
          6.4823317527771,
          -30.329771041870117,
          14.363096237182617,
          56.84889602661133,
          6.166735649108887,
          12.181915283203125,
          14.311959266662598,
          32.80655288696289,
          16.967683792114258,
          56.768333435058594,
          -30.08268928527832,
          10.228336334228516,
          12.098322868347168,
          -3.226283550262451,
          39.39518356323242,
          15.677797317504883,
          2.4474477767944336,
          -20.935300827026367,
          15.758452415466309,
          8.844853401184082,
          13.29325008392334,
          -23.092830657958984,
          -35.876041412353516,
          11.5126371383667,
          3.0660312175750732,
          -5.040938377380371,
          -8.008405685424805,
          -5.276645183563232,
          13.831933975219727,
          -9.658772468566895,
          0.12376493215560913,
          2.320858955383301,
          -8.86607551574707,
          53.80327606201172,
          -20.239622116088867,
          -31.91394805908203,
          -7.341469764709473,
          -19.073760986328125,
          13.05502700805664,
          -23.322017669677734,
          -25.381704330444336,
          12.916847229003906,
          -3.628178358078003,
          7.165049076080322,
          4.816708087921143,
          -20.942039489746094,
          51.55910873413086,
          -16.231054306030273,
          53.18048858642578,
          -19.748266220092773,
          -35.943580627441406,
          -1.4099608659744263,
          -16.89337158203125,
          -19.554407119750977,
          -12.745918273925781,
          9.454038619995117,
          6.738961219787598,
          -35.498783111572266,
          17.24530601501465,
          9.179131507873535,
          -15.982640266418457,
          14.760272026062012,
          -31.32023048400879,
          4.117537021636963,
          -7.431577205657959,
          -30.435819625854492,
          48.715091705322266,
          -24.22781753540039,
          5.653964519500732,
          14.19789981842041,
          7.878198623657227,
          48.951419830322266,
          -0.9875094890594482,
          15.38819694519043,
          -18.187904357910156,
          -35.43865203857422,
          47.65355682373047,
          16.29045867919922,
          -29.681032180786133,
          -35.17378616333008,
          -34.79575729370117,
          27.984270095825195,
          -5.66493558883667,
          -33.94432067871094,
          -32.52567672729492,
          17.3525447845459,
          -2.440572500228882,
          34.1440315246582,
          7.9577484130859375,
          8.806844711303711,
          -22.104597091674805,
          -7.711357116699219,
          43.098785400390625,
          15.567217826843262,
          -17.448436737060547,
          -8.716800689697266,
          35.62812042236328,
          -8.982685089111328,
          -0.37157949805259705,
          -34.92384719848633,
          -32.56779479980469,
          16.764284133911133,
          -11.243537902832031,
          7.449616432189941,
          36.84967041015625,
          -18.24461555480957,
          -10.596911430358887,
          16.362796783447266,
          6.7621002197265625,
          31.446931838989258,
          16.3463134765625,
          54.979164123535156,
          14.855729103088379,
          16.528541564941406,
          39.8932991027832,
          23.979028701782227,
          -10.662117958068848,
          -18.218860626220703,
          -13.859511375427246,
          -18.28496551513672,
          -8.78846549987793,
          16.66213607788086,
          9.968777656555176,
          -18.120744705200195,
          -27.135072708129883,
          41.238914489746094,
          -25.188749313354492,
          -0.8850582242012024,
          2.099865436553955,
          -34.128089904785156,
          -32.68071365356445,
          -23.789077758789062,
          -35.77381896972656,
          -6.193464279174805,
          -6.365744590759277,
          12.691304206848145,
          -33.96502685546875,
          -27.85054588317871,
          -16.99694061279297,
          13.670000076293945,
          -28.966650009155273,
          -31.237590789794922,
          35.104827880859375,
          15.736452102661133,
          16.09026527404785,
          -15.12493896484375,
          -28.530120849609375,
          1.6341127157211304,
          55.909549713134766,
          -22.568660736083984,
          -2.754126787185669,
          -14.554891586303711,
          -3.8691728115081787,
          10.323592185974121,
          19.56711196899414,
          14.153603553771973,
          -0.9829199314117432,
          16.109466552734375,
          17.019147872924805,
          38.30287170410156,
          22.468711853027344,
          -13.315872192382812,
          14.817086219787598,
          24.473264694213867,
          18.179079055786133,
          -25.246313095092773,
          37.017417907714844,
          37.859375,
          12.639071464538574,
          18.926822662353516,
          -4.483892440795898,
          49.80411911010742,
          -20.298173904418945,
          18.004440307617188,
          9.329972267150879,
          17.950281143188477,
          12.510907173156738,
          56.765419006347656,
          -36.311424255371094,
          -7.361932277679443,
          4.941225051879883,
          -33.483734130859375,
          -23.7694091796875,
          -10.461759567260742,
          -5.504858016967773,
          -21.668758392333984,
          -13.373137474060059,
          -12.76828670501709,
          -32.6201171875,
          4.981517791748047,
          26.69424057006836,
          -16.502765655517578,
          -21.803333282470703,
          52.62953567504883,
          -34.79705810546875,
          -16.330297470092773,
          16.557220458984375,
          11.047959327697754,
          11.247200012207031,
          14.929425239562988,
          14.745758056640625,
          -30.391395568847656,
          -24.594951629638672,
          1.1881908178329468,
          -32.045902252197266,
          0.8262702226638794,
          -11.42153263092041,
          24.042570114135742,
          34.4591178894043,
          18.467769622802734,
          56.796627044677734,
          15.749760627746582,
          37.86764144897461,
          15.748117446899414,
          9.104703903198242,
          -21.986928939819336,
          -11.697234153747559,
          -31.92421531677246,
          52.50554656982422,
          -36.61234664916992,
          23.233652114868164,
          -13.870203971862793,
          -28.00732421875,
          -11.264995574951172,
          2.924175262451172,
          9.44099235534668,
          9.099372863769531,
          40.222408294677734,
          3.195549249649048,
          29.149890899658203,
          16.70806121826172,
          -25.541419982910156,
          -20.684064865112305,
          55.543907165527344,
          4.071177005767822,
          -7.58105993270874,
          17.651456832885742,
          -35.21897506713867,
          15.82437801361084,
          18.643346786499023,
          12.668999671936035,
          -29.79294776916504,
          46.02602767944336,
          -8.761092185974121,
          -35.16942596435547,
          -26.509862899780273,
          3.185115337371826,
          -33.93194580078125,
          -25.945493698120117,
          -10.406441688537598,
          45.0966796875,
          -4.006366729736328,
          16.468881607055664,
          8.470974922180176,
          3.406843900680542,
          -2.2751615047454834,
          -13.20284366607666,
          33.234642028808594,
          -1.0476840734481812,
          12.227731704711914,
          -15.14297103881836,
          13.25776195526123,
          -35.57438278198242,
          -31.870790481567383,
          5.9452385902404785,
          -28.160381317138672,
          26.918729782104492,
          -30.051162719726562,
          -31.605731964111328,
          -22.39335823059082,
          -16.04833984375,
          -20.103017807006836,
          45.8774528503418,
          -20.995243072509766,
          13.899434089660645,
          -29.789413452148438,
          28.714527130126953,
          -30.3266658782959,
          -8.04578971862793,
          10.21202564239502,
          30.324426651000977,
          2.9556355476379395,
          -7.097781181335449,
          -2.0911238193511963,
          -34.750186920166016,
          -35.87801742553711,
          24.780649185180664,
          -11.802691459655762,
          17.018192291259766,
          4.014772415161133,
          1.0453054904937744,
          12.392443656921387,
          19.006763458251953,
          13.4165678024292,
          35.91611099243164,
          -1.9126797914505005,
          1.1083124876022339,
          12.812687873840332,
          13.772878646850586,
          5.991832733154297,
          12.900562286376953,
          -6.057366371154785,
          18.915922164916992,
          -35.104251861572266,
          16.893198013305664,
          -5.22231388092041,
          -31.98948097229004,
          -36.22797393798828,
          -24.50684356689453,
          -14.381031036376953,
          10.679375648498535,
          32.496795654296875,
          4.990382194519043,
          22.958105087280273,
          53.13572311401367,
          -15.798287391662598,
          -21.434070587158203,
          -4.495035648345947,
          -31.089109420776367,
          -13.020586013793945,
          -34.28606033325195,
          44.95450973510742,
          3.8742949962615967,
          4.781548023223877,
          -32.97924041748047,
          15.109128952026367,
          -19.897798538208008,
          -27.777997970581055,
          1.2380622625350952,
          17.342552185058594,
          -34.00809097290039,
          16.91881561279297,
          -12.4097318649292,
          -19.385202407836914,
          -0.6129372715950012,
          -22.828426361083984,
          14.446907043457031,
          6.107428073883057,
          -4.960155487060547,
          -6.463570594787598,
          2.730506658554077,
          41.856876373291016,
          10.849320411682129,
          27.607646942138672,
          -29.18985366821289,
          54.141510009765625,
          -31.911378860473633,
          -34.5984992980957,
          54.44137954711914,
          7.154151916503906,
          28.319684982299805,
          16.679960250854492,
          -26.76432991027832,
          -4.595211505889893,
          56.26829528808594,
          52.6046028137207,
          12.34544849395752,
          53.651611328125,
          8.651833534240723,
          -26.746074676513672,
          6.6765828132629395,
          15.129833221435547,
          44.116878509521484,
          54.53388595581055,
          -27.804378509521484,
          -0.348420113325119,
          28.05215835571289,
          -28.657894134521484,
          -35.38217544555664,
          39.66129684448242,
          -23.979684829711914,
          44.17744827270508,
          16.52362060546875,
          -2.779083013534546,
          38.521244049072266,
          39.81744384765625,
          13.793935775756836,
          -25.427383422851562,
          -35.12295150756836,
          -23.44244384765625,
          11.603038787841797,
          -21.270288467407227,
          -20.336894989013672,
          6.765500545501709,
          -23.232084274291992,
          -15.98997974395752,
          -35.99671936035156,
          -21.39596176147461,
          36.449302673339844,
          55.44143295288086,
          46.49036407470703,
          -13.257364273071289,
          -25.219724655151367,
          -1.6965690851211548,
          0.9209562540054321,
          16.46204948425293,
          17.472448348999023,
          43.94599914550781,
          -29.31020164489746,
          2.208374261856079,
          5.485518932342529,
          -14.521947860717773,
          51.6093864440918,
          -1.274139404296875,
          -34.08991622924805,
          48.61519241333008,
          10.410706520080566,
          -16.811933517456055,
          6.326021671295166,
          27.54449462890625,
          42.40053939819336,
          16.34386444091797,
          24.63189697265625,
          -2.0844993591308594,
          -15.938356399536133,
          38.617027282714844,
          -15.60091781616211,
          -10.500289916992188,
          4.1279473304748535,
          16.50792694091797,
          -0.2408653348684311,
          17.863855361938477,
          15.742220878601074,
          -3.269192934036255,
          -24.93807601928711,
          8.077216148376465,
          -8.382722854614258,
          -14.471795082092285,
          34.866119384765625,
          11.154932975769043,
          -35.104042053222656,
          -21.945072174072266,
          -27.3509578704834,
          8.305447578430176,
          56.439453125,
          56.009002685546875,
          -7.5327935218811035,
          42.097564697265625,
          -17.29743003845215,
          -34.408935546875,
          -10.490165710449219,
          1.881016492843628,
          9.531258583068848,
          34.38024139404297,
          5.63718318939209,
          11.80435848236084,
          41.196773529052734,
          54.75301742553711,
          1.022278904914856,
          11.692143440246582,
          -36.31755065917969,
          -23.947216033935547,
          15.8487548828125,
          -14.225135803222656,
          23.00875473022461,
          1.1675289869308472,
          7.187999248504639,
          18.133480072021484,
          28.807374954223633,
          -33.26251220703125,
          -8.037515640258789,
          -9.374796867370605,
          -34.30642318725586,
          50.63832092285156,
          -36.129451751708984,
          17.691997528076172,
          13.872965812683105,
          55.37583541870117,
          53.71987533569336,
          13.37670612335205,
          -11.360600471496582,
          -9.366093635559082,
          20.244129180908203,
          46.95764923095703,
          13.950339317321777,
          -16.500295639038086,
          -13.831923484802246,
          -31.133052825927734,
          10.905072212219238,
          14.608570098876953,
          -27.775774002075195,
          52.577171325683594,
          -22.34561538696289,
          -7.759027004241943,
          -32.905601501464844,
          51.6761360168457,
          -23.294384002685547,
          41.197086334228516,
          56.36714172363281,
          51.95616149902344,
          -20.37462043762207,
          37.420650482177734,
          16.176916122436523,
          19.65836524963379,
          36.50862503051758,
          2.9005115032196045,
          -34.257266998291016,
          11.065699577331543,
          -2.574388265609741,
          17.223102569580078,
          -24.013532638549805,
          11.940500259399414,
          -28.170738220214844,
          54.89808654785156,
          33.52801513671875,
          9.76612663269043,
          4.263469696044922,
          -35.313716888427734,
          16.402984619140625,
          56.340423583984375,
          53.94291687011719,
          -29.58259391784668,
          4.122945308685303,
          -33.75163650512695,
          3.0606558322906494,
          -15.615975379943848,
          14.243011474609375,
          -5.603813648223877,
          20.2333927154541,
          40.394996643066406,
          -29.98781394958496,
          28.618881225585938,
          13.998875617980957,
          -14.572915077209473,
          52.87458419799805,
          -27.09746742248535,
          -35.13167190551758,
          25.507863998413086,
          12.710983276367188,
          -28.445711135864258,
          8.034400939941406,
          -36.105159759521484,
          -24.433673858642578,
          16.39706039428711,
          16.250795364379883,
          56.560890197753906,
          -33.401798248291016,
          12.541916847229004,
          -34.60143280029297,
          25.594865798950195,
          50.515968322753906,
          -31.9215087890625,
          -33.48298645019531,
          54.860511779785156,
          16.301342010498047,
          56.99260330200195,
          5.4217915534973145,
          -19.856422424316406,
          9.36475944519043,
          -4.045228481292725,
          -25.912994384765625,
          -35.41885757446289,
          9.650589942932129,
          10.752983093261719,
          -4.261116981506348,
          54.756526947021484,
          -8.78386402130127,
          13.814626693725586,
          -34.957122802734375,
          54.38689422607422,
          17.39713478088379,
          23.24127960205078,
          -4.15751838684082,
          -11.722189903259277,
          8.73233413696289,
          24.65445327758789,
          46.720951080322266,
          32.74262619018555,
          52.41468048095703,
          22.62185287475586,
          39.64387130737305,
          -25.99201774597168,
          -8.579007148742676,
          19.306406021118164,
          -34.64305877685547,
          12.769086837768555,
          34.79197311401367,
          17.790828704833984,
          55.51526641845703,
          -20.927967071533203,
          -0.4192492365837097,
          -5.31520938873291,
          11.370555877685547,
          34.41270065307617,
          14.922541618347168,
          13.532635688781738,
          13.361416816711426,
          42.352474212646484,
          -35.56498718261719,
          -28.253154754638672,
          53.92995071411133,
          22.59613800048828,
          35.723114013671875,
          21.073993682861328,
          -30.95108413696289,
          53.945167541503906,
          33.83211135864258,
          -22.38446807861328,
          -29.1640682220459,
          -34.906795501708984,
          41.88331604003906,
          -4.02632999420166,
          45.925174713134766,
          0.5435165762901306,
          6.993501663208008,
          -33.49604797363281,
          42.7513313293457,
          13.482671737670898,
          52.653350830078125,
          28.58110809326172,
          3.408895492553711,
          13.815140724182129,
          32.94718551635742,
          -1.9194715023040771,
          22.804716110229492,
          -24.22780990600586,
          48.19939041137695,
          46.74457931518555,
          11.128089904785156,
          27.568117141723633,
          -2.0819995403289795,
          -30.647953033447266,
          -17.85175895690918,
          -33.83255386352539,
          12.59882926940918,
          -11.281927108764648,
          -21.74634552001953,
          -22.410831451416016,
          18.181550979614258,
          -18.386627197265625,
          -9.12735366821289,
          -26.837663650512695,
          -29.346338272094727,
          -7.800839424133301,
          7.327863693237305,
          55.4052734375,
          11.253430366516113,
          52.2940673828125,
          -36.41725540161133,
          41.53528594970703,
          33.952857971191406,
          18.74312973022461,
          54.96622085571289,
          43.02571105957031,
          10.360726356506348,
          -25.745521545410156,
          -18.129077911376953,
          19.681285858154297,
          11.628937721252441,
          15.574275016784668,
          45.896053314208984,
          3.762678384780884,
          13.443629264831543,
          -27.105907440185547,
          52.11488723754883,
          13.124380111694336,
          17.487504959106445,
          21.900890350341797,
          5.65349817276001,
          17.478404998779297,
          19.214923858642578,
          9.543863296508789,
          17.698665618896484,
          13.988237380981445,
          24.47305679321289,
          -7.657983779907227,
          15.183431625366211,
          9.842514038085938,
          13.475126266479492,
          43.8459358215332,
          11.899026870727539,
          1.766961693763733,
          17.33551788330078,
          46.806785583496094,
          41.30109786987305,
          -9.691028594970703,
          45.9451789855957,
          16.73434066772461,
          46.989601135253906,
          6.576215744018555,
          -35.32125473022461,
          19.93367576599121,
          55.8297119140625,
          18.359724044799805,
          14.669174194335938,
          10.84488582611084,
          0.15075446665287018,
          10.391618728637695,
          11.564685821533203,
          -11.348368644714355,
          56.895992279052734,
          41.88774490356445,
          -33.77032470703125,
          -27.684646606445312,
          -32.26365280151367,
          14.151606559753418,
          46.58381652832031,
          12.425429344177246,
          35.77134323120117,
          45.41639709472656,
          37.3570556640625,
          48.10031509399414,
          26.21355628967285,
          8.297774314880371,
          45.60378646850586,
          43.374855041503906,
          -34.472381591796875,
          16.761709213256836,
          -14.484322547912598,
          15.700550079345703,
          -25.898637771606445,
          17.37767791748047,
          46.11420822143555,
          -15.58510684967041,
          -21.426876068115234,
          17.309194564819336,
          -36.205413818359375,
          11.494122505187988,
          -14.85677433013916,
          54.8857536315918,
          -32.80657958984375,
          15.59923267364502,
          10.14352035522461,
          -34.54289627075195,
          -16.692859649658203,
          10.786052703857422,
          -34.7142333984375,
          44.69171905517578,
          -33.667701721191406,
          -12.076728820800781,
          8.09085750579834,
          26.25241470336914,
          20.020004272460938,
          43.6907958984375,
          53.61273193359375,
          -23.4024658203125,
          20.458402633666992,
          -0.8391579985618591,
          -20.52740478515625,
          49.86785125732422,
          -36.68296813964844,
          -31.305322647094727,
          33.52931213378906,
          -24.646718978881836,
          45.31736755371094,
          10.799731254577637,
          56.73625183105469,
          -3.480756998062134,
          31.40981101989746,
          -10.534645080566406,
          50.79052734375,
          24.031171798706055,
          -33.52652359008789,
          27.759334564208984,
          56.812835693359375,
          -9.120699882507324,
          53.21065139770508,
          -36.02272033691406,
          16.84912109375,
          13.000868797302246,
          29.98805046081543,
          26.588438034057617,
          -29.20775032043457,
          11.389195442199707,
          -23.141233444213867,
          17.023822784423828,
          48.56809616088867,
          12.636016845703125,
          56.411155700683594,
          45.9600944519043,
          -6.891350746154785,
          32.568241119384766,
          -7.016184329986572,
          50.683650970458984,
          -26.199199676513672,
          14.112180709838867,
          -7.690089702606201,
          15.87031078338623,
          5.950515270233154,
          53.44329071044922,
          15.649369239807129,
          -35.4837760925293,
          5.398997783660889,
          50.441986083984375,
          -3.5537872314453125,
          -21.786563873291016,
          22.165225982666016,
          26.674888610839844,
          56.8027458190918,
          55.36187744140625,
          44.61780548095703,
          48.530487060546875,
          18.20845603942871,
          20.326488494873047,
          24.079105377197266,
          50.12165069580078,
          13.930603981018066,
          54.13500213623047,
          56.986183166503906,
          54.43875503540039,
          -29.67776870727539,
          4.625502109527588,
          -35.79174041748047,
          9.879555702209473,
          -18.59305763244629,
          27.955469131469727,
          -6.3630757331848145,
          29.713157653808594,
          -33.92824172973633,
          8.103355407714844,
          56.85660934448242,
          20.059368133544922,
          51.917564392089844,
          -32.792320251464844,
          49.70097732543945,
          11.344676971435547,
          13.80783748626709,
          -33.329742431640625,
          52.659732818603516,
          12.317971229553223,
          14.24828815460205,
          -14.364984512329102,
          13.362798690795898,
          14.758628845214844,
          2.3639094829559326,
          45.34675598144531,
          50.841514587402344,
          44.81613540649414,
          -14.531270027160645,
          32.86293411254883,
          -34.94091033935547,
          -20.18175506591797,
          8.275477409362793,
          50.48884201049805,
          -26.309051513671875,
          -27.112239837646484,
          56.007198333740234,
          51.843299865722656,
          18.632171630859375,
          -5.158809185028076,
          5.839366436004639,
          43.337642669677734,
          26.110309600830078,
          -25.669570922851562,
          2.1491940021514893,
          55.210487365722656,
          7.707741737365723,
          51.344486236572266,
          -26.998435974121094,
          23.077953338623047,
          -21.651092529296875,
          52.595008850097656,
          10.950563430786133,
          11.581374168395996,
          5.219881534576416,
          10.351792335510254,
          27.66793441772461,
          -28.271991729736328,
          -0.19455407559871674,
          56.411712646484375,
          -35.94039535522461,
          30.130435943603516,
          23.52517318725586,
          16.750038146972656,
          36.12580871582031,
          22.216520309448242,
          -1.344567894935608,
          -28.135658264160156,
          9.79672908782959,
          3.2087912559509277,
          11.737384796142578,
          26.935976028442383,
          13.493566513061523,
          53.39808654785156,
          56.61656188964844,
          13.183439254760742,
          5.766753673553467,
          49.07966232299805,
          -26.019392013549805,
          -12.314122200012207,
          -2.0836193561553955,
          10.792023658752441,
          -3.427461624145508,
          49.37886428833008,
          -22.85103416442871,
          49.10469436645508,
          35.5886116027832,
          36.602046966552734,
          16.728477478027344,
          4.115388870239258,
          -10.973304748535156,
          -32.22283935546875,
          -34.12108612060547,
          -26.07470703125,
          -15.46127700805664,
          17.136411666870117,
          -22.3591251373291,
          -20.989469528198242,
          55.65802764892578,
          -19.265378952026367,
          15.433980941772461,
          9.712074279785156,
          -18.601600646972656,
          -8.237909317016602,
          -5.514019012451172,
          0.455245703458786,
          -1.551247239112854,
          -13.36899471282959,
          29.83722686767578,
          36.744754791259766,
          45.550357818603516,
          17.528791427612305,
          17.23322105407715,
          11.695332527160645,
          19.31328010559082,
          -20.6867618560791,
          11.305469512939453,
          21.098419189453125,
          -1.0840203762054443,
          11.794183731079102,
          12.835633277893066,
          -35.57011032104492,
          -33.77968215942383,
          -25.851850509643555,
          30.362703323364258,
          34.873748779296875,
          15.042445182800293,
          3.625803232192993,
          14.052517890930176,
          3.7222633361816406,
          8.598336219787598,
          11.993083000183105,
          20.458269119262695,
          44.780357360839844,
          17.677589416503906,
          16.605470657348633,
          12.169050216674805,
          -3.88838267326355,
          -35.8120002746582,
          42.1868896484375,
          12.178297996520996,
          32.1630859375,
          11.966124534606934,
          14.834702491760254,
          9.659358024597168,
          43.73957443237305,
          -22.862037658691406,
          13.564961433410645,
          35.766231536865234,
          27.40650749206543,
          -9.94649887084961,
          53.70846176147461,
          -27.91396713256836,
          -30.36345100402832,
          2.4298489093780518,
          37.15567398071289,
          40.70227813720703,
          49.87451934814453,
          12.167760848999023,
          15.103474617004395,
          9.990864753723145
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"a556c33f-5694-44f6-93c6-f03dc393bd71\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"a556c33f-5694-44f6-93c6-f03dc393bd71\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'a556c33f-5694-44f6-93c6-f03dc393bd71',\n",
       "                        [{\"mode\": \"text\", \"text\": [\"hundreds\", \"of\", \"people\", \"have\", \"been\", \"forced\", \"to\", \"their\", \"homes\", \"in\", \"the\", \"southern\", \"new\", \"south\", \"wales\", \"as\", \"strong\", \"winds\", \"today\", \"huge\", \"towards\", \"town\", \"hill\", \"top\", \"blaze\", \"near\", \"west\", \"sydney\", \"has\", \"highway\", \"at\", \"about\", \"pm\", \"aedt\", \"weather\", \"storm\", \"moved\", \"east\", \"across\", \"blue\", \"mountains\", \"authorities\", \"make\", \"decision\", \"from\", \"streets\", \"an\", \"residents\", \"left\", \"for\", \"nearby\", \"rural\", \"fire\", \"service\", \"says\", \"conditions\", \"which\", \"caused\", \"now\", \"and\", \"around\", \"are\", \"all\", \"more\", \"than\", \"blazes\", \"on\", \"year\", \"eve\", \"crews\", \"called\", \"while\", \"few\", \"details\", \"available\", \"this\", \"stage\", \"it\", \"closed\", \"both\", \"meanwhile\", \"is\", \"no\", \"longer\", \"threatening\", \"area\", \"rain\", \"some\", \"parts\", \"illawarra\", \"hunter\", \"north\", \"coast\", \"but\", \"bureau\", \"done\", \"little\", \"any\", \"hundred\", \"fires\", \"still\", \"burning\", \"state\", \"quite\", \"those\", \"areas\", \"less\", \"five\", \"she\", \"said\", \"places\", \"really\", \"not\", \"significant\", \"so\", \"there\", \"much\", \"far\", \"concerned\", \"fact\", \"they\", \"ve\", \"probably\", \"efforts\", \"firefighters\", \"because\", \"wind\", \"that\", \"with\", \"indian\", \"security\", \"forces\", \"shot\", \"dead\", \"eight\", \"suspected\", \"militants\", \"night\", \"long\", \"kashmir\", \"took\", \"place\", \"capital\", \"deaths\", \"came\", \"pakistani\", \"police\", \"arrested\", \"two\", \"groups\", \"accused\", \"attack\", \"india\", \"parliament\", \"pakistan\", \"based\", \"mohammad\", \"carrying\", \"out\", \"december\", \"military\", \"intelligence\", \"tensions\", \"since\", \"raid\", \"sides\", \"troops\", \"along\", \"border\", \"trading\", \"diplomatic\", \"yesterday\", \"announced\", \"had\", \"chief\", \"mohammed\", \"say\", \"likely\", \"raids\", \"will\", \"be\", \"launched\", \"against\", \"well\", \"other\", \"militant\", \"organisations\", \"between\", \"level\", \"seen\", \"war\", \"national\", \"road\", \"toll\", \"christmas\", \"holiday\", \"period\", \"same\", \"time\", \"last\", \"died\", \"roads\", \"queensland\", \"victoria\", \"western\", \"australia\", \"northern\", \"territory\", \"each\", \"recorded\", \"three\", \"act\", \"tasmania\", \"remain\", \"free\", \"argentina\", \"political\", \"economic\", \"crisis\", \"its\", \"interim\", \"president\", \"who\", \"office\", \"just\", \"week\", \"ago\", \"told\", \"nation\", \"he\", \"could\", \"rescue\", \"key\", \"fellow\", \"would\", \"support\", \"his\", \"massive\", \"foreign\", \"debt\", \"or\", \"plan\", \"was\", \"only\", \"million\", \"jobs\", \"end\", \"four\", \"years\", \"recession\", \"days\", \"after\", \"following\", \"series\", \"failed\", \"senate\", \"leader\", \"until\", \"government\", \"too\", \"another\", \"senior\", \"role\", \"elections\", \"scheduled\", \"march\", \"leaving\", \"worst\", \"by\", \"international\", \"six\", \"suspended\", \"hospital\", \"inappropriate\", \"use\", \"during\", \"work\", \"hours\", \"women\", \"were\", \"labour\", \"health\", \"investigation\", \"further\", \"within\", \"executive\", \"officer\", \"tony\", \"one\", \"put\", \"risk\", \"staff\", \"involved\", \"able\", \"take\", \"over\", \"we\", \"re\", \"very\", \"body\", \"our\", \"these\", \"should\", \"know\", \"better\", \"why\", \"action\", \"them\", \"ll\", \"next\", \"federal\", \"asylum\", \"seekers\", \"return\", \"home\", \"when\", \"environment\", \"secure\", \"kabul\", \"affairs\", \"minister\", \"alexander\", \"downer\", \"refused\", \"how\", \"claims\", \"process\", \"hold\", \"major\", \"threat\", \"most\", \"seeking\", \"many\", \"tried\", \"get\", \"into\", \"matter\", \"britain\", \"countries\", \"europe\", \"claimed\", \"fleeing\", \"taliban\", \"power\", \"afghanistan\", \"finished\", \"mass\", \"detainees\", \"island\", \"pacific\", \"nauru\", \"total\", \"operations\", \"using\", \"aircraft\", \"second\", \"delivered\", \"where\", \"temporary\", \"department\", \"immigration\", \"remaining\", \"spokesman\", \"future\", \"yet\", \"made\", \"united\", \"states\", \"team\", \"seles\", \"michael\", \"scored\", \"victory\", \"france\", \"first\", \"hopman\", \"cup\", \"match\", \"perth\", \"up\", \"event\", \"won\", \"singles\", \"give\", \"us\", \"lead\", \"old\", \"currently\", \"start\", \"fight\", \"hard\", \"winning\", \"then\", \"st\", \"down\", \"determined\", \"th\", \"win\", \"americans\", \"go\", \"swiss\", \"final\", \"great\", \"way\", \"tennis\", \"got\", \"my\", \"am\", \"beat\", \"him\", \"even\", \"though\", \"bit\", \"here\", \"keep\", \"if\", \"do\", \"think\", \"chance\", \"anyone\", \"playing\", \"before\", \"taking\", \"set\", \"american\", \"breaking\", \"third\", \"games\", \"expected\", \"her\", \"tough\", \"player\", \"world\", \"position\", \"you\", \"play\", \"want\", \"try\", \"early\", \"season\", \"opening\", \"quickly\", \"game\", \"completed\", \"despite\", \"celebrations\", \"river\", \"kilometres\", \"battling\", \"hot\", \"melbourne\", \"strongly\", \"contested\", \"afternoon\", \"thursday\", \"line\", \"others\", \"fell\", \"red\", \"cross\", \"overnight\", \"containment\", \"lines\", \"severe\", \"getting\", \"forecast\", \"continue\", \"temperatures\", \"high\", \"least\", \"friday\", \"means\", \"fighters\", \"guard\", \"lot\", \"known\", \"contained\", \"however\", \"given\", \"coming\", \"property\", \"greater\", \"brought\", \"under\", \"control\", \"spencer\", \"city\", \"lower\", \"kilometre\", \"protect\", \"communities\", \"morning\", \"large\", \"above\", \"also\", \"used\", \"drop\", \"commissioner\", \"activity\", \"smoke\", \"being\", \"asked\", \"avoid\", \"reduced\", \"hour\", \"access\", \"royal\", \"park\", \"local\", \"allowed\", \"continuing\", \"thousands\", \"storms\", \"struck\", \"force\", \"trees\", \"cars\", \"energy\", \"every\", \"person\", \"working\", \"through\", \"brisbane\", \"toowoomba\", \"car\", \"inside\", \"fierce\", \"sent\", \"tree\", \"house\", \"injured\", \"entered\", \"official\", \"killed\", \"destroyed\", \"part\", \"began\", \"heritage\", \"traditional\", \"trapped\", \"flames\", \"markets\", \"buildings\", \"blame\", \"death\", \"themselves\", \"victims\", \"public\", \"cut\", \"short\", \"inquiry\", \"general\", \"musharraf\", \"wants\", \"prepared\", \"respond\", \"peace\", \"reduce\", \"tension\", \"move\", \"taken\", \"measures\", \"armed\", \"face\", \"might\", \"received\", \"parties\", \"welcomed\", \"community\", \"trying\", \"like\", \"positive\", \"union\", \"group\", \"nations\", \"among\", \"resolve\", \"stand\", \"off\", \"offer\", \"holding\", \"talks\", \"prime\", \"saying\", \"gives\", \"me\", \"accept\", \"reject\", \"meet\", \"january\", \"regional\", \"cooperation\", \"summit\", \"ruled\", \"assault\", \"warned\", \"saturday\", \"dispute\", \"growing\", \"small\", \"conflict\", \"sunday\", \"meeting\", \"situation\", \"domestic\", \"society\", \"form\", \"terrorism\", \"eastern\", \"afghan\", \"british\", \"officials\", \"ended\", \"without\", \"agreement\", \"lack\", \"document\", \"delay\", \"giving\", \"weeks\", \"number\", \"peacekeepers\", \"allow\", \"dr\", \"appeared\", \"signed\", \"already\", \"soon\", \"nothing\", \"sign\", \"proposals\", \"commanders\", \"occupation\", \"israeli\", \"army\", \"palestinian\", \"attacked\", \"gaza\", \"strip\", \"palestinians\", \"opened\", \"vehicle\", \"jewish\", \"edge\", \"sources\", \"post\", \"gunmen\", \"killing\", \"months\", \"including\", \"israelis\", \"october\", \"radical\", \"islamic\", \"hamas\", \"settlement\", \"can\", \"stop\", \"overall\", \"honours\", \"hobart\", \"yacht\", \"race\", \"ian\", \"boat\", \"appears\", \"title\", \"rival\", \"away\", \"nine\", \"metre\", \"boats\", \"australian\", \"losing\", \"geoff\", \"point\", \"apparently\", \"reported\", \"injuries\", \"africa\", \"spinner\", \"test\", \"african\", \"squad\", \"tour\", \"due\", \"injury\", \"captain\", \"shaun\", \"pollock\", \"hopes\", \"prepare\", \"ready\", \"going\", \"come\", \"best\", \"possible\", \"begun\", \"campaign\", \"doubles\", \"hoping\", \"nice\", \"always\", \"good\", \"looking\", \"forward\", \"see\", \"again\", \"hewitt\", \"putting\", \"pressure\", \"himself\", \"month\", \"open\", \"switzerland\", \"tie\", \"reach\", \"grand\", \"per\", \"cent\", \"happens\", \"times\", \"sort\", \"zealand\", \"lord\", \"director\", \"peter\", \"list\", \"seven\", \"classic\", \"country\", \"order\", \"budget\", \"biggest\", \"ever\", \"become\", \"dropped\", \"front\", \"predicted\", \"change\", \"mark\", \"williams\", \"incident\", \"region\", \"back\", \"close\", \"mr\", \"something\", \"don\", \"banks\", \"help\", \"payment\", \"workers\", \"issued\", \"leaders\", \"banking\", \"what\", \"happened\", \"monday\", \"man\", \"crash\", \"mid\", \"boy\", \"hit\", \"telephone\", \"remains\", \"condition\", \"petrol\", \"david\", \"laws\", \"hoped\", \"built\", \"prior\", \"required\", \"such\", \"increase\", \"separate\", \"flights\", \"gun\", \"carry\", \"finally\", \"stopped\", \"plane\", \"travelled\", \"attempting\", \"board\", \"flight\", \"personnel\", \"hand\", \"released\", \"planning\", \"terrorist\", \"ability\", \"airline\", \"problems\", \"follows\", \"paris\", \"explosives\", \"shoes\", \"tourists\", \"safety\", \"central\", \"emergency\", \"search\", \"became\", \"soft\", \"ground\", \"unit\", \"officers\", \"walk\", \"winner\", \"decided\", \"gary\", \"crossed\", \"almost\", \"half\", \"fleet\", \"leading\", \"victorian\", \"minute\", \"clear\", \"fast\", \"skipper\", \"blake\", \"successful\", \"weekend\", \"lost\", \"greatest\", \"concern\", \"changes\", \"extensive\", \"conducted\", \"heading\", \"battle\", \"suicide\", \"backed\", \"never\", \"mind\", \"side\", \"round\", \"ocean\", \"assa\", \"abloy\", \"accompanied\", \"light\", \"starting\", \"crowd\", \"behind\", \"crew\", \"yachts\", \"rest\", \"laden\", \"hearing\", \"court\", \"richard\", \"reid\", \"placed\", \"wall\", \"created\", \"grant\", \"possibility\", \"later\", \"charged\", \"jail\", \"terms\", \"charges\", \"allegedly\", \"airlines\", \"enough\", \"disaster\", \"leadership\", \"calling\", \"envoy\", \"anthony\", \"zinni\", \"cease\", \"retired\", \"marine\", \"late\", \"november\", \"secretary\", \"colin\", \"powell\", \"earlier\", \"bring\", \"halt\", \"statement\", \"yasser\", \"arafat\", \"calls\", \"violence\", \"confidence\", \"building\", \"agreed\", \"several\", \"played\", \"administration\", \"believe\", \"presence\", \"effective\", \"bringing\", \"council\", \"rate\", \"hiv\", \"male\", \"sex\", \"twice\", \"report\", \"centre\", \"disease\", \"need\", \"feel\", \"statistics\", \"show\", \"previous\", \"figures\", \"wake\", \"call\", \"rise\", \"sea\", \"levels\", \"global\", \"according\", \"survey\", \"antarctic\", \"organisation\", \"giant\", \"ice\", \"vaughan\", \"case\", \"serious\", \"increased\", \"water\", \"did\", \"metres\", \"break\", \"related\", \"impact\", \"human\", \"industrial\", \"cannot\", \"problem\", \"potential\", \"cities\", \"low\", \"september\", \"shane\", \"may\", \"room\", \"outlook\", \"certainly\", \"ahead\", \"concerns\", \"continues\", \"carried\", \"mt\", \"targeted\", \"boys\", \"heights\", \"ministry\", \"embassy\", \"representation\", \"ban\", \"planes\", \"delhi\", \"ahmed\", \"actions\", \"complex\", \"mission\", \"movement\", \"added\", \"result\", \"non\", \"operating\", \"threatened\", \"defence\", \"osama\", \"bin\", \"saudi\", \"protection\", \"supporters\", \"helped\", \"create\", \"sure\", \"lives\", \"information\", \"men\", \"arrest\", \"head\", \"party\", \"al\", \"qaeda\", \"network\", \"attacks\", \"york\", \"washington\", \"collapsed\", \"completely\", \"individuals\", \"resistance\", \"mayor\", \"giuliani\", \"led\", \"past\", \"trade\", \"speaking\", \"day\", \"crime\", \"source\", \"difficult\", \"deadly\", \"comes\", \"ensure\", \"your\", \"felt\", \"job\", \"turn\", \"believed\", \"served\", \"term\", \"prevent\", \"media\", \"batsmen\", \"boxing\", \"wicket\", \"runs\", \"andy\", \"bichel\", \"langer\", \"matthew\", \"hayden\", \"went\", \"innings\", \"bowling\", \"jacques\", \"kallis\", \"neil\", \"mckenzie\", \"wickets\", \"balls\", \"caught\", \"although\", \"showed\", \"ball\", \"klusener\", \"boucher\", \"adding\", \"waugh\", \"paid\", \"brett\", \"lee\", \"leg\", \"continued\", \"field\", \"running\", \"henderson\", \"direct\", \"allan\", \"donald\", \"ricky\", \"ponting\", \"returning\", \"glenn\", \"mcgrath\", \"rafter\", \"swept\", \"nearly\", \"whether\", \"survived\", \"pulled\", \"member\", \"found\", \"helicopter\", \"big\", \"wave\", \"knew\", \"arrived\", \"damage\", \"news\", \"radio\", \"suburbs\", \"throughout\", \"average\", \"things\", \"expects\", \"john\", \"confirm\", \"criminal\", \"muslim\", \"extremists\", \"jihad\", \"beginning\", \"television\", \"held\", \"virgin\", \"attempt\", \"ansett\", \"internet\", \"travel\", \"adelaide\", \"launceston\", \"canberra\", \"customers\", \"largest\", \"base\", \"market\", \"press\", \"main\", \"business\", \"endeavour\", \"claim\", \"suffered\", \"life\", \"run\", \"land\", \"bank\", \"heavy\", \"tanks\", \"helicopters\", \"jenin\", \"attacking\", \"immediately\", \"israel\", \"soldiers\", \"returned\", \"escaped\", \"self\", \"rule\", \"authority\", \"injuring\", \"slightly\", \"fired\", \"exchange\", \"sir\", \"actor\", \"civil\", \"yes\", \"wednesday\", \"heart\", \"aged\", \"cancer\", \"having\", \"treatment\", \"awards\", \"approval\", \"range\", \"king\", \"george\", \"secret\", \"thing\", \"cricket\", \"proteas\", \"resume\", \"affected\", \"flying\", \"band\", \"expect\", \"population\", \"passed\", \"mountain\", \"confident\", \"tomorrow\", \"services\", \"whole\", \"fair\", \"share\", \"find\", \"expressed\", \"circumstances\", \"whatever\", \"needs\", \"annual\", \"speech\", \"changed\", \"itself\", \"beyond\", \"america\", \"history\", \"humanity\", \"live\", \"terror\", \"wounded\", \"fighter\", \"weapons\", \"kandahar\", \"governor\", \"custody\", \"surrender\", \"bombing\", \"airport\", \"militia\", \"handed\", \"russian\", \"important\", \"republic\", \"spread\", \"money\", \"look\", \"system\", \"project\", \"ways\", \"prisoners\", \"justice\", \"coalition\", \"families\", \"financial\", \"rights\", \"spokeswoman\", \"trial\", \"education\", \"programs\", \"ms\", \"centrelink\", \"income\", \"employment\", \"pay\", \"child\", \"shopping\", \"sergeant\", \"shortly\", \"members\", \"stuart\", \"bush\", \"question\", \"improve\", \"receiving\", \"questions\", \"pace\", \"jason\", \"gillespie\", \"right\", \"hopefully\", \"provide\", \"bowler\", \"jets\", \"saw\", \"passengers\", \"ceremony\", \"hamid\", \"karzai\", \"cabinet\", \"economy\", \"cost\", \"dollars\", \"must\", \"plans\", \"projects\", \"various\", \"believes\", \"tora\", \"bora\", \"caves\", \"visit\", \"bid\", \"does\", \"enter\", \"searching\", \"signs\", \"suspect\", \"warplanes\", \"commander\", \"charge\", \"gone\", \"pentagon\", \"macgill\", \"full\", \"steve\", \"adam\", \"warne\", \"rejected\", \"terrorists\", \"ariel\", \"sharon\", \"declared\", \"staying\", \"bombings\", \"smaller\", \"follow\", \"save\", \"young\", \"requested\", \"normal\", \"technology\", \"ill\", \"professor\", \"deputy\", \"institute\", \"law\", \"opposition\", \"thought\", \"family\", \"making\", \"japanese\", \"unidentified\", \"reports\", \"japan\", \"warning\", \"approach\", \"church\", \"handling\", \"alleged\", \"abuse\", \"anglican\", \"school\", \"howard\", \"hollingworth\", \"criticism\", \"archbishop\", \"resign\", \"costello\", \"explanation\", \"needed\", \"step\", \"understanding\", \"simon\", \"crean\", \"described\", \"legal\", \"advice\", \"heard\", \"understand\", \"gave\", \"confirmed\", \"timor\", \"comment\", \"responsibility\", \"leave\", \"company\", \"guess\", \"unity\", \"followed\", \"program\", \"fund\", \"policy\", \"effort\", \"freeze\", \"qantas\", \"maintenance\", \"relations\", \"commission\", \"employees\", \"billion\", \"gas\", \"reached\", \"phillips\", \"deal\", \"offered\", \"ministers\", \"abu\", \"worked\", \"documents\", \"factory\", \"former\", \"true\", \"read\", \"tell\", \"real\", \"detail\", \"names\", \"premier\", \"facility\", \"allegations\", \"knowledge\", \"evidence\", \"voted\", \"deployed\", \"initial\", \"mandate\", \"assistance\", \"un\", \"resolution\", \"numbers\", \"eventually\", \"germany\", \"bonn\", \"anti\", \"nuclear\", \"assisting\", \"bomb\", \"provided\", \"crackdown\", \"food\", \"clashes\", \"powers\", \"fear\", \"unrest\", \"own\", \"woomera\", \"detention\", \"visa\", \"outside\", \"recent\", \"bill\", \"private\", \"sector\", \"credit\", \"data\", \"doctors\", \"ask\", \"research\", \"companies\", \"medical\", \"record\", \"often\", \"solution\", \"consumers\", \"dozens\", \"seriously\", \"roof\", \"children\", \"witnesses\", \"collapse\", \"everything\", \"fine\", \"manager\", \"afp\", \"agency\", \"corporation\", \"son\", \"zimbabwe\", \"white\", \"commonwealth\", \"mean\", \"issue\", \"declaration\", \"table\", \"waiting\", \"response\", \"request\", \"observers\", \"election\", \"territories\", \"nablus\", \"improved\", \"pre\", \"bombers\", \"jerusalem\", \"haifa\", \"interest\", \"unfortunately\", \"robert\", \"august\", \"senator\", \"whereabouts\", \"hicks\", \"fighting\", \"alongside\", \"vote\", \"relationship\", \"operation\", \"latest\", \"stay\", \"assembly\", \"elders\", \"draft\", \"damaged\", \"current\", \"voice\", \"twenty\", \"reveal\", \"refugees\", \"australians\", \"detain\", \"transport\", \"air\", \"strachan\", \"training\", \"crashed\", \"strike\", \"accident\", \"students\", \"findings\", \"harris\", \"investment\", \"asic\", \"include\", \"counts\", \"acting\", \"management\", \"coroner\", \"investigating\", \"hearings\", \"ray\", \"qc\", \"representing\", \"experts\", \"begin\", \"named\", \"sometimes\", \"advance\", \"marines\", \"revealed\", \"captured\", \"hunt\", \"jalalabad\", \"bomber\", \"strikes\", \"actually\", \"responding\", \"insurance\", \"alliance\", \"approached\", \"july\", \"proposed\", \"labor\", \"issues\", \"options\", \"didn\", \"single\", \"anything\", \"fatah\", \"factions\", \"rather\", \"offices\", \"started\", \"tuesday\", \"focus\", \"strategic\", \"targets\", \"review\", \"meetings\", \"violent\", \"farm\", \"discussions\", \"debate\", \"disappointed\", \"philip\", \"ruddock\", \"understood\", \"attorney\", \"daryl\", \"aboard\", \"asio\", \"appropriate\", \"present\", \"finding\", \"tribal\", \"doubt\", \"pilot\", \"procedures\", \"aboriginal\", \"sentence\", \"administrators\", \"paying\", \"entitlements\", \"redundancy\", \"decide\", \"absolutely\", \"hih\", \"creditors\", \"firm\", \"chairman\", \"finance\", \"directors\", \"receive\", \"tailenders\", \"scene\", \"channel\", \"facilities\", \"whose\", \"examination\", \"unions\", \"adequate\", \"together\", \"necessary\", \"rumsfeld\", \"networks\", \"recovery\", \"decisions\", \"oil\", \"growth\", \"structure\", \"university\", \"cause\", \"negotiations\", \"club\", \"elected\", \"happy\", \"picked\", \"outcome\", \"treated\", \"hope\", \"headquarters\", \"cave\", \"interview\", \"different\", \"investigate\", \"escalating\", \"doing\", \"french\", \"negotiating\", \"address\", \"middle\", \"wanted\", \"locked\", \"wage\", \"manufacturing\", \"doug\", \"cameron\", \"seemed\", \"sharing\", \"sending\", \"quarter\", \"coup\", \"invasion\", \"shows\", \"volunteers\", \"clean\", \"track\", \"space\", \"shuttle\", \"station\", \"landed\", \"trip\", \"walked\", \"proposal\", \"publicly\", \"hotel\", \"indonesian\", \"suharto\", \"vice\", \"indonesia\", \"solomon\", \"islands\", \"ballot\", \"positions\", \"ethnic\", \"success\", \"conference\", \"met\", \"words\", \"target\", \"fall\", \"special\", \"interests\", \"promised\", \"doesn\", \"costs\", \"yallourn\", \"mining\", \"convicted\", \"whiting\", \"murder\", \"sarah\", \"career\", \"hijacked\", \"tape\", \"sheikh\", \"aware\", \"denied\", \"connection\", \"underway\", \"woman\", \"infected\", \"gunships\", \"bus\", \"ambush\", \"blasted\", \"ramallah\", \"wing\", \"responsible\", \"unemployment\", \"westpac\", \"anz\", \"bargaining\", \"industry\", \"lording\", \"construction\", \"cfmeu\", \"martin\", \"kingham\", \"faces\", \"bob\", \"neville\", \"headed\", \"clearly\", \"unable\", \"guilty\", \"verdict\", \"ford\", \"lockett\", \"interlaken\", \"tragedy\", \"adventure\", \"canyoning\", \"manslaughter\", \"guides\", \"farmers\", \"coach\", \"co\", \"friedli\", \"francs\", \"gang\", \"reserve\", \"committee\", \"drug\", \"study\", \"decades\", \"results\", \"doctor\", \"gambier\", \"path\", \"amin\", \"peres\", \"determine\", \"lung\", \"kieren\", \"champion\", \"suggested\", \"rates\", \"provisional\", \"liquidation\", \"civilians\", \"sultan\", \"course\", \"butterfly\", \"afroz\", \"goshen\", \"wayne\", \"flood\", \"gorge\", \"gerber\", \"kissinger\", \"stability\", \"replied\", \"launch\", \"davis\", \"krishna\", \"products\", \"chosen\", \"treasurer\", \"cuts\", \"natural\", \"races\", \"eliminated\", \"austar\", \"traveland\", \"apra\", \"masood\", \"tonight\", \"rabbani\", \"virus\", \"ses\", \"harrison\", \"ashes\", \"benares\", \"beatle\", \"hare\", \"choosing\", \"owen\"], \"type\": \"scatter\", \"x\": [6.987914085388184, 43.54826354980469, 35.50959396362305, 43.52037811279297, 35.78676223754883, 9.408696174621582, 44.26482009887695, 41.10158920288086, 4.35351037979126, 44.0360221862793, 39.77569580078125, 19.828943252563477, 41.52598190307617, 40.75772476196289, 47.62147521972656, 44.56865310668945, 45.20519256591797, 46.80210876464844, 36.45764923095703, -4.531875133514404, 13.258060455322266, 7.208590507507324, 35.82487106323242, 0.015487306751310825, -18.836143493652344, 31.63606071472168, 30.606521606445312, 31.184629440307617, 44.952816009521484, 1.820544719696045, 44.482418060302734, 39.08378601074219, 14.32950210571289, 6.109614849090576, 43.34783172607422, 12.776952743530273, -9.690340995788574, 30.935749053955078, 44.03907012939453, 31.785642623901367, 44.15387725830078, 43.7311897277832, 44.90947341918945, 29.260555267333984, 44.77316665649414, -10.582367897033691, 42.31787872314453, -20.57769012451172, 38.344966888427734, 43.925071716308594, -30.62425994873047, -31.286195755004883, 33.98409652709961, 45.71174240112305, 44.59746551513672, 40.229515075683594, 40.199214935302734, 2.1224355697631836, 33.80079650878906, 44.06654739379883, 31.74947166442871, 44.917667388916016, 32.04639434814453, 39.25639724731445, 34.252689361572266, 1.6829642057418823, 44.97629165649414, 38.4842643737793, 4.953417778015137, 0.12010091543197632, 45.33171463012695, 30.543581008911133, 40.73332595825195, -19.884334564208984, -6.378032684326172, 39.718666076660156, -34.588096618652344, 39.447601318359375, -38.648624420166016, 39.20075988769531, 35.07774353027344, 42.974761962890625, 33.48638916015625, -37.96833801269531, 1.1315548419952393, 38.929508209228516, -38.97389221191406, 33.73031997680664, -3.689572334289551, -16.913692474365234, 3.8091561794281006, 32.83778381347656, 10.422080039978027, 41.169761657714844, 30.576438903808594, -39.01204299926758, -38.79668426513672, 33.507503509521484, 0.4290851652622223, 27.455852508544922, 31.342607498168945, 3.3961212635040283, 31.280067443847656, 0.8443487286567688, 31.42483139038086, 33.4640007019043, -11.676936149597168, 30.642818450927734, 31.407878875732422, 37.928951263427734, -39.71798324584961, 23.265094757080078, 39.02363586425781, -4.766316890716553, 30.669742584228516, 34.81159210205078, 41.51511001586914, 1.8216581344604492, 3.230426788330078, -29.724624633789062, 41.610435485839844, 38.55814743041992, 4.961911201477051, -17.809228897094727, 43.71324920654297, 33.74075698852539, -9.594724655151367, 41.8658561706543, 44.47113800048828, 39.58608627319336, 32.275848388671875, 30.413436889648438, 30.654552459716797, 45.67177963256836, 37.3435173034668, -3.1648926734924316, 46.12940216064453, 32.87460708618164, 37.88063049316406, -0.8963136076927185, 44.50675964355469, 42.38731384277344, 6.059698581695557, 16.76644515991211, 20.714794158935547, -1.725038766860962, 33.465885162353516, 35.674251556396484, 43.87411117553711, 42.20578384399414, 14.957456588745117, 35.10203552246094, 41.15818405151367, 7.337830066680908, 30.620838165283203, 10.800344467163086, -7.088927745819092, 10.21823787689209, 37.92285919189453, 35.28931427001953, 30.644384384155273, 3.161557197570801, -24.59817886352539, 33.06184768676758, 2.408963203430176, -40.75481033325195, 46.6843147277832, 24.679819107055664, -1.7499948740005493, 2.2572884559631348, -30.464757919311523, 31.477127075195312, -7.487878322601318, 40.508811950683594, 40.0385627746582, 5.448762893676758, 32.967777252197266, 1.0540947914123535, 2.695711612701416, 41.1400032043457, 38.28944396972656, 29.052671432495117, 37.4753303527832, 39.109134674072266, 30.557401657104492, 9.087465286254883, -29.13863754272461, 30.3985652923584, -40.323280334472656, -36.71302795410156, 44.4515495300293, 32.254791259765625, -6.908594131469727, -4.832961082458496, 46.66563415527344, 4.0289306640625, -16.521997451782227, 14.979515075683594, 30.622661590576172, 36.50160217285156, 34.97077941894531, 3.0028676986694336, 46.544254302978516, -18.78224754333496, 18.842397689819336, 34.46419143676758, 38.59358596801758, 8.573155403137207, 7.378965377807617, -36.03740692138672, 36.95685577392578, 28.101688385009766, -38.110877990722656, 22.634031295776367, -16.722131729125977, -33.120208740234375, 24.365354537963867, 41.878318786621094, -39.22502517700195, 39.25395584106445, 46.12675476074219, 33.126930236816406, 41.017784118652344, -31.565813064575195, 31.044876098632812, 33.96295928955078, 38.36670684814453, 34.89316177368164, -38.479591369628906, 34.8917236328125, 33.85917282104492, -14.288857460021973, 23.27981185913086, -38.04118347167969, 36.01324462890625, 41.68567657470703, 40.69356918334961, -9.179267883300781, 33.65803909301758, -35.8206787109375, 33.81858825683594, 1.5209753513336182, 40.450008392333984, 41.52452850341797, 28.722030639648438, 16.969324111938477, 46.62752914428711, 34.988197326660156, 33.123939514160156, -19.801910400390625, 30.38943099975586, 44.8870735168457, 38.503562927246094, 10.265264511108398, 9.58420467376709, -6.579433917999268, 33.93428421020508, 3.056546211242676, 34.53274917602539, 44.47311019897461, 35.103919982910156, 45.75296401977539, 35.97626876831055, -38.8570442199707, -23.687551498413086, 22.26546287536621, 4.873266696929932, -39.77747344970703, 44.413883209228516, 30.83382797241211, 33.4128303527832, 2.3104336261749268, 44.309326171875, -0.16860094666481018, 27.545230865478516, 34.15947341918945, 39.789756774902344, 36.21385955810547, 16.762060165405273, 43.41785430908203, -38.96147918701172, 44.735633850097656, 0.5461201071739197, 37.5681266784668, 8.606614112854004, 17.68642234802246, -6.0369486808776855, -23.14546012878418, 34.27471923828125, 42.744815826416016, 25.148984909057617, 33.10593032836914, -3.485119104385376, 6.474118232727051, 38.204654693603516, 37.035400390625, 41.61960220336914, 31.413101196289062, 30.566335678100586, 3.080000877380371, 30.66030502319336, 37.606109619140625, 35.37531661987305, 39.00955581665039, 46.730865478515625, -10.749066352844238, 30.92176628112793, 31.718204498291016, -24.872760772705078, 30.91973304748535, 33.540771484375, 45.08011245727539, 46.62805938720703, 23.170753479003906, 33.69126892089844, 41.30034637451172, -18.676288604736328, 0.38898664712905884, 13.314428329467773, -34.817501068115234, 42.50593185424805, 3.309807538986206, 13.424405097961426, -33.231510162353516, 43.4218864440918, 36.98371505737305, 22.048812866210938, -28.517663955688477, 39.61042785644531, -39.394893646240234, 38.80303955078125, -39.671905517578125, 43.50227737426758, -38.275943756103516, 33.3244514465332, 41.87975311279297, -13.986112594604492, 14.97903823852539, 4.372488021850586, -9.640256881713867, 19.131181716918945, -39.139678955078125, 31.957197189331055, 39.81092834472656, 33.39731979370117, -0.9364049434661865, -10.115472793579102, 38.87342071533203, 5.15298318862915, 12.909181594848633, -3.6102101802825928, -37.54722595214844, 3.7609565258026123, 4.397212505340576, 46.618980407714844, 31.422822952270508, -8.552688598632812, 31.229232788085938, -10.780303001403809, 16.171871185302734, 1.4773128032684326, -37.26283645629883, 44.930294036865234, -30.4558162689209, -26.01015853881836, 30.99540138244629, 31.314443588256836, 31.9460391998291, 38.3482666015625, -40.082550048828125, -24.883760452270508, -30.563228607177734, 19.36836814880371, -37.38439178466797, 38.715518951416016, -21.24608039855957, 45.554195404052734, 46.69197463989258, 0.7391449809074402, 36.11983871459961, 42.22426223754883, 43.241241455078125, -33.3459587097168, 33.101680755615234, 37.75908660888672, 30.86635971069336, 30.03911018371582, -2.1928751468658447, 45.361000061035156, 4.050197601318359, 19.16622543334961, -37.99555587768555, 36.10865020751953, -2.897313356399536, 30.312442779541016, -11.603132247924805, 22.775999069213867, 46.57080078125, 3.5254290103912354, 35.45911407470703, 5.0444135665893555, 13.298770904541016, 25.438161849975586, 45.318809509277344, 8.289924621582031, 36.60539627075195, 3.2120583057403564, 39.27069091796875, -28.848066329956055, 30.80890464782715, 35.65361022949219, 2.653472900390625, 0.3370293378829956, 35.31343078613281, -3.4422500133514404, 39.104549407958984, 43.112823486328125, 30.44879722595215, -37.29481887817383, -37.00472640991211, -27.455867767333984, 36.85045623779297, 6.647802352905273, 41.50067138671875, 19.802261352539062, -1.0905125141143799, 43.059593200683594, -10.098258972167969, 46.69983673095703, 46.746192932128906, -30.95551109313965, 3.4251809120178223, 37.50702667236328, 9.43423843383789, 37.23810577392578, 46.421443939208984, 39.59982681274414, -17.21309471130371, 40.207977294921875, -2.9564664363861084, 3.622525453567505, -5.5845489501953125, -37.66145324707031, 2.6973206996917725, 40.766536712646484, 2.381126642227173, 46.27322769165039, 0.7768768072128296, -11.243324279785156, 1.3919874429702759, 32.59164047241211, -33.787513732910156, -10.135204315185547, -12.664132118225098, -24.804943084716797, 42.239810943603516, 18.111595153808594, -13.048856735229492, -32.42976760864258, -7.3390069007873535, 45.87506866455078, -3.6241374015808105, -23.24197769165039, -37.23949432373047, 3.0690786838531494, -30.198802947998047, 20.498441696166992, 4.19891357421875, 44.2864875793457, 3.9857664108276367, -22.287883758544922, -5.30980920791626, 42.04185104370117, -23.129453659057617, 22.760910034179688, -5.981528282165527, -9.964923858642578, 46.57651901245117, 45.28959274291992, -4.0945353507995605, -22.185274124145508, -25.281627655029297, 6.146195411682129, 30.2860050201416, 44.530029296875, 3.306323766708374, 31.401405334472656, -11.918787002563477, -3.8501250743865967, -24.508567810058594, -19.833070755004883, 32.39167785644531, 7.738851070404053, -40.0229606628418, 39.89200973510742, 17.22355079650879, 3.560041666030884, 22.813846588134766, -19.240009307861328, -22.47272491455078, 30.25095558166504, 46.610191345214844, -11.382123947143555, 1.626249074935913, 5.17249870300293, -11.925463676452637, 43.718849182128906, -14.302512168884277, 30.41241455078125, -7.948243618011475, 14.693143844604492, -41.54827117919922, 2.5690503120422363, -24.681846618652344, 32.5852165222168, 13.81973648071289, -34.814388275146484, 28.47663116455078, 27.356754302978516, 15.226593971252441, 42.124366760253906, 31.57302474975586, 4.45680570602417, -5.006656169891357, -19.75687599182129, -6.7215352058410645, -32.494293212890625, 2.389669418334961, -39.20911407470703, 34.75947570800781, 45.36567306518555, -34.1177978515625, 46.36918640136719, 33.1237678527832, -35.83985900878906, 46.53801345825195, 3.0903499126434326, -27.82288932800293, -35.3547477722168, 4.310983180999756, -34.74018096923828, -34.77788543701172, 4.567836284637451, -16.731401443481445, 20.207515716552734, -38.01221466064453, -15.796186447143555, 43.9334831237793, 26.99165916442871, 10.052141189575195, 1.2354998588562012, 32.393436431884766, -40.40824508666992, 12.343949317932129, -37.392398834228516, -39.86723327636719, 44.83860778808594, -22.13370704650879, 5.405575752258301, 9.353686332702637, 28.913925170898438, -16.650320053100586, 19.73105812072754, 5.939143657684326, 10.608657836914062, 30.124019622802734, 2.5709540843963623, -1.6192123889923096, 20.15826988220215, 33.21281051635742, 42.63196563720703, 3.202834367752075, 30.523540496826172, 30.599855422973633, 19.84734535217285, 7.093409061431885, -38.971866607666016, 3.83632493019104, 32.80936813354492, 46.39484405517578, -7.848150253295898, 44.39549255371094, 47.02067947387695, 46.569358825683594, -32.476314544677734, 4.35276985168457, -28.436687469482422, 1.0598889589309692, -39.4668083190918, 2.8658688068389893, -38.75562286376953, -7.391531944274902, -14.994138717651367, -17.4328670501709, -41.44701385498047, 2.895458221435547, -22.655797958374023, 19.180187225341797, -8.01951789855957, -27.926645278930664, -38.49063491821289, 8.087684631347656, 30.954835891723633, 2.3553097248077393, -1.0088194608688354, -11.572550773620605, -17.76847267150879, 35.50128936767578, 34.78249740600586, 30.44911766052246, 28.628705978393555, 30.586105346679688, -37.20915603637695, 46.50250244140625, 46.40445327758789, -5.2202911376953125, -20.201690673828125, -12.950730323791504, -38.86930847167969, 13.835660934448242, 37.51020050048828, 0.1412144899368286, 10.375284194946289, 46.29214096069336, -29.751590728759766, -39.85382843017578, 26.175838470458984, -3.559138774871826, 2.24060320854187, -19.84421730041504, -2.1240270137786865, -24.626150131225586, -17.359325408935547, 37.45723342895508, 15.448837280273438, 41.25409698486328, 2.5458695888519287, 34.266597747802734, 4.197531223297119, 23.70170783996582, 7.061214447021484, -8.553293228149414, -26.139339447021484, 3.7157137393951416, -3.574228048324585, -1.8223719596862793, -38.6463623046875, 3.5413029193878174, 36.89820098876953, 30.77305030822754, 23.83656120300293, -33.26697540283203, 8.988468170166016, 30.581666946411133, 30.4708194732666, -26.311922073364258, 31.221942901611328, 43.902278900146484, -36.112552642822266, -20.264842987060547, -17.553499221801758, 4.217087268829346, 46.810569763183594, -34.830360412597656, 11.295110702514648, -21.375946044921875, 0.38611164689064026, -26.000722885131836, -23.376338958740234, -29.373022079467773, -13.151965141296387, -2.7674028873443604, 40.45277404785156, -7.354918003082275, -7.045730113983154, 7.525834083557129, -4.6912312507629395, -6.5183563232421875, -21.118045806884766, 41.705467224121094, -34.848350524902344, 31.42625617980957, 16.44815444946289, -12.63595962524414, -26.870031356811523, 30.877304077148438, -37.69163513183594, 44.86909484863281, -15.723663330078125, -7.405544757843018, -36.443328857421875, 4.628629684448242, 2.37267804145813, 44.31570053100586, 46.4326057434082, 16.852985382080078, 40.461368560791016, -5.004666805267334, 16.687002182006836, -14.988764762878418, -13.201125144958496, -5.175724029541016, 3.580205202102661, 41.94737243652344, 46.43574905395508, 3.725255012512207, 12.508380889892578, 14.209168434143066, 2.741330862045288, 1.825708031654358, 39.887508392333984, 12.343340873718262, 35.449378967285156, 11.165016174316406, -21.736129760742188, -28.638446807861328, -4.773890495300293, -23.252742767333984, 30.445005416870117, 30.087203979492188, -38.83573532104492, 4.749671459197998, 0.16850051283836365, 5.967921733856201, -36.01292419433594, 45.23099136352539, 40.23668670654297, -11.596888542175293, 8.912400245666504, -39.44232177734375, 15.123340606689453, -10.448219299316406, 4.703165054321289, 1.6666476726531982, -20.48003387451172, 5.12099552154541, -40.16194534301758, -31.45691680908203, -27.59099769592285, 43.09778594970703, 27.765823364257812, 36.75101852416992, -41.131614685058594, 20.683712005615234, 32.870643615722656, 46.57630920410156, 40.261104583740234, -26.55837631225586, 43.693241119384766, -15.329122543334961, 44.530677795410156, -5.181879997253418, 31.076101303100586, 0.24352706968784332, 45.631797790527344, -0.7939931154251099, 30.667116165161133, -36.570404052734375, 44.2816162109375, 33.58568572998047, 9.476958274841309, -38.89236068725586, -24.060209274291992, 44.63960647583008, -1.0387322902679443, -28.97325897216797, -38.40336990356445, 4.307667255401611, 28.026548385620117, 6.250770568847656, -17.23046112060547, -5.82049560546875, -38.99724197387695, -17.709182739257812, 22.90721893310547, -36.64759063720703, -16.929048538208008, -2.746364116668701, 1.0964970588684082, 2.5554492473602295, -3.7813520431518555, -31.453340530395508, 17.719404220581055, -17.85003662109375, -7.135383129119873, 3.31199312210083, 4.365799903869629, -9.072561264038086, -3.3111467361450195, 46.36495590209961, -24.362140655517578, 42.318092346191406, -19.44611930847168, 46.42924499511719, -19.879194259643555, -12.339325904846191, 3.4820122718811035, -12.380698204040527, -19.094568252563477, 0.7160146832466125, 45.0157356262207, -19.173219680786133, 9.592169761657715, 3.6433029174804688, -11.664464950561523, -38.812286376953125, 2.0365262031555176, -13.725164413452148, 18.735227584838867, -20.604915618896484, 2.9450247287750244, -6.866117000579834, -24.934768676757812, -38.06116485595703, -39.512062072753906, 7.447065353393555, -41.40126419067383, 41.80908966064453, -39.304561614990234, -39.07060623168945, -38.177406311035156, 6.6142425537109375, -10.579299926757812, -32.389591217041016, -19.585235595703125, 7.391799449920654, -32.925804138183594, -17.87522315979004, -30.22321891784668, -29.48107147216797, -21.476383209228516, -41.08934020996094, -37.98040008544922, -36.64529037475586, 31.568105697631836, -5.327345371246338, -37.6187858581543, -11.969548225402832, 3.0956013202667236, -14.516249656677246, -40.16469192504883, -34.26705551147461, -31.777488708496094, -39.73296356201172, -31.319177627563477, -36.402366638183594, -2.7394495010375977, 36.75777053833008, 18.867847442626953, -35.856929779052734, -13.387465476989746, 30.946016311645508, -37.04938507080078, 41.192962646484375, -22.34206199645996, -3.056394577026367, -28.5662841796875, -37.18561553955078, -14.456131935119629, -35.92721939086914, -4.756899356842041, 10.237160682678223, 26.376054763793945, 3.3635313510894775, -11.269497871398926, -2.452472448348999, -8.372174263000488, -24.072059631347656, -14.747310638427734, -12.864713668823242, 5.230804443359375, -41.306400299072266, -2.3727774620056152, -18.684690475463867, 34.197322845458984, -39.8109245300293, 3.5569403171539307, -35.29767608642578, 18.011627197265625, 2.4445693492889404, 40.93479919433594, 1.3951983451843262, -12.887933731079102, 32.72490310668945, -40.36249542236328, 5.4369072914123535, 39.72783660888672, 46.05107879638672, 33.21949768066406, -2.4597158432006836, 29.955167770385742, -37.4271240234375, 46.09315872192383, 5.615592956542969, 32.513343811035156, -38.12224578857422, 39.05863571166992, 17.4847354888916, 3.6042749881744385, -12.882844924926758, -13.95071792602539, 40.607383728027344, 38.0936393737793, 4.3920087814331055, -0.44013461470603943, 5.4372358322143555, -33.7306022644043, 35.415462493896484, 32.470054626464844, 6.930311679840088, 37.61252212524414, -24.6911563873291, -34.258052825927734, 1.2998360395431519, 3.139800548553467, 2.196168899536133, -40.01618957519531, 12.382052421569824, -2.2514209747314453, -1.6304994821548462, -29.30659294128418, -13.947273254394531, 7.395382404327393, -39.9395637512207, -24.680387496948242, -16.10759735107422, -24.763275146484375, -36.883399963378906, -18.580793380737305, -24.557865142822266, -0.6918429732322693, 5.107859134674072, 27.119600296020508, 39.262088775634766, 34.47248077392578, 0.12355068325996399, -38.1002082824707, -17.65101432800293, 3.4643733501434326, 45.08343505859375, -35.73217010498047, -39.26047134399414, -29.944740295410156, -2.5572879314422607, -17.86081314086914, 45.80552673339844, 38.70759201049805, 29.628223419189453, 3.793299674987793, -0.8915375471115112, 4.27268123626709, 41.080387115478516, -0.4120195508003235, -5.134189128875732, -26.524269104003906, 4.994804859161377, 2.9872782230377197, -25.2308406829834, -4.967536449432373, -38.99348449707031, -3.4146485328674316, -31.319101333618164, -5.958591461181641, -31.912805557250977, -7.0008344650268555, -15.874014854431152, -19.619632720947266, -9.746774673461914, 5.903580188751221, 15.618148803710938, -2.7612266540527344, 1.7769179344177246, -39.063724517822266, -40.31998062133789, -32.12040328979492, 35.799949645996094, 36.30110549926758, 31.568246841430664, -39.477333068847656, 3.208385705947876, -35.9024772644043, -29.4610652923584, -9.096212387084961, -6.6699628829956055, -35.035282135009766, 28.95804214477539, 44.55927276611328, 45.01437759399414, 40.65339279174805, 24.82956886291504, 30.95217514038086, 30.167631149291992, 11.608872413635254, 31.459901809692383, 12.997113227844238, 4.361050605773926, -0.140577495098114, 5.380342960357666, -5.732264041900635, -20.983970642089844, -11.828882217407227, 2.5549142360687256, -10.696600914001465, 18.09226417541504, 3.0323362350463867, -40.37223434448242, 31.61680793762207, -10.153655052185059, -11.453167915344238, -1.9753998517990112, -37.295780181884766, 1.6498041152954102, -40.243282318115234, 46.687957763671875, -32.8802375793457, 18.42060661315918, 2.3849730491638184, 14.941025733947754, 1.9139035940170288, -7.260364055633545, -28.575551986694336, -32.41139221191406, -16.166778564453125, -36.395973205566406, 7.036972999572754, -9.477819442749023, -5.756246566772461, 39.392120361328125, -8.25296401977539, -21.47645378112793, 0.9888671040534973, -0.009984715841710567, 5.694857597351074, -2.8896443843841553, 1.4610675573349, 13.849217414855957, -18.085206985473633, 2.6594643592834473, -37.51676559448242, 1.448747158050537, 8.543251991271973, -13.233593940734863, -36.01041030883789, -39.33476257324219, -39.28976058959961, -36.107879638671875, 5.246753692626953, 45.751251220703125, -16.32201385498047, 4.110673904418945, 42.81619644165039, -13.627426147460938, -0.858349621295929, -37.72114944458008, -25.7553653717041, 1.8506327867507935, -22.896486282348633, -22.93895149230957, 1.8957240581512451, -37.44849395751953, -33.39180374145508, -0.5227232575416565, 3.7399401664733887, 23.690139770507812, -0.03660006448626518, 3.066843032836914, -22.05489158630371, 40.603309631347656, -24.471925735473633, 3.23517107963562, 14.533498764038086, 41.51741409301758, -38.784149169921875, -15.533936500549316, -14.492898941040039, -0.20521360635757446, -39.739288330078125, 35.22639083862305, 46.74528121948242, 46.27483367919922, -21.832998275756836, -4.786146640777588, -22.08363914489746, 4.048473358154297, -38.66078567504883, 46.607017517089844, -23.06275749206543, -13.005382537841797, -38.44484329223633, -25.238340377807617, 8.4463529586792, -5.848818302154541, -16.303579330444336, 36.615455627441406, -38.203067779541016, -19.92225456237793, -13.082282066345215, -27.66319465637207, 4.118443012237549, 45.237552642822266, 4.247714519500732, -36.62266159057617, -0.6773244738578796, -9.368986129760742, -36.725791931152344, -30.504369735717773, -39.64708709716797, -22.154577255249023, -37.13240051269531, -15.115525245666504, 2.709315061569214, -38.92259979248047, 15.08123779296875, -2.514612913131714, -9.448507308959961, 31.826047897338867, -26.630308151245117, -40.1028938293457, 33.431602478027344, -16.290185928344727, -7.212026119232178, 4.595632076263428, 32.03566360473633, 11.308089256286621, -29.264507293701172, -12.234833717346191, -36.09942626953125, 8.717011451721191, 42.118839263916016, -37.66972351074219, 1.3691946268081665, -25.31962776184082, 2.830867052078247, 0.5420404672622681, -13.203938484191895, -21.673748016357422, -17.1990909576416, -11.909122467041016, -35.939361572265625, 1.7289836406707764, 36.61151123046875, 2.043177604675293, -40.522178649902344, -18.754215240478516, -11.720965385437012, -25.72025489807129, -9.860654830932617, 45.689674377441406, -26.933576583862305, -39.33458709716797, 25.91316795349121, 0.6096228957176208, -14.244093894958496, -25.019821166992188, 11.17479133605957, 1.8685576915740967, 0.637451171875, -11.016653060913086, 2.6160943508148193, -29.279863357543945, 2.0405995845794678, 28.110795974731445, 44.926513671875, 5.214176177978516, 4.398808479309082, -18.269914627075195, 1.6072237491607666, -12.699668884277344, -30.666427612304688, -27.8748779296875, 3.5694966316223145, 2.7791025638580322, -37.05656433105469, 2.1046345233917236, -36.25349044799805, -13.633042335510254, -31.781702041625977, 4.413998126983643, -15.315746307373047, -0.5108894109725952, -38.112464904785156, 1.7413491010665894, 9.57337474822998, 11.952496528625488, 37.965126037597656, 30.000900268554688, 0.7424514889717102, 0.16290727257728577, 13.352521896362305, 15.502333641052246, 4.704498291015625, -5.452127933502197, -39.1158332824707, -3.462080240249634, -1.72360098361969, -24.316986083984375, 3.689737558364868, -36.32915496826172, 3.83012056350708, 4.00843620300293, -7.043853282928467, 2.5551514625549316, 10.547392845153809, -35.68305587768555, 5.293129920959473, 3.6223878860473633, 5.504662990570068, -37.99687194824219, -11.96591854095459, -39.985137939453125, -5.680607318878174, 27.098257064819336, -38.866455078125, -28.683822631835938, -36.97289276123047, 40.27157211303711, 34.95045471191406, 2.92276668548584, -19.47966766357422, -11.054572105407715, 31.127758026123047, -27.90160369873047, 18.490421295166016, -17.03318977355957, -15.672249794006348, -38.50547409057617, 3.993272542953491, -34.04118347167969, -14.973709106445312, 5.5614013671875, 13.413363456726074, -30.37192726135254, 5.321133136749268, 46.509185791015625, -26.78912925720215, 1.6271089315414429, -14.757377624511719, -37.89452362060547, -17.499067306518555, -11.631083488464355, 1.694825530052185, 26.094099044799805, -36.595680236816406, -2.4208133220672607, 46.3241081237793, 17.047513961791992, -4.078090667724609, 4.193572521209717, -18.245018005371094, 40.5169792175293, 39.83309555053711, -16.17180824279785, -4.0436296463012695, -11.03774356842041, 30.623409271240234, -19.739118576049805, -15.657953262329102, -13.016716003417969, -22.751907348632812, 5.502283573150635, 5.863917827606201, -3.641972541809082, 0.864633321762085, 24.02347183227539, 4.2042927742004395, 4.979922771453857, -23.117368698120117, -32.140079498291016, 24.782875061035156, 0.669183075428009, -9.28821849822998, -29.614173889160156, 40.99106979370117, -20.22412872314453, -6.648801326751709, 3.4258148670196533, 4.310786247253418, -18.085378646850586, -9.096504211425781, 2.955397844314575, 3.8309590816497803, -10.414898872375488, -7.901947975158691, 4.145377159118652, -40.61806106567383, -15.620271682739258, -24.52188491821289, -40.72262191772461, 31.42584800720215, -28.101177215576172, 43.92412185668945, 1.6887242794036865, -13.067407608032227, 2.003898859024048, 45.28566360473633, -38.75056457519531, -16.488277435302734, -6.384703159332275, -17.940364837646484, -12.253196716308594, -23.138158798217773, 14.435599327087402, -4.220634460449219, 13.254219055175781, 4.235185146331787, 24.325191497802734, -39.703365325927734, -5.639657974243164, 2.5325260162353516, -22.589628219604492, 2.8059000968933105, -14.195554733276367, -37.84335708618164, -8.160061836242676, -25.866531372070312, -4.659766674041748, -0.9725664854049683, 22.352848052978516, -25.396333694458008, 17.344186782836914, -10.547054290771484, -29.747901916503906, 38.33896255493164, 26.618526458740234, -19.383604049682617, -3.118666887283325, -13.750971794128418, 33.130435943603516, -0.5846967697143555, -8.391495704650879, -21.933856964111328, -3.5208210945129395, -14.022516250610352, 26.755979537963867, -19.517784118652344, 15.919404029846191, 31.851694107055664, 45.479835510253906, 7.703188896179199, 30.42228126525879, -13.484579086303711, -31.595378875732422, -17.39850425720215, 8.615372657775879, -12.665495872497559, 6.720057487487793, -15.978789329528809, -16.007200241088867, -10.017236709594727, -8.842141151428223, 0.4431982934474945, -41.05249786376953, 37.20897674560547, -33.36479949951172, 0.7910104393959045, -1.0612961053848267, 5.0582661628723145, -6.918564796447754, -0.47674864530563354, 1.893652319908142, -26.454309463500977, 6.42510461807251, -6.915207862854004, -13.878973007202148, -24.7643985748291, 3.7579293251037598, -12.474563598632812, -16.54059410095215, -32.99214172363281, 11.072949409484863, -39.810203552246094, -24.464391708374023, 4.361113548278809, -14.50041675567627, -16.17099952697754, 22.584312438964844, 1.5914733409881592, -10.82203483581543, 1.2541303634643555, -12.466300964355469, -3.3580050468444824, 5.513850212097168, -2.438937187194824, -21.157005310058594, -13.662504196166992, 3.368295192718506, 2.6899349689483643, 1.8081731796264648, -17.3438720703125, 3.172144651412964, 8.53376579284668, -1.1735631227493286, 12.162866592407227, -36.04804992675781, -19.083454132080078, 3.1921753883361816, -14.575446128845215, -8.017965316772461, 3.235220193862915, -37.81580352783203, -16.29322052001953, 1.7063926458358765, -40.51750564575195, -1.2852933406829834, -27.6236572265625, -1.4497562646865845, 0.168659970164299, -28.753395080566406, 1.62604820728302, 45.32689666748047, -21.59351921081543, 3.691995859146118, -17.424436569213867, -23.776927947998047, -39.04216003417969, -30.84539222717285, 2.9825057983398438, -4.99736213684082, -34.937660217285156, -38.41219711303711, -28.55207633972168, 1.482234001159668, -40.33378601074219, 17.526235580444336, -14.148930549621582, -22.470500946044922, -8.277813911437988, -6.888155460357666, 1.5279755592346191, 2.248906135559082, -3.4105446338653564, -14.113245964050293, 2.016942024230957, -30.911300659179688, -26.407617568969727, 3.9741721153259277, -6.198347091674805, -27.302446365356445, 39.67497253417969, -1.1776857376098633, -36.4032096862793, -17.201993942260742, 2.2733864784240723, -9.086202621459961, 23.35650634765625, 31.244230270385742, -2.0237948894500732, -38.862144470214844, -4.584836959838867, -8.02626895904541, 18.613536834716797, -11.040556907653809, -12.101269721984863, 0.619027853012085, -38.32036590576172, -16.706506729125977, -31.949214935302734, -15.173227310180664, 2.15293550491333, -30.425783157348633, -39.77033996582031, 32.63715744018555, 1.5732080936431885, 1.4303690195083618, 39.28916549682617, 1.1583755016326904, 35.93294143676758, -2.3773739337921143, -37.3532829284668, -7.79773473739624, -3.414368152618408, -16.29705810546875, -8.165810585021973, -17.75159454345703, -30.03429412841797, -39.070404052734375, -30.690082550048828, -16.319629669189453, 5.524180889129639, -19.970012664794922, 2.2048068046569824, -1.3645050525665283, -25.90178871154785, -20.924701690673828, -10.409368515014648, 1.593520998954773, -28.97871208190918, 4.1615214347839355, 0.1814020276069641, 5.396295547485352, -2.5493295192718506, 1.6123501062393188, 17.448423385620117, 1.5608307123184204, 2.6867446899414062, -5.732601165771484, 30.337881088256836, 4.105705738067627, -13.438009262084961, -27.984519958496094, 30.323524475097656, 1.655562400817871, 4.400761604309082, 2.960050106048584, 36.49358367919922, -8.897233963012695, -22.87485694885254, -35.31090545654297, -15.400956153869629, -1.1581432819366455, -16.233203887939453, -31.090476989746094, -2.209012269973755, -35.100276947021484, -31.580154418945312, -14.443120956420898, 2.8513457775115967, -18.298856735229492, 3.959690570831299, -32.54247283935547, -0.3693159818649292, -2.2808451652526855, 3.812478542327881, -10.062054634094238, -30.018016815185547, -5.838962078094482, -41.0711555480957, -31.27757453918457, -2.1927175521850586, -10.890748977661133, -22.27727508544922, 3.94174861907959, 1.8044253587722778, 1.2799456119537354, -25.786819458007812, -18.77276039123535, -39.21418762207031, 2.3615076541900635, -39.66463088989258, -4.706277847290039, 0.6611180901527405, -15.553709030151367, 3.4019956588745117, -20.788921356201172, -38.287132263183594, -9.242613792419434, -5.4671478271484375, -14.278263092041016, 22.786117553710938, 4.171152591705322, 0.3770877420902252, -25.176538467407227, -17.809450149536133, 1.9897127151489258, -5.7386555671691895, -2.0682570934295654, -15.784689903259277, -16.769529342651367, 0.6995654702186584, 7.251498222351074, 3.360912322998047, 41.584144592285156, -5.1891703605651855, -27.3642578125, -16.954782485961914, -38.449485778808594, -15.842772483825684, -35.1736946105957, -11.24600887298584, -11.826170921325684, -4.625999927520752, -35.44071960449219, -5.388739109039307, -40.54948806762695, -30.38511085510254, -1.858169674873352, 3.092115640640259, -20.906574249267578, -14.779520034790039, 1.5141383409500122, -1.7426201105117798, -7.520579814910889, -4.455383777618408, -0.7685651779174805, -3.9637303352355957, 24.251705169677734, -9.355188369750977, -19.737165451049805, -13.193379402160645, -25.41063117980957, -37.77260208129883, -7.979479789733887, 19.322917938232422, -33.64534378051758, 5.196836471557617, 7.083828449249268, 3.8506085872650146, -15.244266510009766, -36.6640510559082, -19.96379280090332, -1.2815358638763428, -7.665472507476807, -20.56283187866211, -3.7039458751678467, -31.368873596191406, -23.52789306640625, -19.812259674072266, -10.769295692443848, -17.233043670654297, 41.67713928222656, -36.83451461791992, 42.644474029541016, -16.226551055908203, -39.806663513183594, 0.9725263118743896, -6.175349712371826, -0.09805956482887268, -35.86052703857422, 4.365568161010742, -3.9652533531188965, -32.112308502197266, -33.80850601196289, -6.659698486328125, -27.09425163269043, -27.080522537231445, -16.164854049682617, -10.992804527282715, -8.43914794921875, -41.31871032714844, -37.668365478515625, 1.4452673196792603, -0.4089850187301636, -28.739185333251953, 13.060574531555176, -16.234539031982422, -33.005619049072266, -7.6584038734436035, -26.224273681640625, 1.9248909950256348, -30.11958122253418, -10.570536613464355, -22.393632888793945, -31.140634536743164, -36.969825744628906, -29.301799774169922, 4.31374454498291, -23.841825485229492, -38.37278366088867, -19.140485763549805, -9.76196575164795, 4.706887722015381, 1.6181260347366333, -10.36555004119873, 2.989647626876831, -0.16461774706840515, 10.795783996582031, -27.430931091308594, -31.420862197875977, -39.37876510620117, -23.882749557495117, 2.091907501220703, -16.10919189453125, -11.308109283447266, -18.918540954589844, -17.08672523498535, 15.897212982177734, -2.1196465492248535, 1.9649916887283325, 5.404397964477539, 9.880634307861328, -27.863357543945312, -40.175254821777344, -5.313533782958984, -31.09767723083496, -2.3289477825164795, 4.589580059051514, 3.2413442134857178, 37.320343017578125, -40.18357467651367, -37.8821907043457, -2.4368629455566406, -1.9522477388381958, -27.788991928100586, 3.7798731327056885, 28.388248443603516, -31.06997299194336, 3.9399657249450684, -17.099178314208984, -33.06288528442383, -10.962403297424316, -26.1990966796875, -34.142234802246094, -39.11476135253906, 7.572174072265625, -40.04143524169922, -38.98963165283203, -37.15925979614258, 2.7669103145599365, 3.4952526092529297, 2.02835750579834, -10.925053596496582, -11.9108247756958, -21.632192611694336, -6.748457431793213, -32.98331832885742, -29.01176643371582, -3.568909168243408, -41.07646942138672, -22.747865676879883, 43.157649993896484, -10.089658737182617, -4.0670671463012695, -25.7406005859375, 2.022250175476074, 2.7645959854125977, -11.55325698852539, -37.22403335571289, -13.507805824279785, -39.520118713378906, -35.10481643676758, -23.562931060791016, -3.1033544540405273, 0.4217807948589325, -6.251979351043701, -5.41923189163208, -28.120166778564453, -40.829795837402344, -8.20405387878418, 4.125303745269775, -14.608622550964355, 2.472320556640625, -31.12278938293457, -14.588204383850098, -30.006919860839844, 2.7163197994232178, -31.01382064819336, -17.919038772583008, 3.6932880878448486, 1.1064817905426025, -37.56631088256836, -11.00253963470459, 0.6725674867630005, -23.393247604370117, 13.937875747680664, 5.498360633850098, 3.389073371887207, -3.6703619956970215, -20.5777587890625, -18.0986385345459, -22.36763572692871], \"y\": [-5.852118015289307, -42.61534118652344, -37.16272735595703, -42.587196350097656, -37.41513442993164, -2.95501971244812, -42.756195068359375, -41.35460662841797, -16.674209594726562, -43.060508728027344, -40.70439910888672, 10.678156852722168, -41.71809005737305, -41.62645721435547, 2.486205816268921, -43.4848518371582, 9.637706756591797, 2.4015274047851562, -37.962486267089844, -33.768829345703125, 3.2253546714782715, -5.120482444763184, 17.3554630279541, -30.347862243652344, 12.375263214111328, -20.445199966430664, -22.962032318115234, -31.057361602783203, -43.18147277832031, -25.10930061340332, -42.86281204223633, -39.86176300048828, 3.8510048389434814, -10.018165588378906, -5.015580654144287, 1.5494016408920288, 15.174556732177734, -23.125226974487305, 11.570070266723633, 17.270904541015625, 10.965791702270508, 12.3953275680542, -2.848613977432251, 17.202585220336914, -42.98804473876953, 13.861613273620605, -41.91545104980469, -31.804977416992188, -10.175382614135742, -42.81792449951172, 10.64430046081543, -23.44777488708496, -35.50877380371094, -1.1731058359146118, -43.49315643310547, 15.563348770141602, -40.715694427490234, -26.521080017089844, -35.64248275756836, -42.98019790649414, -32.33019256591797, -43.09187316894531, -32.92036437988281, -40.20941162109375, -36.05997848510742, 42.015438079833984, -43.40392303466797, -39.5066032409668, 31.77043342590332, 46.996910095214844, -1.9432252645492554, -24.862056732177734, 15.361470222473145, -32.83443069458008, -36.2935905456543, -40.20927810668945, -16.062402725219727, -39.91416931152344, -12.969366073608398, -9.405166625976562, -14.294425964355469, -42.254390716552734, -35.40631103515625, 7.388576030731201, 29.023090362548828, -9.95609188079834, 1.1827179193496704, -35.18998718261719, 20.3472957611084, 13.904584884643555, 28.426856994628906, -17.20416831970215, -0.9555498361587524, -40.916954040527344, 17.109922409057617, -12.029370307922363, 1.333734154701233, -35.47413635253906, 25.409461975097656, 16.77083969116211, -31.849079132080078, -16.265201568603516, -21.386262893676758, -28.659162521362305, -20.946060180664062, -16.922222137451172, -36.147403717041016, -27.492366790771484, -20.71866798400879, -39.06718063354492, -8.694506645202637, 13.986557960510254, -39.73786163330078, -34.582942962646484, -27.70258331298828, -36.5731201171875, 14.304636001586914, -28.663040161132812, -17.402942657470703, 10.394699096679688, -41.24319839477539, -9.862682342529297, -12.690279960632324, 12.666897773742676, 12.134408950805664, -16.48504066467285, 16.183752059936523, -41.47362518310547, -43.40296936035156, -9.194972038269043, -33.290283203125, -26.44922637939453, 16.917938232421875, 8.731624603271484, -11.56999397277832, -34.21370315551758, 7.365176200866699, -17.259519577026367, -10.974510192871094, 47.25785827636719, 10.642464637756348, -6.129786014556885, -8.787965774536133, 6.8440961837768555, 11.225090026855469, -33.30252456665039, -35.013580322265625, 16.948041915893555, -42.83420181274414, -6.340755939483643, 4.3049492835998535, -14.263812065124512, -7.478363990783691, -6.792052745819092, -24.07805824279785, -2.2557449340820312, 18.309900283813477, -2.1940994262695312, -39.06299591064453, 17.24492835998535, -24.271259307861328, -19.437061309814453, 11.296043395996094, -17.015361785888672, 31.12819480895996, -7.114949703216553, 0.954110324382782, 14.622488975524902, -33.403953552246094, 32.63785934448242, 11.049837112426758, -31.947446823120117, -35.75212860107422, -40.53839874267578, -8.651717185974121, 32.52046585083008, -34.385921478271484, -28.842700958251953, -21.589792251586914, -40.902061462402344, -39.29954147338867, 17.188573837280273, -38.76496505737305, -9.326251029968262, -27.863834381103516, -3.207468271255493, -23.764028549194336, -25.97989845275879, -4.607408046722412, -14.978324890136719, 11.375452995300293, -18.909330368041992, -34.62021255493164, 50.01417541503906, 2.782327175140381, 30.814109802246094, -34.10951614379883, 3.640664577484131, -23.96915626525879, -38.009559631347656, -14.446057319641113, 40.82707595825195, 0.8934673070907593, -34.13090896606445, 8.18336009979248, -36.20378494262695, -10.502182006835938, -4.093618392944336, -7.078902721405029, 8.342794418334961, -38.36467361450195, 16.547962188720703, -14.650313377380371, 13.052640914916992, 56.08891296386719, -19.905742645263672, 14.73849105834961, 14.486043930053711, -11.215974807739258, -40.052001953125, 7.367980480194092, -34.595191955566406, -41.206504821777344, 8.509794235229492, -30.649389266967773, -15.798432350158691, -10.323972702026367, -36.62118148803711, -11.625631332397461, -36.660362243652344, -35.288028717041016, 16.12945556640625, 13.805644035339355, -13.538360595703125, -37.59921646118164, -6.9181318283081055, -41.108158111572266, -35.149662017822266, -16.15052032470703, -16.7908878326416, -35.673187255859375, 25.20597267150879, -40.60614776611328, -7.124131202697754, 16.31160545349121, 7.337202548980713, 4.873968601226807, -36.710391998291016, -17.685806274414062, 13.044286727905273, -27.92951011657715, -43.36543273925781, -10.499923706054688, -1.7295093536376953, -2.2355360984802246, 51.636993408203125, -15.825857162475586, -24.567890167236328, -36.34111785888672, 11.523224830627441, -14.258615493774414, -1.0662593841552734, 17.000106811523438, -9.811688423156738, 11.298096656799316, 12.739779472351074, 39.29561233520508, -2.586592435836792, -43.3845100402832, -23.338207244873047, -17.154356002807617, 24.890295028686523, -3.699450731277466, 47.31707763671875, 16.356185913085938, -15.55765151977539, -8.777929306030273, -12.870776176452637, 6.571127414703369, -42.53343200683594, -9.551899909973145, 11.072507858276367, -28.567590713500977, -11.328749656677246, -5.024940013885498, 7.431629657745361, -35.78489685058594, -30.961811065673828, -36.01481246948242, -5.724868297576904, 14.993463516235352, -16.864795684814453, -33.38582992553711, -9.535663604736328, -10.374357223510742, -38.42455291748047, -41.030662536621094, -20.685972213745117, -28.21696662902832, 31.497690200805664, -27.095890045166016, -11.269306182861328, -13.917255401611328, -9.040721893310547, 2.1078362464904785, 52.53512954711914, -22.996490478515625, -32.28668212890625, -27.007225036621094, -22.66192054748535, -16.373065948486328, 10.691898345947266, 3.3672778606414795, 14.095560073852539, 17.346372604370117, -41.11406326293945, 11.057119369506836, 22.717548370361328, 3.0176942348480225, 8.337010383605957, -42.00782775878906, -19.191802978515625, 2.622157335281372, -19.781606674194336, -4.895166873931885, -11.980522155761719, 12.479339599609375, 9.262083053588867, 15.718713760375977, -9.274889945983887, -10.076493263244629, -8.505707740783691, -4.793968677520752, -10.409242630004883, -17.381948471069336, -41.676490783691406, -34.36235046386719, 5.101744651794434, -14.00584602355957, 17.412456512451172, 9.614171028137207, -7.610135555267334, -32.78965377807617, -8.784551620483398, -34.94895553588867, 21.507408142089844, 51.772239685058594, 16.0001277923584, -11.096575736999512, 1.5495338439941406, -34.75990676879883, -16.069822311401367, -13.180204391479492, -12.188958168029785, 2.844151496887207, -21.042028427124023, 16.59469985961914, -31.37790298461914, 16.657320022583008, 6.937716007232666, -28.035676956176758, 4.599451541900635, -2.552572727203369, 10.024544715881348, -27.4210262298584, -22.438091278076172, -31.04344940185547, -32.376216888427734, -10.563688278198242, -3.7778067588806152, 11.645584106445312, 9.54284381866455, 9.37617015838623, 2.0161643028259277, -39.645660400390625, 11.087254524230957, -1.5342825651168823, 4.469498157501221, -29.743635177612305, -37.70108413696289, 13.832867622375488, -5.132258892059326, 10.154210090637207, 17.352861404418945, -38.946678161621094, 17.14301109313965, -27.213781356811523, -32.46529769897461, -1.9581191539764404, -15.6100435256958, 9.785013198852539, 4.644377708435059, -12.995782852172852, 22.40249252319336, -26.790889739990234, 53.844329833984375, 13.168107032775879, 1.6761021614074707, 37.394535064697266, -13.806097030639648, -12.530360221862793, 2.2014176845550537, 15.191160202026367, 10.237081527709961, -5.526419162750244, 16.907651901245117, -16.725648880004883, -9.583500862121582, -24.28182601928711, -23.400226593017578, 17.455787658691406, -24.530298233032227, 25.88549041748047, 17.522043228149414, 49.01753616333008, -39.831363677978516, -5.286355495452881, -25.91062355041504, -11.063385963439941, -13.003442764282227, -24.70784568786621, -38.277587890625, -7.810775279998779, -7.12365198135376, 10.410545349121094, 24.805063247680664, -5.346645355224609, 51.970558166503906, 1.8060778379440308, 2.5308032035827637, 10.998912811279297, 33.19120407104492, -38.765464782714844, -1.763439416885376, -38.563812255859375, 6.255399227142334, 15.447619438171387, -33.54308319091797, 15.308497428894043, -34.478885650634766, -20.32216453552246, -35.70552444458008, -11.847981452941895, 35.895870208740234, 15.058600425720215, 25.800561904907227, 0.3935142755508423, -27.800519943237305, 14.556198120117188, 25.23358726501465, -18.037580490112305, 7.536343097686768, 16.962430953979492, -35.21141815185547, -29.424962997436523, 13.748388290405273, 7.868879795074463, 12.718878746032715, -19.89692497253418, 17.52909278869629, 8.128511428833008, 21.069372177124023, -29.280160903930664, -12.542470932006836, -20.765823364257812, -22.707109451293945, 10.874964714050293, 31.56787872314453, -3.7178361415863037, -17.800046920776367, -29.807743072509766, -34.914649963378906, -6.5365777015686035, 10.374215126037598, 13.822683334350586, -34.773162841796875, 52.84846496582031, 5.302839279174805, -2.1011955738067627, 50.26743698120117, -30.603120803833008, -27.514633178710938, -7.846433639526367, -27.631376266479492, 11.742621421813965, 29.391315460205078, -21.049985885620117, -36.20143127441406, 20.83224105834961, -29.41501808166504, 56.77047348022461, -17.626543045043945, -4.374062538146973, -7.903671741485596, -40.36860656738281, 7.332202434539795, -17.750967025756836, 13.249510765075684, -33.164554595947266, 12.394989013671875, -26.999208450317383, 4.054445743560791, 13.505264282226562, 23.58144760131836, -13.206250190734863, -35.22782897949219, -4.51057767868042, 12.680678367614746, -26.41402816772461, 51.87812423706055, 3.8282599449157715, -1.5507593154907227, -24.1368408203125, -30.59598731994629, -18.189205169677734, 4.146796703338623, 7.081033706665039, 16.341176986694336, 16.142465591430664, 5.01747989654541, 13.602296829223633, -20.634355545043945, -14.773857116699219, 21.15616226196289, -32.08552551269531, -34.65480422973633, 9.131194114685059, -21.74892234802246, 3.6759531497955322, 17.290916442871094, 9.936750411987305, 8.474609375, 0.7792072892189026, -16.56816864013672, -15.915307998657227, 5.522094249725342, -21.44866943359375, 12.359023094177246, -17.958843231201172, 38.689491271972656, -18.19158172607422, 6.150826930999756, -14.123458862304688, 55.607269287109375, 10.617233276367188, -13.036296844482422, 14.855752944946289, -4.223571300506592, 16.25723648071289, -1.0707849264144897, -26.59079933166504, -33.482234954833984, 3.7196998596191406, 0.9702826142311096, -13.597737312316895, 5.887918472290039, -2.700377941131592, 11.415324211120605, 34.03912353515625, -3.886061906814575, 16.92482566833496, -33.576560974121094, 10.195441246032715, -9.590704917907715, -0.4596942365169525, 16.850391387939453, -24.994779586791992, 47.12183380126953, 10.452354431152344, 17.35110855102539, -5.84704065322876, 30.59733772277832, -26.95508575439453, -24.695938110351562, 10.150131225585938, -6.556545734405518, -14.138704299926758, 34.943660736083984, -18.124774932861328, 6.313364028930664, 51.13335418701172, -3.5508313179016113, 3.4205546379089355, 1.6819870471954346, -21.74078941345215, -12.582527160644531, -23.552717208862305, 27.069063186645508, 2.5035336017608643, 26.907447814941406, -13.848885536193848, 51.051292419433594, 11.294027328491211, 15.097336769104004, -1.6063603162765503, -19.631383895874023, -31.91365623474121, 8.97509765625, 16.9647159576416, 10.031159400939941, 2.889434337615967, -6.900503635406494, -22.567123413085938, -21.34830665588379, 21.610855102539062, 13.15707015991211, -33.67363739013672, 17.549102783203125, 17.404138565063477, -25.672157287597656, 16.408218383789062, -24.689199447631836, -15.456746101379395, 5.9745192527771, 0.6973513960838318, 17.45646858215332, 13.359222412109375, 54.413150787353516, 5.20293664932251, 2.814788818359375, -11.393664360046387, 45.99848937988281, -1.5848668813705444, 0.4587395489215851, 11.441973686218262, -4.061037063598633, 15.644165992736816, -34.92142868041992, 37.055179595947266, 11.85496711730957, 20.496315002441406, -28.289987564086914, 56.0997314453125, -38.76132583618164, 6.121220111846924, -41.66946029663086, 40.50615692138672, -15.366873741149902, -22.055469512939453, 13.946943283081055, -7.716467380523682, 53.294281005859375, -29.03180694580078, 38.83545684814453, -35.2592658996582, -32.949440002441406, -11.217470169067383, -20.96573257446289, -12.080690383911133, -23.49806022644043, 14.493209838867188, -19.565841674804688, -4.509716510772705, -24.73013687133789, -27.853673934936523, -28.041311264038086, -31.320697784423828, 12.011778831481934, -17.631488800048828, 12.280840873718262, -34.333988189697266, -20.984281539916992, 2.9874751567840576, 8.415326118469238, -0.0947212353348732, 13.76541519165039, 24.684799194335938, 10.734583854675293, -30.396907806396484, -23.344505310058594, 13.993644714355469, 19.394729614257812, -40.99393844604492, 50.573917388916016, -35.302734375, -5.617327690124512, 20.9885311126709, -35.636600494384766, 12.982388496398926, 15.157470703125, -15.835659980773926, -31.55305290222168, 7.224542617797852, 14.149847030639648, -28.142446517944336, 17.31271743774414, 6.296378135681152, 10.022363662719727, -35.83674621582031, -36.232933044433594, -15.73828411102295, 36.97426986694336, 45.32155227661133, -3.6971192359924316, 2.446667194366455, 7.225032329559326, 15.296239852905273, 50.07212448120117, 6.541576862335205, -35.26328659057617, 15.397216796875, 50.2320442199707, -19.73444366455078, 14.040031433105469, 6.213736057281494, -13.396276473999023, 2.290118455886841, 4.750053882598877, -17.831144332885742, 23.691316604614258, 15.888401985168457, 1.325715184211731, -13.815083503723145, -0.7576612234115601, 10.024210929870605, 11.08782958984375, 20.324275970458984, 11.364333152770996, -23.331350326538086, -27.382587432861328, -3.0470001697540283, -13.17680835723877, 24.289058685302734, -7.113954067230225, -13.145007133483887, -2.2791330814361572, -8.483497619628906, -34.780006408691406, -3.334775686264038, -6.935920715332031, 4.174124240875244, -35.60638427734375, 34.94375991821289, -27.62804412841797, -31.40256690979004, -13.657609939575195, -2.038602590560913, -21.86798667907715, 10.62430191040039, 12.87649154663086, 15.894780158996582, 17.1691951751709, -2.2738568782806396, 11.120302200317383, -17.91493034362793, 5.560961723327637, -40.35759353637695, -26.133548736572266, -4.552865028381348, -35.67836380004883, 10.52935791015625, 19.299177169799805, -30.83673667907715, 47.4384765625, 8.85081958770752, 47.92023468017578, -27.001237869262695, -11.982834815979004, 11.372308731079102, -16.403562545776367, -2.457165241241455, 3.846672534942627, -29.330049514770508, -3.198528528213501, 20.04477882385254, -24.331472396850586, 5.118788719177246, 32.89270782470703, 16.52431297302246, -7.472360134124756, 56.21580505371094, 50.59288787841797, -0.41226181387901306, 56.331966400146484, 13.081576347351074, -12.823253631591797, 56.00641632080078, -34.02910232543945, 43.40439224243164, 28.334749221801758, 19.271926879882812, -20.381792068481445, 7.9035844802856445, 12.54338264465332, 50.85159683227539, -14.337276458740234, -12.886204719543457, 52.95529556274414, 48.704498291015625, 6.4823317527771, -30.329771041870117, 14.363096237182617, 56.84889602661133, 6.166735649108887, 12.181915283203125, 14.311959266662598, 32.80655288696289, 16.967683792114258, 56.768333435058594, -30.08268928527832, 10.228336334228516, 12.098322868347168, -3.226283550262451, 39.39518356323242, 15.677797317504883, 2.4474477767944336, -20.935300827026367, 15.758452415466309, 8.844853401184082, 13.29325008392334, -23.092830657958984, -35.876041412353516, 11.5126371383667, 3.0660312175750732, -5.040938377380371, -8.008405685424805, -5.276645183563232, 13.831933975219727, -9.658772468566895, 0.12376493215560913, 2.320858955383301, -8.86607551574707, 53.80327606201172, -20.239622116088867, -31.91394805908203, -7.341469764709473, -19.073760986328125, 13.05502700805664, -23.322017669677734, -25.381704330444336, 12.916847229003906, -3.628178358078003, 7.165049076080322, 4.816708087921143, -20.942039489746094, 51.55910873413086, -16.231054306030273, 53.18048858642578, -19.748266220092773, -35.943580627441406, -1.4099608659744263, -16.89337158203125, -19.554407119750977, -12.745918273925781, 9.454038619995117, 6.738961219787598, -35.498783111572266, 17.24530601501465, 9.179131507873535, -15.982640266418457, 14.760272026062012, -31.32023048400879, 4.117537021636963, -7.431577205657959, -30.435819625854492, 48.715091705322266, -24.22781753540039, 5.653964519500732, 14.19789981842041, 7.878198623657227, 48.951419830322266, -0.9875094890594482, 15.38819694519043, -18.187904357910156, -35.43865203857422, 47.65355682373047, 16.29045867919922, -29.681032180786133, -35.17378616333008, -34.79575729370117, 27.984270095825195, -5.66493558883667, -33.94432067871094, -32.52567672729492, 17.3525447845459, -2.440572500228882, 34.1440315246582, 7.9577484130859375, 8.806844711303711, -22.104597091674805, -7.711357116699219, 43.098785400390625, 15.567217826843262, -17.448436737060547, -8.716800689697266, 35.62812042236328, -8.982685089111328, -0.37157949805259705, -34.92384719848633, -32.56779479980469, 16.764284133911133, -11.243537902832031, 7.449616432189941, 36.84967041015625, -18.24461555480957, -10.596911430358887, 16.362796783447266, 6.7621002197265625, 31.446931838989258, 16.3463134765625, 54.979164123535156, 14.855729103088379, 16.528541564941406, 39.8932991027832, 23.979028701782227, -10.662117958068848, -18.218860626220703, -13.859511375427246, -18.28496551513672, -8.78846549987793, 16.66213607788086, 9.968777656555176, -18.120744705200195, -27.135072708129883, 41.238914489746094, -25.188749313354492, -0.8850582242012024, 2.099865436553955, -34.128089904785156, -32.68071365356445, -23.789077758789062, -35.77381896972656, -6.193464279174805, -6.365744590759277, 12.691304206848145, -33.96502685546875, -27.85054588317871, -16.99694061279297, 13.670000076293945, -28.966650009155273, -31.237590789794922, 35.104827880859375, 15.736452102661133, 16.09026527404785, -15.12493896484375, -28.530120849609375, 1.6341127157211304, 55.909549713134766, -22.568660736083984, -2.754126787185669, -14.554891586303711, -3.8691728115081787, 10.323592185974121, 19.56711196899414, 14.153603553771973, -0.9829199314117432, 16.109466552734375, 17.019147872924805, 38.30287170410156, 22.468711853027344, -13.315872192382812, 14.817086219787598, 24.473264694213867, 18.179079055786133, -25.246313095092773, 37.017417907714844, 37.859375, 12.639071464538574, 18.926822662353516, -4.483892440795898, 49.80411911010742, -20.298173904418945, 18.004440307617188, 9.329972267150879, 17.950281143188477, 12.510907173156738, 56.765419006347656, -36.311424255371094, -7.361932277679443, 4.941225051879883, -33.483734130859375, -23.7694091796875, -10.461759567260742, -5.504858016967773, -21.668758392333984, -13.373137474060059, -12.76828670501709, -32.6201171875, 4.981517791748047, 26.69424057006836, -16.502765655517578, -21.803333282470703, 52.62953567504883, -34.79705810546875, -16.330297470092773, 16.557220458984375, 11.047959327697754, 11.247200012207031, 14.929425239562988, 14.745758056640625, -30.391395568847656, -24.594951629638672, 1.1881908178329468, -32.045902252197266, 0.8262702226638794, -11.42153263092041, 24.042570114135742, 34.4591178894043, 18.467769622802734, 56.796627044677734, 15.749760627746582, 37.86764144897461, 15.748117446899414, 9.104703903198242, -21.986928939819336, -11.697234153747559, -31.92421531677246, 52.50554656982422, -36.61234664916992, 23.233652114868164, -13.870203971862793, -28.00732421875, -11.264995574951172, 2.924175262451172, 9.44099235534668, 9.099372863769531, 40.222408294677734, 3.195549249649048, 29.149890899658203, 16.70806121826172, -25.541419982910156, -20.684064865112305, 55.543907165527344, 4.071177005767822, -7.58105993270874, 17.651456832885742, -35.21897506713867, 15.82437801361084, 18.643346786499023, 12.668999671936035, -29.79294776916504, 46.02602767944336, -8.761092185974121, -35.16942596435547, -26.509862899780273, 3.185115337371826, -33.93194580078125, -25.945493698120117, -10.406441688537598, 45.0966796875, -4.006366729736328, 16.468881607055664, 8.470974922180176, 3.406843900680542, -2.2751615047454834, -13.20284366607666, 33.234642028808594, -1.0476840734481812, 12.227731704711914, -15.14297103881836, 13.25776195526123, -35.57438278198242, -31.870790481567383, 5.9452385902404785, -28.160381317138672, 26.918729782104492, -30.051162719726562, -31.605731964111328, -22.39335823059082, -16.04833984375, -20.103017807006836, 45.8774528503418, -20.995243072509766, 13.899434089660645, -29.789413452148438, 28.714527130126953, -30.3266658782959, -8.04578971862793, 10.21202564239502, 30.324426651000977, 2.9556355476379395, -7.097781181335449, -2.0911238193511963, -34.750186920166016, -35.87801742553711, 24.780649185180664, -11.802691459655762, 17.018192291259766, 4.014772415161133, 1.0453054904937744, 12.392443656921387, 19.006763458251953, 13.4165678024292, 35.91611099243164, -1.9126797914505005, 1.1083124876022339, 12.812687873840332, 13.772878646850586, 5.991832733154297, 12.900562286376953, -6.057366371154785, 18.915922164916992, -35.104251861572266, 16.893198013305664, -5.22231388092041, -31.98948097229004, -36.22797393798828, -24.50684356689453, -14.381031036376953, 10.679375648498535, 32.496795654296875, 4.990382194519043, 22.958105087280273, 53.13572311401367, -15.798287391662598, -21.434070587158203, -4.495035648345947, -31.089109420776367, -13.020586013793945, -34.28606033325195, 44.95450973510742, 3.8742949962615967, 4.781548023223877, -32.97924041748047, 15.109128952026367, -19.897798538208008, -27.777997970581055, 1.2380622625350952, 17.342552185058594, -34.00809097290039, 16.91881561279297, -12.4097318649292, -19.385202407836914, -0.6129372715950012, -22.828426361083984, 14.446907043457031, 6.107428073883057, -4.960155487060547, -6.463570594787598, 2.730506658554077, 41.856876373291016, 10.849320411682129, 27.607646942138672, -29.18985366821289, 54.141510009765625, -31.911378860473633, -34.5984992980957, 54.44137954711914, 7.154151916503906, 28.319684982299805, 16.679960250854492, -26.76432991027832, -4.595211505889893, 56.26829528808594, 52.6046028137207, 12.34544849395752, 53.651611328125, 8.651833534240723, -26.746074676513672, 6.6765828132629395, 15.129833221435547, 44.116878509521484, 54.53388595581055, -27.804378509521484, -0.348420113325119, 28.05215835571289, -28.657894134521484, -35.38217544555664, 39.66129684448242, -23.979684829711914, 44.17744827270508, 16.52362060546875, -2.779083013534546, 38.521244049072266, 39.81744384765625, 13.793935775756836, -25.427383422851562, -35.12295150756836, -23.44244384765625, 11.603038787841797, -21.270288467407227, -20.336894989013672, 6.765500545501709, -23.232084274291992, -15.98997974395752, -35.99671936035156, -21.39596176147461, 36.449302673339844, 55.44143295288086, 46.49036407470703, -13.257364273071289, -25.219724655151367, -1.6965690851211548, 0.9209562540054321, 16.46204948425293, 17.472448348999023, 43.94599914550781, -29.31020164489746, 2.208374261856079, 5.485518932342529, -14.521947860717773, 51.6093864440918, -1.274139404296875, -34.08991622924805, 48.61519241333008, 10.410706520080566, -16.811933517456055, 6.326021671295166, 27.54449462890625, 42.40053939819336, 16.34386444091797, 24.63189697265625, -2.0844993591308594, -15.938356399536133, 38.617027282714844, -15.60091781616211, -10.500289916992188, 4.1279473304748535, 16.50792694091797, -0.2408653348684311, 17.863855361938477, 15.742220878601074, -3.269192934036255, -24.93807601928711, 8.077216148376465, -8.382722854614258, -14.471795082092285, 34.866119384765625, 11.154932975769043, -35.104042053222656, -21.945072174072266, -27.3509578704834, 8.305447578430176, 56.439453125, 56.009002685546875, -7.5327935218811035, 42.097564697265625, -17.29743003845215, -34.408935546875, -10.490165710449219, 1.881016492843628, 9.531258583068848, 34.38024139404297, 5.63718318939209, 11.80435848236084, 41.196773529052734, 54.75301742553711, 1.022278904914856, 11.692143440246582, -36.31755065917969, -23.947216033935547, 15.8487548828125, -14.225135803222656, 23.00875473022461, 1.1675289869308472, 7.187999248504639, 18.133480072021484, 28.807374954223633, -33.26251220703125, -8.037515640258789, -9.374796867370605, -34.30642318725586, 50.63832092285156, -36.129451751708984, 17.691997528076172, 13.872965812683105, 55.37583541870117, 53.71987533569336, 13.37670612335205, -11.360600471496582, -9.366093635559082, 20.244129180908203, 46.95764923095703, 13.950339317321777, -16.500295639038086, -13.831923484802246, -31.133052825927734, 10.905072212219238, 14.608570098876953, -27.775774002075195, 52.577171325683594, -22.34561538696289, -7.759027004241943, -32.905601501464844, 51.6761360168457, -23.294384002685547, 41.197086334228516, 56.36714172363281, 51.95616149902344, -20.37462043762207, 37.420650482177734, 16.176916122436523, 19.65836524963379, 36.50862503051758, 2.9005115032196045, -34.257266998291016, 11.065699577331543, -2.574388265609741, 17.223102569580078, -24.013532638549805, 11.940500259399414, -28.170738220214844, 54.89808654785156, 33.52801513671875, 9.76612663269043, 4.263469696044922, -35.313716888427734, 16.402984619140625, 56.340423583984375, 53.94291687011719, -29.58259391784668, 4.122945308685303, -33.75163650512695, 3.0606558322906494, -15.615975379943848, 14.243011474609375, -5.603813648223877, 20.2333927154541, 40.394996643066406, -29.98781394958496, 28.618881225585938, 13.998875617980957, -14.572915077209473, 52.87458419799805, -27.09746742248535, -35.13167190551758, 25.507863998413086, 12.710983276367188, -28.445711135864258, 8.034400939941406, -36.105159759521484, -24.433673858642578, 16.39706039428711, 16.250795364379883, 56.560890197753906, -33.401798248291016, 12.541916847229004, -34.60143280029297, 25.594865798950195, 50.515968322753906, -31.9215087890625, -33.48298645019531, 54.860511779785156, 16.301342010498047, 56.99260330200195, 5.4217915534973145, -19.856422424316406, 9.36475944519043, -4.045228481292725, -25.912994384765625, -35.41885757446289, 9.650589942932129, 10.752983093261719, -4.261116981506348, 54.756526947021484, -8.78386402130127, 13.814626693725586, -34.957122802734375, 54.38689422607422, 17.39713478088379, 23.24127960205078, -4.15751838684082, -11.722189903259277, 8.73233413696289, 24.65445327758789, 46.720951080322266, 32.74262619018555, 52.41468048095703, 22.62185287475586, 39.64387130737305, -25.99201774597168, -8.579007148742676, 19.306406021118164, -34.64305877685547, 12.769086837768555, 34.79197311401367, 17.790828704833984, 55.51526641845703, -20.927967071533203, -0.4192492365837097, -5.31520938873291, 11.370555877685547, 34.41270065307617, 14.922541618347168, 13.532635688781738, 13.361416816711426, 42.352474212646484, -35.56498718261719, -28.253154754638672, 53.92995071411133, 22.59613800048828, 35.723114013671875, 21.073993682861328, -30.95108413696289, 53.945167541503906, 33.83211135864258, -22.38446807861328, -29.1640682220459, -34.906795501708984, 41.88331604003906, -4.02632999420166, 45.925174713134766, 0.5435165762901306, 6.993501663208008, -33.49604797363281, 42.7513313293457, 13.482671737670898, 52.653350830078125, 28.58110809326172, 3.408895492553711, 13.815140724182129, 32.94718551635742, -1.9194715023040771, 22.804716110229492, -24.22780990600586, 48.19939041137695, 46.74457931518555, 11.128089904785156, 27.568117141723633, -2.0819995403289795, -30.647953033447266, -17.85175895690918, -33.83255386352539, 12.59882926940918, -11.281927108764648, -21.74634552001953, -22.410831451416016, 18.181550979614258, -18.386627197265625, -9.12735366821289, -26.837663650512695, -29.346338272094727, -7.800839424133301, 7.327863693237305, 55.4052734375, 11.253430366516113, 52.2940673828125, -36.41725540161133, 41.53528594970703, 33.952857971191406, 18.74312973022461, 54.96622085571289, 43.02571105957031, 10.360726356506348, -25.745521545410156, -18.129077911376953, 19.681285858154297, 11.628937721252441, 15.574275016784668, 45.896053314208984, 3.762678384780884, 13.443629264831543, -27.105907440185547, 52.11488723754883, 13.124380111694336, 17.487504959106445, 21.900890350341797, 5.65349817276001, 17.478404998779297, 19.214923858642578, 9.543863296508789, 17.698665618896484, 13.988237380981445, 24.47305679321289, -7.657983779907227, 15.183431625366211, 9.842514038085938, 13.475126266479492, 43.8459358215332, 11.899026870727539, 1.766961693763733, 17.33551788330078, 46.806785583496094, 41.30109786987305, -9.691028594970703, 45.9451789855957, 16.73434066772461, 46.989601135253906, 6.576215744018555, -35.32125473022461, 19.93367576599121, 55.8297119140625, 18.359724044799805, 14.669174194335938, 10.84488582611084, 0.15075446665287018, 10.391618728637695, 11.564685821533203, -11.348368644714355, 56.895992279052734, 41.88774490356445, -33.77032470703125, -27.684646606445312, -32.26365280151367, 14.151606559753418, 46.58381652832031, 12.425429344177246, 35.77134323120117, 45.41639709472656, 37.3570556640625, 48.10031509399414, 26.21355628967285, 8.297774314880371, 45.60378646850586, 43.374855041503906, -34.472381591796875, 16.761709213256836, -14.484322547912598, 15.700550079345703, -25.898637771606445, 17.37767791748047, 46.11420822143555, -15.58510684967041, -21.426876068115234, 17.309194564819336, -36.205413818359375, 11.494122505187988, -14.85677433013916, 54.8857536315918, -32.80657958984375, 15.59923267364502, 10.14352035522461, -34.54289627075195, -16.692859649658203, 10.786052703857422, -34.7142333984375, 44.69171905517578, -33.667701721191406, -12.076728820800781, 8.09085750579834, 26.25241470336914, 20.020004272460938, 43.6907958984375, 53.61273193359375, -23.4024658203125, 20.458402633666992, -0.8391579985618591, -20.52740478515625, 49.86785125732422, -36.68296813964844, -31.305322647094727, 33.52931213378906, -24.646718978881836, 45.31736755371094, 10.799731254577637, 56.73625183105469, -3.480756998062134, 31.40981101989746, -10.534645080566406, 50.79052734375, 24.031171798706055, -33.52652359008789, 27.759334564208984, 56.812835693359375, -9.120699882507324, 53.21065139770508, -36.02272033691406, 16.84912109375, 13.000868797302246, 29.98805046081543, 26.588438034057617, -29.20775032043457, 11.389195442199707, -23.141233444213867, 17.023822784423828, 48.56809616088867, 12.636016845703125, 56.411155700683594, 45.9600944519043, -6.891350746154785, 32.568241119384766, -7.016184329986572, 50.683650970458984, -26.199199676513672, 14.112180709838867, -7.690089702606201, 15.87031078338623, 5.950515270233154, 53.44329071044922, 15.649369239807129, -35.4837760925293, 5.398997783660889, 50.441986083984375, -3.5537872314453125, -21.786563873291016, 22.165225982666016, 26.674888610839844, 56.8027458190918, 55.36187744140625, 44.61780548095703, 48.530487060546875, 18.20845603942871, 20.326488494873047, 24.079105377197266, 50.12165069580078, 13.930603981018066, 54.13500213623047, 56.986183166503906, 54.43875503540039, -29.67776870727539, 4.625502109527588, -35.79174041748047, 9.879555702209473, -18.59305763244629, 27.955469131469727, -6.3630757331848145, 29.713157653808594, -33.92824172973633, 8.103355407714844, 56.85660934448242, 20.059368133544922, 51.917564392089844, -32.792320251464844, 49.70097732543945, 11.344676971435547, 13.80783748626709, -33.329742431640625, 52.659732818603516, 12.317971229553223, 14.24828815460205, -14.364984512329102, 13.362798690795898, 14.758628845214844, 2.3639094829559326, 45.34675598144531, 50.841514587402344, 44.81613540649414, -14.531270027160645, 32.86293411254883, -34.94091033935547, -20.18175506591797, 8.275477409362793, 50.48884201049805, -26.309051513671875, -27.112239837646484, 56.007198333740234, 51.843299865722656, 18.632171630859375, -5.158809185028076, 5.839366436004639, 43.337642669677734, 26.110309600830078, -25.669570922851562, 2.1491940021514893, 55.210487365722656, 7.707741737365723, 51.344486236572266, -26.998435974121094, 23.077953338623047, -21.651092529296875, 52.595008850097656, 10.950563430786133, 11.581374168395996, 5.219881534576416, 10.351792335510254, 27.66793441772461, -28.271991729736328, -0.19455407559871674, 56.411712646484375, -35.94039535522461, 30.130435943603516, 23.52517318725586, 16.750038146972656, 36.12580871582031, 22.216520309448242, -1.344567894935608, -28.135658264160156, 9.79672908782959, 3.2087912559509277, 11.737384796142578, 26.935976028442383, 13.493566513061523, 53.39808654785156, 56.61656188964844, 13.183439254760742, 5.766753673553467, 49.07966232299805, -26.019392013549805, -12.314122200012207, -2.0836193561553955, 10.792023658752441, -3.427461624145508, 49.37886428833008, -22.85103416442871, 49.10469436645508, 35.5886116027832, 36.602046966552734, 16.728477478027344, 4.115388870239258, -10.973304748535156, -32.22283935546875, -34.12108612060547, -26.07470703125, -15.46127700805664, 17.136411666870117, -22.3591251373291, -20.989469528198242, 55.65802764892578, -19.265378952026367, 15.433980941772461, 9.712074279785156, -18.601600646972656, -8.237909317016602, -5.514019012451172, 0.455245703458786, -1.551247239112854, -13.36899471282959, 29.83722686767578, 36.744754791259766, 45.550357818603516, 17.528791427612305, 17.23322105407715, 11.695332527160645, 19.31328010559082, -20.6867618560791, 11.305469512939453, 21.098419189453125, -1.0840203762054443, 11.794183731079102, 12.835633277893066, -35.57011032104492, -33.77968215942383, -25.851850509643555, 30.362703323364258, 34.873748779296875, 15.042445182800293, 3.625803232192993, 14.052517890930176, 3.7222633361816406, 8.598336219787598, 11.993083000183105, 20.458269119262695, 44.780357360839844, 17.677589416503906, 16.605470657348633, 12.169050216674805, -3.88838267326355, -35.8120002746582, 42.1868896484375, 12.178297996520996, 32.1630859375, 11.966124534606934, 14.834702491760254, 9.659358024597168, 43.73957443237305, -22.862037658691406, 13.564961433410645, 35.766231536865234, 27.40650749206543, -9.94649887084961, 53.70846176147461, -27.91396713256836, -30.36345100402832, 2.4298489093780518, 37.15567398071289, 40.70227813720703, 49.87451934814453, 12.167760848999023, 15.103474617004395, 9.990864753723145]}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a556c33f-5694-44f6-93c6-f03dc393bd71');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    vectors = [] # positions in vector space\n",
    "    labels = [] # keep track of words to label our data again later\n",
    "    for word in model.wv.vocab:\n",
    "        vectors.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    vectors = np.asarray(vectors)\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "\n",
    "def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True):\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    trace = go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)\n",
    "    data = [trace]\n",
    "\n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    #\n",
    "    # Label randomly subsampled 25 data points\n",
    "    #\n",
    "    indices = list(range(len(labels)))\n",
    "    selected_indices = random.sample(indices, 25)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "except Exception:\n",
    "    plot_function = plot_with_matplotlib\n",
    "else:\n",
    "    plot_function = plot_with_plotly\n",
    "\n",
    "plot_function(x_vals, y_vals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "----------\n",
    "\n",
    "In this tutorial we learned how to train word2vec models on your custom data\n",
    "and also how to evaluate it. Hope that you too will find this popular tool\n",
    "useful in your Machine Learning tasks!\n",
    "\n",
    "Links\n",
    "-----\n",
    "\n",
    "- API docs: :py:mod:`gensim.models.word2vec`\n",
    "- `Original C toolkit and word2vec papers by Google <https://code.google.com/archive/p/word2vec/>`_.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
